<link rel="stylesheet" type="text/css" href="main.css"><div class="container chtoc "><div id="header" id-sequence="1"><div id="chapHead" id-sequence="2"><div id="chapterNumber" id-sequence="3"><div class="chapLabel">Chapter</div><div class="chapNum">5</div></div></div><h1 id="CRXLKMX9SVCDCVG4L007" id-sequence="4">The Perceiving Mind: Sensation and Perception</h1></div><div class="content" id="0_content" id-sequence="5"><div id="chapterOutline" id-sequence="6"><ul><li><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="UYJZ78E8L7BRBKCDJ954">Chapter Introduction</a></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-1 </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="RWBZ2VMJFBPF7NTWA025">How Does Sensation Lead to Perception?</a></span><ul><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-1a </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MKRCVFCG9TRPCE02Y171">Sensory Information Travels to the Brain</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-1b </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="ACBSMC64UAN6PC2LT376">The Brain Constructs Perceptions from Sensory Information</a></span></li></ul></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-2 </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="KYMZJT4FQYQVKMJH6632">How Do We See?</a></span><ul><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-2a </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="DRDRMUTCZMW50CY7M263">The Visual Stimulus</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-2b </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="PHQHDBWK8MPBVXUWT080">The Biology of Vision</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-2c </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422">Visual Perception and Cognition</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-2d </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MCYC71NXZJ0X2YZ41055">Developmental and Individual Differences in Vision</a></span></li></ul></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-3 </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="WRNRZQU3P77P17WEF982">How Do We Hear?</a></span><ul><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-3a </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BNLAEA4HZ7J9K48H2540">The Auditory Stimulus</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-3b </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="TFXE8EUL9PYRQB87P719">The Biology of Audition</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-3c </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="KYVXYMRVY8Y7HXMHG320">Auditory Perception and Cognition</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-3d </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="FWAD17EN0M96KAV0A864">Developmental and Individual Differences in Audition</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-3e </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="FGTDNKAMLJSD3RMH2932">Sociocultural Influences on Auditory Perception</a></span></li></ul></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-4 </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="CRNC7DKSL2E63LSQ8900">How Do We Feel Body Position, Touch, Temperature, and Pain?</a></span><ul><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-4a </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="WBRFW8M5CPL1G587C487">Somatosensory Stimuli</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-4b </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MAKWJ35DYYNCCBR5L291">The Biology of the Somatosenses</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-4c </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="PDWA93KMEA13TKF8W067">Sociocultural Influences on the Somatosenses</a></span></li></ul></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-5 </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="HQUX3UCAXRE5U9B52946">How Do We Process Smells and Tastes?</a></span><ul><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-5a </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="UXUX6HT38ALMHL7XC793">Chemical Stimuli</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-5b </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="XNBKV9NL3DN94427M749">The Biology of the Chemical Senses</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-5c </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="FGYH01JSJBXD0V27L228">Perception and Cognition in the Chemical Senses</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-5d </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="VCWDNHQS7VADTHARM103">Developmental and Individual Differences in the Chemical Senses</a></span></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-5e </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MQBWE81ACZV4FXDGK821">Sociocultural Influences on the Chemical Senses</a></span></li></ul></li><li><span class="moduleLabel"><span class="moduleLabelOrdinal">5-6 </span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="SUHKULPWPBFYVJYV4857">Chapter Review</a></span><ul><li><span class="moduleLabel"><span class="moduleLabelOrdinal"></span><a href="javascript://" data-link-type="toc" data-isbn="9781337561815" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="SUHKULPWPBFYVJYV4857">Key Terms The Language of Psychological Science</a></span></li></ul></li></ul></div></div><div id="footer" id-sequence="7"></div></div><div class="container chintro "><div id="header" id-sequence="10"><div id="breadcrumb-old" id-sequence="11" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="12" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h1 id="UYJZ78E8L7BRBKCDJ954" id-sequence="13"><span class="headingText">Chapter Introduction</span></h1></div><div class="content" id="UYJZ78E8L7BRBKCDJ954_content" id-sequence="14"><div class="pageSection" id="NAUUATQGYKL637D9A558" id-sequence="15"> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14c9 rs_skip" id="PLST9ADRZZVQGUD5K494" clrenderdata="[&quot;UHDCZM6GZBZLFTV09445&quot;]" id-sequence="16"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_co01-t3.jpg" data-width="1139" data-height="1377"></div><div class="metadata inlineImage" data-filename="61815_05_co01-t2.jpg" data-width="595" data-height="721" data-alt="The rods and cones in the retina begin the process of interpreting the light energy that enters the eye."></div><div class="nb_media image unnumbered wide"><div class="mediaDescription" id="KEMSNQ1DM0BB2VN6G046" id-sequence="17"><p>The rods and cones in the retina begin the process of interpreting the light energy that enters the eye.</p></div> <div class="imageContainer" style="width:595px;height:721px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_co01-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="The rods and cones in the retina begin the process of interpreting the light energy that enters the eye." width="595" height="721" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Argosy Publishing, Inc. </div> </div></div></div> </div><a data-type="pageEnd" name="PageEnd_148" data-page="148"></a><div class="pageSection" id="FRVM57238DQX1EHVA347" id-sequence="18"> <div class="learningObjectives" id="MMTHC6LP839CG8DV6926" id-sequence="19"><div class="containerHeading"><h3 id="QZGJ0CF3KLEU0T0L3286" id-sequence="20">Learning Objectives</h3></div><ol class="decimal learnObjList" id="MMTHC6LP839CG8DV6926" id-sequence="21"> <li class="learnObj" id="PVJUQRE6GQDZMM755789" id-sequence="22">Explain the basic concepts of sensation and perception, including transduction of stimuli into neural signals, distinctions between bottom-up and top-down perceptual processing, thresholds, and measurement.</li> <li class="learnObj" id="AMTMZURD9MKY3JH0V190" id-sequence="23">Identify the process by which the physical structures of the eye transduce light waves into neural signals, producing the sense of vision.</li> <li class="learnObj" id="BLTF92WNDYNNE6T74793" id-sequence="24">Summarize the processes responsible for color vision, object recognition, and depth perception.</li> <li class="learnObj" id="BHSMXJYPV537RAG1D419" id-sequence="25">Describe the process by which physical structures of the ear transduce sound waves into neural signals, producing perception of pitch, loudness, and spatial location in hearing.</li> <li class="learnObj" id="DUTJ5GKNEPYFKN09B801" id-sequence="26">Explain the mechanisms by which the somatosensory and chemical sense systems produce perception of body position, touch, skin temperature, pain, smell, and taste.</li> <li class="learnObj" id="UDTQHA5PC49GH0MZW418" id-sequence="27">Analyze the causes of various individual differences in perception, including development and culture, in terms of biology, experience, and their interaction.</li> </ol></div> </div><div class="pageSection" id="VQZVM384S3Q5Y6EKH014" id-sequence="28"> <p id="QQQRFNHXCF2HSJYVX150" id-sequence="29">We like to think we understand reality. After all, we can see, hear, touch, smell, and taste it. We don’t live in some science fiction universe where things are not how they appear. Or do we?</p> <p id="PCDWPMPVFRXVEUT19665" id-sequence="30">The human eye can see many different colors, but what does it mean to “see” a color? Is color something that is a fixed quality of an object? Is the sky really blue? Is an apple really red? Or does the human mind construct these colors from the light reflected from these objects into the eye? Consider the image of the blue/black or white/gold dress that became an Internet sensation in February 2015. A friend of a Scottish bride posted the dress worn by the bride’s mother on her Tumblr blog, leading to a discussion that engaged everyone from Justin Bieber to esteemed neuroscientists. Why do people see this photo so differently?</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14ca rs_skip" id="MJVQ708DJ22BP6BVT739" clrenderdata="[&quot;KTQM2ETYB584LE9TR922&quot;]" id-sequence="31"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf01-t2.jpg" data-width="220" data-height="276" data-alt="A photo of a woman wearing a blue dress."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="TLZNJFR40TLWS6P9P026" id-sequence="32"><p>“The Dress” became an Internet phenomenon as people debated its true colors. Do you see it as black and blue? White and gold? Something else?</p></div> <div class="imageContainer" style="width:220px;height:276px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf01-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A photo of a woman wearing a blue dress." width="220" height="276" class="rs_skip"></div><div class="mediaCredit">Laura Freberg </div> </div></div></div> <p id="CRYP26P0XHWSGXBDL675" id-sequence="33">Neuroscientists disagree about why the dress produced such different responses. The <em>Journal of Vision</em> prepared an entire issue (“A Dress Rehearsal for Vision Science”) devoted to explaining the dress phenomenon. A survey of 1,400 people found that 57% described the dress as blue/black (which is correct), 30% as white/gold, 11% as blue/brown, and 2% as something else (Lafer-Sousa, Hermann, &amp; Conway, 2015). Older individuals and women were more likely to choose white/gold. These researchers believe<a data-type="pageEnd" name="PageEnd_149" data-page="149"></a> that people choose dress colors based on their expectations regarding the lighting. If you think the dress is seen in daylight, you make different conclusions than if you think the dress is seen under artificial light.</p> <p id="AGDX3E6AS7AKERDLD891" id-sequence="34">Other scientists believe there is something special about the color blue due to our considerable experience with natural lighting (<span class="citation" id="RBYJY31GCJKQSETKN593" id-sequence="35">Winkler, Spillmann, Werner, &amp; Webster, 2015</span>). Because indirect lighting and shadows are usually blue, participants are more likely to confuse blue objects with blue lighting. If you assume the light falling on the dress is somewhat blue, you will probably see it as white.</p> <p id="YSLRF9TGUC55KPEWL280" id-sequence="36">Would having a color deficiency change the way a person sees the dress? See for yourself. We can reconstruct how the image would look to a person with a rare type of blue-yellow color deficiency (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="QNRN7167MB8QCZN81734" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="UYJZ78E8L7BRBKCDJ954" data-element-id="QNRN7167MB8QCZN81734">Figure 5.1</a>). Surprisingly, this has little effect, although the blue looks somewhat gray. Is the reality seen by a person with a color deficiency different from your reality? We’re going to argue that it is not reality that changes but rather the way the brain views that reality.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14cb rs_skip" id="JADEXYV5JG3VQX2VP270" clrenderdata="[&quot;WLCP6SCDVPNPCK1QM686&quot;]" id-sequence="37"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf02-t2.jpg" data-width="407" data-height="277" data-alt="A photo of a woman wearing a blue dress shown two time - one on the left is the original image and the one on the right is a tritanope simulation. It has a pink cast on the woman’s bare arms."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="UFYZT1UE62LJWY0DL953" id-sequence="38"><p>“Tritanopes” have a rare type of blue-yellow color deficiency. We can simulate how the mysterious dress would look to a tritanope. The differences are surprisingly subtle, which explains why we use the term “color deficiency” rather than “colorblindness.” This example also reminds us that a single reality (the dress) can be sensed and perceived very differently by individual minds.</p></div> <div class="imageContainer" style="width:407px;height:277px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf02-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A photo of a woman wearing a blue dress shown two time - one on the left is the original image and the one on the right is a tritanope simulation. It has a pink cast on the woman’s bare arms." width="407" height="277" class="rs_skip"></div><div class="mediaCredit">Cecilia Bleasdale/Wikipedia </div> </div></div></div> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14cc rs_skip" id="QNRN7167MB8QCZN81734" clrenderdata="[&quot;BPWX4289JF07V2QQK291&quot;]" id-sequence="39"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f01-t3.png" data-width="642" data-height="597"></div><div class="metadata inlineImage" data-filename="61815_05_f01-t2.png" data-width="595" data-height="553" data-alt="A pair of photos at the top show a dog looking at a ball. The photograph on the left is human’s view and that on the right is dog’s view. The photo on the left is colorful while that on the right shows only blues, yellows, and grays. A ribbon below the photos shows different kinds of rays that are categorized into parts based on wavelength in meters. The rays indicated from left to right are cosmic rays, gamma rays, X rays, ultraviolet rays, visible rays, infrared, microwave radar, T V F M Ay M Radio waves, and short waves. The visible rays, in the wavelength of 10 power negative 6, are enlarged into two ribbons below, one denoting human’s view and the other denoting dog’s view. In human’s view, seven colors, violet, indigo, blue, green, yellow, orange, and red, are visible. In dog’s view, only gray, blue, and yellow are visible."></div><div class="nb_media image wide"><div class="mediaTitle" id="BXHDAU4QF3ZAYVEEX269" id-sequence="40"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.1</span></span><span class="mediaAssetTitle">All Species Experience an Adaptive Reality.</span></div><div class="mediaDescription" id="NBFFWK8WTRVHXZB4V527" id-sequence="41"><p>Humans see only a small part of the electromagnetic energy emitted from the Sun. Some animals see even less. Dogs apparently do fine seeing blues, yellows, and grays, whereas humans have evolved to see a more colorful world. The dog’s view of the world is simulated in the photo on the right.</p></div> <div class="imageContainer" style="width:595px;height:553px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f01-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A pair of photos at the top show a dog looking at a ball. The photograph on the left is human’s view and that on the right is dog’s view. The photo on the left is colorful while that on the right shows only blues, yellows, and grays. A ribbon below the photos shows different kinds of rays that are categorized into parts based on wavelength in meters. The rays indicated from left to right are cosmic rays, gamma rays, X rays, ultraviolet rays, visible rays, infrared, microwave radar, T V F M Ay M Radio waves, and short waves. The visible rays, in the wavelength of 10 power negative 6, are enlarged into two ribbons below, one denoting human’s view and the other denoting dog’s view. In human’s view, seven colors, violet, indigo, blue, green, yellow, orange, and red, are visible. In dog’s view, only gray, blue, and yellow are visible." width="595" height="553" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Leah Warkentin/AGE Fotostock </div> </div></div></div> <p id="JPWJXSQEMSCA20FJ1256" id-sequence="42">As you’ll see in this chapter, we construct models of reality from the information obtained through our senses. We like to think that we are aware of the world around us, and it is unsettling to realize that the world might be different from the representations of reality formed by the human mind. You will learn how the models built by the human mind have promoted our survival over many generations. Our models of reality are distinct from those built by the minds of other animals, whose survival depends on obtaining different types of information from their environments.</p> </div><div class="footnotes"></div></div><div id="footer" id-sequence="43"></div></div><div class="container page "><div id="header" id-sequence="46"><div id="breadcrumb-old" id-sequence="47" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="48" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h1 id="TSHX224UVAEPMDEQ2366" id-sequence="49"><span class="sectionLabel rs_skip">5-1</span> <span class="headingText">How Does Sensation Lead to Perception?</span></h1></div><div class="content" id="RWBZ2VMJFBPF7NTWA025_content" id-sequence="50"> <p id="MLUGSMZYSR45ETKKG279" id-sequence="51">Our bodies are bombarded with information during wakefulness and sleep. This information takes many forms, from the electromagnetic energy of the sun to vibrations in the air to molecules dissolved in saliva on our tongues. The process of <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f77" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f77"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f77" id="TQGSZS5SAWRSJ8M12525" id-sequence="52"><span class="index nb_hidden clAnnotationDecoration rs_skip">sensation</span><span class="term"><span class="primaryTerm" id="QUFK0G7CM8LXRTBDD255" id-sequence="53">sensation</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The process of detecting environmental stimuli or stimuli arising from the body.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f77">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="QUFK0G7CM8LXRTBDD255" id-sequence="53">sensation</span></span>
        <span class="definition rs_skip">The process of detecting environmental stimuli or stimuli arising from the body.</span>
        <span class="pointer"></span>
    </span>
</span> brings information to the brain that arises in the reality outside our bodies, like a beautiful sunset, or originates from within, like an upset stomach.</p> <p id="JYLJK0Z5VP90SW2R2056" id-sequence="54">Sensory systems have been shaped by natural selection, described in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="TPPAPQFA7W5XFGWW3455" data-chapter-id="TPPAPQFA7W5XFGWW3455" data-element-id="TPPAPQFA7W5XFGWW3455">Chapter 3</a>, to provide information that enhances survival within a particular niche. We sense a uniquely human reality, and one that is not shared by other animals. Your dog howls seconds before you hear the siren from an approaching ambulance because the dog’s hearing is better than yours for high-pitched sounds. Horses bolt at the slightest provocation, but they may be reacting to the vibration of an approaching car or an animal that they sense through their front hooves, a source of information that is not available to the rider. Some animals sense light energy outside the human visible spectrum. Insects can see ultraviolet light, and some snakes use infrared energy to detect their prey.</p> <p id="MLNC25JA99M0TYZ4A076" id-sequence="55">Differences in sensation do occur from person to person, such as the need to wear corrective glasses or not, but they are relatively subtle. However, once we move from the process of sensation to that of <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f78" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f78"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f78" id="JWTW06KWE5EBYZYD3793" id-sequence="56"><span class="index nb_hidden clAnnotationDecoration rs_skip">perception</span><span class="term"><span class="primaryTerm" id="YJFXADFXU9JD1J4L8657" id-sequence="57">perception</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The process of interpreting sensory information.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f78">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="YJFXADFXU9JD1J4L8657" id-sequence="57">perception</span></span>
        <span class="definition rs_skip">The process of interpreting sensory information.</span>
        <span class="pointer"></span>
    </span>
</span>, or the interpretation of sensory input, individual differences become more evident. For example, friends voting for different presidential candidates will come to different conclusions about who won a debate. Everyone watching the exchange sensed similar information, but each person’s perceptions are unique.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14cd rs_skip" id="ZDUK7YR8T92KVPTQX563" clrenderdata="[&quot;GFZPVPKEMRMA06BVV741&quot;]" id-sequence="58"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf03-t2.jpg" data-width="307" data-height="221" data-alt="A photo of a rodent that seems aglow at night."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="FRDDA5TBVABUKNFPK043" id-sequence="59"><p>Some types of snakes (vipers, boas, and pythons) can sense prey using infrared energy.</p></div> <div class="imageContainer" style="width:307px;height:221px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf03-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A photo of a rodent that seems aglow at night." width="307" height="221" class="rs_skip"></div><div class="mediaCredit">Ted Kinsman/Science Source </div> </div></div></div> <a data-type="pageEnd" name="PageEnd_150" data-page="150"></a> <div class="footnotes"></div></div><div id="footer" id-sequence="60"></div></div><div class="container page "><div id="header" id-sequence="63"><div id="breadcrumb-old" id-sequence="64" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="65" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="YRRMCGMP25P1KVRPK780" id-sequence="66"><span class="sectionLabel rs_skip">5-1a</span> <span class="headingText">Sensory Information Travels to the Brain</span></h2></div><div class="content" id="MKRCVFCG9TRPCE02Y171_content" id-sequence="67"> <p id="BTHB641XTGK18X6HG838" id-sequence="68">Sensation begins with the interaction between a physical stimulus and our biological sensory systems. A stimulus is anything that elicits a reaction from our sensory systems. For example, we react to light energy that falls within our visual range, as we will see later in this chapter, but we cannot see light energy that falls outside that range, such as the microwaves that cook our dinner or the ultraviolet waves that harm our skin (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="QNRN7167MB8QCZN81734" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="UYJZ78E8L7BRBKCDJ954" data-element-id="QNRN7167MB8QCZN81734">Figure 5.1</a>).</p> <p id="CRBRN7R1KJ78209BN460" id-sequence="69">Before you can use information from your senses, it must be translated into a form the nervous system can understand. This process of translation from stimulus to neural signal is known as <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f79" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f79"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f79" id="ZWFYVXLM2STSP9T8V835" id-sequence="70"><span class="index nb_hidden clAnnotationDecoration rs_skip">transduction</span><span class="term"><span class="primaryTerm" id="KATLEHSLSJBRRGMJF530" id-sequence="71">transduction</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The translation of incoming sensory information into neural signals.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f79">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="KATLEHSLSJBRRGMJF530" id-sequence="71">transduction</span></span>
        <span class="definition rs_skip">The translation of incoming sensory information into neural signals.</span>
        <span class="pointer"></span>
    </span>
</span>. You might think of sensory transduction as being similar to the processing of information by your computer. Modern computers transduce a variety of inputs, including voice, keyboard, mouse clicks, and touch, into a programming language for further processing.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14ce rs_skip" id="FAWGJ75E1PGZ98QT0345" clrenderdata="[&quot;LYVTZPNG2P6B4EQYW967&quot;]" id-sequence="72"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf04-t2.jpg" data-width="483" data-height="325" data-alt="A football referee making a point to four players."></div><div class="nb_media image unnumbered wide"><div class="mediaDescription" id="ZGCSQLTPJ3PMBRS8B432" id-sequence="73"><p>We have all had the experience of watching events with others (sensation) and then being shocked by the different interpretations we hear of what just happened (perception).</p></div> <div class="imageContainer" style="width:483px;height:325px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf04-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A football referee making a point to four players." width="483" height="325" class="rs_skip"></div><div class="mediaCredit">AP Images/Roberto Pfeil </div> </div></div></div><a data-type="pageEnd" name="PageEnd_151" data-page="151"></a> <div class="footnotes"></div></div><div id="footer" id-sequence="74"></div></div><div class="container page "><div id="header" id-sequence="77"><div id="breadcrumb-old" id-sequence="78" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="79" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="CXDTBFHS2JNDW5KX3043" id-sequence="80"><span class="sectionLabel rs_skip">5-1b</span> <span class="headingText">The Brain Constructs Perceptions from Sensory Information</span></h2></div><div class="content" id="ACBSMC64UAN6PC2LT376_content" id-sequence="81"> <p id="NKPLW1VDLQP88XGES900" id-sequence="82">Once information from the sensory systems has been transduced into neural signals and sent to the brain, the process of perception, or the interpretation of the sensory information, begins. Perception allows us to organize, recognize, and use the information provided by the senses.</p> <div class="container dependent margin narrative  rs_skip" id="KKCWGBSWZ6UKBVNPW312" id-sequence="83"><div class="sidebarContent" id="KKCWGBSWZ6UKBVNPW312_sidebarcontent" id-sequence="84"> <p id="YZPSN59CU9837R3QK635" id-sequence="85">If you think about the most memorable advertisements you have seen lately on television or online, it is likely that they share the features of attention-getting stimuli: novelty (we don’t see talking geckos every day), change (rapid movement, use of changing colors, and the dreaded pop-up), and intensity (the sound is often louder than the program you’re watching).</p> </div></div> <p id="LMUKJJ30BSFT1RWLB306" id-sequence="86">An important gateway to perception is the process of attention, defined as a narrow focus of consciousness. As we discuss in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="MQJZJ4JJN52VRSCZ7957" data-chapter-id="MQJZJ4JJN52VRSCZ7957" data-element-id="MQJZJ4JJN52VRSCZ7957">Chapters 6</a>, <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="BZTD4SLT399WRK8ST946" data-chapter-id="BZTD4SLT399WRK8ST946" data-element-id="BZTD4SLT399WRK8ST946">9</a>, and <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="PWZAN7SUG6TWKKB67880" data-chapter-id="PWZAN7SUG6TWKKB67880" data-element-id="PWZAN7SUG6TWKKB67880">10</a>, attention often determines which features of the environment influence our subsequent thoughts and behaviors. Which stimuli are likely to grab our attention? Unfamiliar, changing, or high-intensity stimuli often affect our survival and have a high priority for our attention. Unfamiliar stimuli in our ancestors’ environment might have meant a new source of danger (an unknown predator) or a new source of food (an unfamiliar fruit) that warranted additional investigation. Our sensory systems are particularly sensitive to change in the environment. Notice how you pay attention to the sound of your heating system cycling on or off but pay little attention to the noise it makes while running. This reduced response to an unchanging stimulus is known as <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f7a" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f7a"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f7a" id="DFFXV5TK93W67DJ4G224" id-sequence="87"><span class="index nb_hidden clAnnotationDecoration rs_skip">sensory adaptation</span><span class="term"><span class="primaryTerm" id="CAAPDFHSGVPA0VRL8970" id-sequence="88">sensory adaptation</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The tendency to pay less attention to a nonchanging source of stimulation.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f7a">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="CAAPDFHSGVPA0VRL8970" id-sequence="88">sensory adaptation</span></span>
        <span class="definition rs_skip">The tendency to pay less attention to a nonchanging source of stimulation.</span>
        <span class="pointer"></span>
    </span>
</span>. High-intensity stimuli, such as bright lights and loud noises, draw our attention because the situations that produce these stimuli, such as a nearby explosion, can have obvious consequences for our safety.</p> <p id="XKQJTNWCHLKXTGMF6069" id-sequence="89">We rarely have the luxury of paying attention to any single stimulus. In most cases, we experience divided attention, in which we attempt to process multiple sources of sensory information. Students walk to class without getting run over by a car while texting. These divided attention abilities are limited. We simply cannot process all the information converging simultaneously on our sensory systems. To prioritize input, we use selective attention or the ability to focus on a subset of available information and exclude the rest. These abilities may be disrupted in cases of attention deficit hyperactivity disorder (ADHD; <span class="citation" id="CRBXDBXJX68LB81K8202" id-sequence="90"> Wimmer et al., 2015</span>; also see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="KNKVM7TED147CWT15523" data-chapter-id="KNKVM7TED147CWT15523" data-element-id="KNKVM7TED147CWT15523">Chapter 14</a>).</p> <p id="EGHVF7VVYBS81K06X624" id-sequence="91">We refer to the brain’s use of incoming signals to construct perceptions as <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f7b" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f7b"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f7b" id="NXYUUC28Z4FZEZMKQ551" id-sequence="92"><span class="index nb_hidden clAnnotationDecoration rs_skip">bottom-up processing</span><span class="term"><span class="primaryTerm" id="PPYRSNERMRGE95MTQ639" id-sequence="93">bottom-up processing</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Perception based on building simple input into more complex perceptions</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f7b">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="PPYRSNERMRGE95MTQ639" id-sequence="93">bottom-up processing</span></span>
        <span class="definition rs_skip">Perception based on building simple input into more complex perceptions</span>
        <span class="pointer"></span>
    </span>
</span>. For example, we construct our visual reality from information about light that is sent from the eye to the brain. However, the brain also imposes a structure on the incoming information, a type of processing known as top-down. In <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f7c" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f7c"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f7c" id="SJPBW380161NBNF9D960" id-sequence="94"><span class="index nb_hidden clAnnotationDecoration rs_skip">top-down processing</span><span class="term"><span class="primaryTerm" id="TDGDFHPLNS0HM3BKR365" id-sequence="95">top-down processing</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A perceptual process in which memory and other cognitive processes are required for interpreting incoming sensory information</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f7c">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="TDGDFHPLNS0HM3BKR365" id-sequence="95">top-down processing</span></span>
        <span class="definition rs_skip">A perceptual process in which memory and other cognitive processes are required for interpreting incoming sensory information</span>
        <span class="pointer"></span>
    </span>
</span>, we use knowledge gained from prior experience with stimuli to perceive them. For example, a skilled reader has no trouble reading the following sentences, even though the words are jumbled:</p> <p id="FMEH5UF1KH3EY43WE574" id-sequence="96">All you hvae to do to mkae a snetnece raedalbe is to mkae srue taht the fisrt and lsat letrtes of ecah wrod saty the smae. Wtih prcatcie, tihs porcses becoems mcuh fsater and esaeir.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14cf rs_skip" id="LDRTHPPBHA8Z5RAWW720" clrenderdata="[&quot;LZLUDGWX4VJJ9U997716&quot;]" id-sequence="97"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf05-t2.jpg" data-width="576" data-height="360" data-alt="Divided attention abilities are limited. Some people believe that heads-up displays for cars assist drivers with divided attention, while others believe the displays are too distracting."></div><div class="nb_media image unnumbered wide"><div class="mediaDescription" id="AZXSEVG1N7B0NY3Y1381" id-sequence="98"><p>Divided attention abilities are limited. Some people believe that heads-up displays for cars assist drivers with divided attention, while others believe the displays are too distracting.</p></div> <div class="imageContainer" style="width:576px;height:360px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf05-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Divided attention abilities are limited. Some people believe that heads-up displays for cars assist drivers with divided attention, while others believe the displays are too distracting." width="576" height="360" class="rs_skip"></div><div class="mediaCredit">chombosan/ <a target="_blank" id="BFQFP68ZGKZKVUZAY295" name="BFQFP68ZGKZKVUZAY295" class="external" href="http://Shutterstock.com" id-sequence="99">Shutterstock.com</a></div> </div></div></div><a data-type="pageEnd" name="PageEnd_152" data-page="152"></a> <p id="RVBK0NF8Z93LT5ZCH248" id-sequence="100">How can we explain our ability to read these sentences? First, we require bottom-up processing to bring the sensations of the letter shapes to our brain. From there, however, we use knowledge and experience to recognize individual words. Many students have learned the hard way that term papers must be proofread carefully. As in our example, if the brain expects to see a particular word, you are likely to see that word, even if it is misspelled, a mistake that is unlikely to be made by the literal, bottom-up processing of a computer spell-checker.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d0 rs_skip" id="HZLSZBESRJDMR382Y117" clrenderdata="[&quot;QTNLL25XHS3GWZYA7155&quot;]" id-sequence="101"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf06-t2.jpg" data-width="309" data-height="226" data-alt="A photo of a scan of the lungs on which the image of a gorilla is superimposed."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="GCLMQ6QZ11RP3X5EU618" id-sequence="102"><p>Selective attention, or our focus on a subset of input, prioritizes incoming information. However, we can sometimes be so focused that we miss important information. An astonishing 20 out of 24 expert radiologists completely missed the image of a gorilla superimposed on scans of lungs while scanning for signs of cancer.</p></div> <div class="imageContainer" style="width:309px;height:226px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf06-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A photo of a scan of the lungs on which the image of a gorilla is superimposed." width="309" height="226" class="rs_skip"></div><div class="mediaCredit">skyhawk x/ <a target="_blank" id="LLFEX0RDHM14LPD2M035" name="LLFEX0RDHM14LPD2M035" class="external" href="http://Shutterstock.com" id-sequence="103">Shutterstock.com</a><em>Source:</em> T. Drew, T., M. L.-H. Võ, &amp; J. M. <span class="citation" id="ZJDPAZQUTQ6MRSRJ1393" id-sequence="104"> Wolfe (2013)</span>. “The Invisible Gorilla Strikes Again: Sustained Inattentional Blindness in Expert Observers,” <em>Psychological Science</em>, 24(9), 1848–1853. doi: 10.1177/0956797613479386 </div> </div></div></div> <p id="SVXNB4EGW8CFDG3DL964" id-sequence="105">Can we predict when the mind will use bottom-up or top-down processing? There are no hard and fast rules. Obviously, we always use bottom-up processing, or the information would not be perceived. It is possible that bottom-up processing alone allows us to respond appropriately to simple stimuli, like indicating whether you saw a flash of light. As stimuli become more complicated, like reading a sentence or recognizing a friend in a crowd, we are more likely to engage in top-down processing in addition to bottom-up processing.</p> <div class="pageSection" id="AKAXUUT0KG9JL5VKY277" id-sequence="106"> <h3 id="UFPQ4766HCTR5Y72K540" id-sequence="107"><span class="headingText">Measuring Perception</span></h3> <p id="RPAX8ES03XCDDD3R2565" id-sequence="108">Gustav Fechner (1801–1887) developed methods, which he called <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f7d" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f7d"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f7d" id="ELEKSXD0YXQK36SGQ936" id-sequence="109"><span class="index nb_hidden clAnnotationDecoration rs_skip">psychophysics</span><span class="term"><span class="primaryTerm" id="BPZHZN83VAW2UDTR5764" id-sequence="110">psychophysics</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The study of relationships between the physical qualities of stimuli and the subjective responses they produce.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f7d">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="BPZHZN83VAW2UDTR5764" id-sequence="110">psychophysics</span></span>
        <span class="definition rs_skip">The study of relationships between the physical qualities of stimuli and the subjective responses they produce.</span>
        <span class="pointer"></span>
    </span>
</span>, for studying the relationships between stimuli (the physics part) and perception of those stimuli (the psyche or mind part) (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="BTRGKHX059315U2KW848" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="ACBSMC64UAN6PC2LT376" data-element-id="BTRGKHX059315U2KW848">Figure 5.2</a>). Fechner’s careful methods not only contributed to the establishment of psychology as a true science but are still used in research today.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d1 rs_skip" id="BTRGKHX059315U2KW848" clrenderdata="[&quot;DLPP2QJP6JDYBFVYK654&quot;]" id-sequence="111"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f02-t3.png" data-width="668" data-height="295"></div><div class="metadata inlineImage" data-filename="61815_05_f02-t2.png" data-width="595" data-height="256" data-alt="A photo of Gustav Fechner on the right and a graph on the left. Along the X axis of the graph rectangles of many sizes are arranged. On the Y axis is the percent of choices. The rectangle at which the graph for most pleasing peaks (35%) is the same as the rectangle where the graph for least pleasing drops (0%). This is the golden triangle, the fourth triangle from the right."></div><div class="nb_media image wide"><div class="mediaTitle" id="ZQEU5EUBJ353DCYRU222" id-sequence="112"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.2</span></span><span class="mediaAssetTitle">Connecting the Physical World and the Mind.</span></div><div class="mediaDescription" id="VVXHK30U9R6SRS7B2207" id-sequence="113"><p>“Golden” rectangles, named for their proportions rather than color, appear in art and architecture dating back to ancient Greece, but why are they attractive? Gustav Fechner (1801–1887) made many attempts to link physical realities with human psychological responses. He asked people to choose which rectangles are most pleasing or least pleasing. His results indicated that the most pleasing rectangle was fourth from the right. This rectangle is the closest to having golden proportions (1:1.618). Its sides have a ratio of 13:21.</p></div> <div class="imageContainer" style="width:595px;height:256px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f02-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A photo of Gustav Fechner on the right and a graph on the left. Along the X axis of the graph rectangles of many sizes are arranged. On the Y axis is the percent of choices. The rectangle at which the graph for most pleasing peaks (35%) is the same as the rectangle where the graph for least pleasing drops (0%). This is the golden triangle, the fourth triangle from the right." width="595" height="256" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Photo Researchers, Inc/Alamy Stock Photo </div> </div></div></div> <p id="XJFYYWY2BBC4K4B7P431" id-sequence="114">The methods of psychophysics allow us to establish the limits of awareness, or thresholds, for each of our sensory systems. The smallest possible stimulus that can be detected at least 50% of the time is known as the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f7e" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f7e"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f7e" id="QEMQL1RXRW6SAVW88103" id-sequence="115"><span class="index nb_hidden clAnnotationDecoration rs_skip">absolute threshold</span><span class="term"><span class="primaryTerm" id="PGUNHK8WFDNPDL1QT096" id-sequence="116">absolute threshold</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The smallest amount of stimulus that can be detected.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f7e">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="PGUNHK8WFDNPDL1QT096" id-sequence="116">absolute threshold</span></span>
        <span class="definition rs_skip">The smallest amount of stimulus that can be detected.</span>
        <span class="pointer"></span>
    </span>
</span>. Under ideal circumstances, our senses are surprisingly sensitive (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="EXUELD99HQ52R4U09754" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="ACBSMC64UAN6PC2LT376" data-element-id="EXUELD99HQ52R4U09754">Figure 5.3</a>). For example, you can see the equivalent of a candle flame 30 miles (about 48 kilometers) away on a moonless night. We can also establish a <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f7f" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f7f"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f7f" id="WESD8QEFYQ6GYNB4Y391" id-sequence="117"><span class="index nb_hidden clAnnotationDecoration rs_skip">difference threshold</span><span class="term"><span class="primaryTerm" id="DCTNZYS5VU80W7Z3Q400" id-sequence="118">difference threshold</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The smallest detectable difference between two stimuli.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f7f">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="DCTNZYS5VU80W7Z3Q400" id-sequence="118">difference threshold</span></span>
        <span class="definition rs_skip">The smallest detectable difference between two stimuli.</span>
        <span class="pointer"></span>
    </span>
</span>, or the smallest difference between two stimuli that can be detected at least 50% of the time. The amount of difference that can be detected depends on the size of the stimuli being compared. As stimuli get larger, differences must also become larger to be detected by an observer.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d2 rs_skip" id="EXUELD99HQ52R4U09754" clrenderdata="[&quot;NRDW3ABZK350DXVCT943&quot;]" id-sequence="119"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f03-t3.png" data-width="633" data-height="324"></div><div class="metadata inlineImage" data-filename="61815_05_f03-t2.png" data-width="595" data-height="304" data-alt="A photo of a woman with all the sense organs shown with lines of different colors and styles. On her hand is a fly. The picture of the fly is enlarged on the right. The woman’s sense of smell is indicated with an enlarged image of a perfume bottle being sprayed on a wrist, on the right."></div><div class="nb_media image wide"><div class="mediaTitle" id="KVAULA6YB9VJAVURB435" id-sequence="120"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.3</span></span><span class="mediaAssetTitle">Absolute Sensory Thresholds.</span></div><div class="mediaDescription" id="XQPD6ZUCW1KYCQETM479" id-sequence="121"><p>An absolute threshold is the smallest amount of sensation that can be processed by our sensory systems under ideal conditions. Moving from left to right in this image, we see that the absolute threshold for touch is the equivalent of feeling the wing of a fly fall on your cheek from a distance of 0.4 inch (about 1 centimeter), the absolute threshold for olfaction is a drop of perfume in the air filling a six-room apartment, the absolute threshold for sweetness is the equivalent of one teaspoon (about 5 grams) of sugar in two gallons (about 7.5 liters) of water (the absolute threshold for bitter tastes is even more sensitive), the absolute threshold for hearing is the equivalent of the sound of a mosquito 10 feet (about 3 meters) away, and the absolute threshold for vision is seeing a candle flame 30 miles (about 48 kilometers) away on a dark, clear night.</p></div> <div class="imageContainer" style="width:595px;height:304px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f03-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A photo of a woman with all the sense organs shown with lines of different colors and styles. On her hand is a fly. The picture of the fly is enlarged on the right. The woman’s sense of smell is indicated with an enlarged image of a perfume bottle being sprayed on a wrist, on the right." width="595" height="304" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Photos, left to right: Gladskikh Tatiana/ <a target="_blank" id="SPFGM89NR927P97YW945" name="SPFGM89NR927P97YW945" class="external" href="http://Shutterstock.com" id-sequence="122">Shutterstock.com</a>; Kuttelvaserova Stuchelova/ <a target="_blank" id="JRPCKGJXA4HCXDYNN902" name="JRPCKGJXA4HCXDYNN902" class="external" href="http://Shutterstock.com" id-sequence="123">Shutterstock.com</a>; Christopher Elwell/ <a target="_blank" id="MKKT3SZWM06WF3TNH476" name="MKKT3SZWM06WF3TNH476" class="external" href="http://Shutterstock.com" id-sequence="124">Shutterstock.com</a>; AlexRoz/ <a target="_blank" id="ZQQGYU5LB9T6L67SQ909" name="ZQQGYU5LB9T6L67SQ909" class="external" href="http://Shutterstock.com" id-sequence="125">Shutterstock.com</a>. </div> </div></div></div> </div> <div class="pageSection" id="SASU2PKEJB3PM1GVJ356" id-sequence="126"> <h3 id="JNAPV6TPJDKPHW5WA607" id-sequence="127"><span class="headingText">Signal Detection</span></h3> <div class="container dependent margin narrative  rs_skip" id="JYLKR0D1YY0J8GUNZ559" id-sequence="128"><div class="sidebarContent" id="JYLKR0D1YY0J8GUNZ559_sidebarcontent" id-sequence="129"> <p id="HUCGJ9C7X0ZQXSUZZ453" id-sequence="130">Another example of signal detection is a jury’s decision about whether a person is guilty. Based on frequently uncertain and conflicting evidence, jurors must weigh their concerns about convicting an innocent person (false alarm) or letting a real criminal go (miss).</p> </div></div> <p id="FMZFJ13XECALM8FSH868" id-sequence="131">Many perceptions involve some uncertainty. Perhaps you’re driving rather fast, and you think a distant car behind you might be a police officer. Do you slow down right away? Or do you wait until the car is close enough that you know for sure it’s a police officer? How do your personal feelings about making mistakes affect your decision? Would the cost of a ticket ruin your budget?</p> <a data-type="pageEnd" name="PageEnd_153" data-page="153"></a> <p id="XDQYKDTU6H0C3BNFL702" id-sequence="132">This type of decision making can have serious implications, such as in the case of decisions made by radiologists examining the results of mammograms for signs of cancer or by intelligence officers assessing the possibility of an attack. Is there reason for concern or not? This situation is different from the thresholds described earlier because it adds the cognitive process of decision making to the process of sensation. In other words, <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f80" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f80"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f80" id="MTNJ42Z7SEXEAWDE9511" id-sequence="133"><span class="index nb_hidden clAnnotationDecoration rs_skip">signal detection</span><span class="term"><span class="primaryTerm" id="MBUD9Y2LCW11RQB87094" id-sequence="134">signal detection</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The analysis of sensory and decision-making processes in the detection of faint, uncertain stimuli.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f80">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="MBUD9Y2LCW11RQB87094" id-sequence="134">signal detection</span></span>
        <span class="definition rs_skip">The analysis of sensory and decision-making processes in the detection of faint, uncertain stimuli.</span>
        <span class="pointer"></span>
    </span>
</span> is a two-step process involving </p><ul class="custom" id="URKEY37N2QM0KA8BA760" id-sequence="135"> <li id="FHSSQU9890DYNN4NB914" id-sequence="136"><span class="manualLabel" char="3">(a)</span><p id="RHVEQHXQ4KSPL4KTY438" id-sequence="137">the actual intensity of the stimulus, which influences the observer’s belief that the stimulus did occur, and</p></li> <li id="ACANDPTAB31U4BTVF516" id-sequence="138"><span class="manualLabel" char="3">(b)</span><p id="SBRA7R8E00NANCU03344" id-sequence="139">the individual observer’s criteria for deciding whether the stimulus occurred.</p></li> </ul> <p id="WZNEMC3T4E6F7MGY8494" id-sequence="140">Experiments on signal detection provide insight into this type of decision making. In these experiments, trials with a single, faint stimulus and trials with no stimulus are presented randomly. The participant states whether a stimulus was present on each trial. The possible outcomes of this experiment are shown in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="BWCZS6TS1K2W4DHGQ005" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="ACBSMC64UAN6PC2LT376" data-element-id="BWCZS6TS1K2W4DHGQ005">Table 5.1</a>. In the case of reading mammograms, we can use such experiments to help us understand why two people might respond differently, even if they were sensing the same information. Ideally, a radiologist would identify 100% of all tumors without any false alarms, but mammograms are not that easy to evaluate. A radiologist afraid of missing a tumor might identify anything that looks remotely like a tumor as the basis for more testing. Few cases of cancer would be missed (high hit rate), but many healthy patients would go through unnecessary procedures (high false alarm rate). In contrast, another radiologist might need a higher level of certainty about the presence of a tumor before asking for further tests. This would reduce the number of false alarms, but it would also run a higher risk of overlooking tumors (high miss rate).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d3 rs_skip" id="FMFEJSAEREW0PW4XZ463" clrenderdata="[&quot;UQTRCD280ZWC8V68M529&quot;]" id-sequence="141"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf07-t2.jpg" data-width="406" data-height="352" data-alt="According to Fechner’s work on the difference threshold, British Olympian Zoe Smith would be more likely to notice the difference between 2- and 4-pound (between 1 to 2 kilograms) weights than the difference between her new record of 121 kilograms (266.76 pounds) in the clean and jerk event and the former record of 120 kilograms (264.56 pounds)."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="UAXLNVB5VNHRLNJZJ325" id-sequence="142"><p>According to Fechner’s work on the difference threshold, British Olympian Zoe Smith would be more likely to notice the difference between 2- and 4-pound (between 1 to 2 kilograms) weights than the difference between her new record of 121 kilograms (266.76 pounds) in the clean and jerk event and the former record of 120 kilograms (264.56 pounds).</p></div> <div class="imageContainer" style="width:406px;height:352px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf07-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="According to Fechner’s work on the difference threshold, British Olympian Zoe Smith would be more likely to notice the difference between 2- and 4-pound (between 1 to 2 kilograms) weights than the difference between her new record of 121 kilograms (266.76 pounds) in the clean and jerk event and the former record of 120 kilograms (264.56 pounds)." width="406" height="352" class="rs_skip"></div><div class="mediaCredit">YURI CORTEZ/AFP/Getty Images/Newscom </div> </div></div></div> <a data-type="pageEnd" name="PageEnd_154" data-page="154"></a> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d4 rs_skip" id="VKEXYGXZSF97VL8CT615" clrenderdata="[&quot;FJMRA7G7U2727A8GF758&quot;]" id-sequence="143"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_unf08-t3.png" data-width="883" data-height="407"></div><div class="metadata inlineImage" data-filename="61815_05_unf08-t2.png" data-width="595" data-height="269" data-alt="A composite of three images. On the left is a spoonful of sugar and two jars of liquid. In the middle is a mosquito and on the right is a person holding a candle in the dark."></div><div class="nb_media image unnumbered wide"> <div class="imageContainer" style="width:595px;height:269px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf08-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A composite of three images. On the left is a spoonful of sugar and two jars of liquid. In the middle is a mosquito and on the right is a person holding a candle in the dark." width="595" height="269" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Photos, left to right: fotomak/ <a target="_blank" id="MTSS9XNUDZEFL23FM190" name="MTSS9XNUDZEFL23FM190" class="external" href="http://Shutterstock.com" id-sequence="144">Shutterstock.com</a>; seeyou/ <a target="_blank" id="AKLXU5Z2XUFQ1L25G462" name="AKLXU5Z2XUFQ1L25G462" class="external" href="http://Shutterstock.com" id-sequence="145">Shutterstock.com</a>; taedong/ <a target="_blank" id="ZZCZ8XYLEK3J1F04B366" name="ZZCZ8XYLEK3J1F04B366" class="external" href="http://Shutterstock.com" id-sequence="146">Shutterstock.com</a>; Karen H. Ilagan/ <a target="_blank" id="CHEGZVQ3DWRW1VBHD748" name="CHEGZVQ3DWRW1VBHD748" class="external" href="http://Shutterstock.com" id-sequence="147">Shutterstock.com</a>. </div> </div></div></div> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d5 rs_skip" id="RKAAFXXSEVMJWSDLC299" clrenderdata="[&quot;FYBJ19WF7KBS6AW9A540&quot;]" id-sequence="148"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf40-t2.jpg" data-width="585" data-height="382" data-alt="Two doctors looking at a scan report displayed on a computer."></div><div class="nb_media image unnumbered wide"><div class="mediaDescription" id="ZXQMCJD8PZZZJJHG7309" id-sequence="149"><p>Does this mammogram indicate the woman has cancer or not? Many decisions we make are based on ambiguous stimuli. Signal detection theory helps us understand how an individual doctor balances the risks of missing a cancer and those of alarming a healthy patient.</p></div> <div class="imageContainer" style="width:585px;height:382px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf40-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Two doctors looking at a scan report displayed on a computer." width="585" height="382" class="rs_skip"></div><div class="mediaCredit">BSIP/Getty Images </div> </div></div></div> <a data-type="pageEnd" name="PageEnd_155" data-page="155"></a> <div class="table rs_skip" id="BWCZS6TS1K2W4DHGQ005" id-sequence="150"><div class="containerHeading"><span class="label">Table <span class="ordinal">5.1</span></span><h3 id="HBSPW3NZRTYB3SY83103" id-sequence="151">Possible Outcomes in Signal Detection</h3></div> <div class="maintable narrowtable" style="height: auto;"><table data-width="360" class="frameall" style="width: 480px;"> <colgroup><col width="160"><col width="160"><col width="160"></colgroup> <thead> <tr id="AUYZ2WWVB5J39MP3W973" id-sequence="152"> <th id="WSWM98CM8T1NAK7AN757" class="alignleft valignbottom underscore" id-sequence="153"><p id="ZENNLXLQDXDF9P1R1973" id-sequence="154">Participant Response</p></th> <th id="DWLY4XUJWJDVQSP8C506" class="alignleft valignbottom underscore" id-sequence="155"><p id="YYQDWYR3WT0B2R9JB561" id-sequence="156">Stimulus Present</p></th> <th id="AKVZ2WKUGJ7QP08G4781" class="alignleft valignbottom underscore sidescore" id-sequence="157"><p id="XXZSJPU1LZ6M9M4WF578" id-sequence="158">Stimulus Absent</p></th> </tr> </thead> <tbody id="LHAB89ATMUT5XNUQH948" id-sequence="159"> <tr class="odd" id="HDPK76XPPA4PPEGFR316" id-sequence="160"> <td id="SUBR2DQQUK4EZA4YL649" class="alignleft valigntop" id-sequence="161"><p id="EXEGTPBUU3AL65CPL308" id-sequence="162">Yes</p></td> <td id="MNST2UD3TYTVLUK31116" class="alignleft valigntop" id-sequence="163"><p id="VNDHP5H9HPV2Q5DZ4386" id-sequence="164">Hit</p></td> <td id="CMREH3198LSY2SHAB194" class="alignleft valigntop sidescore" id-sequence="165"><p id="DYVRH78UW8P34GLV8020" id-sequence="166">False alarm</p></td> </tr> <tr class="even" id="WQVMPJZ5U10JJ8CSV184" id-sequence="167"> <td id="YYKU38RATS222MENQ005" class="alignleft valigntop underscore" id-sequence="168"><p id="WMTZ1EJPHF148BVX4690" id-sequence="169">No</p></td> <td id="MWEY7UPQEGNFU4ND4919" class="alignleft valigntop underscore" id-sequence="170"><p id="TZUQCF1VYYHXLAGXY239" id-sequence="171">Miss</p></td> <td id="BYTKYGYTA7QH70D0L350" class="alignleft valigntop sidescore underscore" id-sequence="172"><p id="BPLP47J1FPQ5AC1HX878" id-sequence="173">Correct rejection</p></td> </tr> </tbody> </table></div> </div> <div class="container dependent mt_summary narrative  rs_skip" id="XRGKPBBHDMNT2XA14378" label="summary" id-sequence="174"><div class="containerHeading"><span class="label">Summary <span class="ordinal">5.1</span></span><h3 id="CWLEVEU6U0SLZPNQK868" id-sequence="175">Assessing Perception</h3></div><div class="sidebarContent" id="XRGKPBBHDMNT2XA14378_sidebarcontent" id-sequence="176"> <div class="table rs_skip" id="AYAGHWB84AZ0GE64T659" id-sequence="177"> <div class="maintable narrowtable" style="height: auto;"><table data-width="450" class="frameall" style="width: 600px;"> <colgroup><col width="200"><col width="200"><col width="200"></colgroup> <thead> <tr id="GRME068HKJ0ZXNGX5587" id-sequence="178"> <th id="LSEZ19568H3VHGLAK708" class="alignleft valignbottom underscore" id-sequence="179"><p id="GGZRA8H97SB6ERCNZ903" id-sequence="180">Concept</p></th> <th id="RYTJJWSA6K8YMKRPK804" class="alignleft valignbottom underscore" id-sequence="181"><p id="LBYM1GC6UJCRR81SK894" id-sequence="182">Definition</p></th> <th id="JNYYC5YW3MXC9X7N2168" class="alignleft valignbottom underscore sidescore" id-sequence="183"><p id="GJSQ13D5V187GGV0E215" id-sequence="184">Example</p></th> </tr> </thead> <tbody id="MMFJ7CQ8C3NETB9BS043" id-sequence="185"> <tr class="odd" id="STGMRC3D5CW50JAEP260" id-sequence="186"> <td id="UMZZBKDSQ5D4D6PNT834" class="alignleft valigntop underscore" id-sequence="187"><p id="HVCPM1HYA8P9V5A7V758" id-sequence="188"><strong><em>Absolute threshold</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d6 rs_skip" id="PYQK7J0QPZZXJWNZE668" clrenderdata="[&quot;JGXFK55TS5HJXV6D2955&quot;]" id-sequence="189"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf09-t2.jpg" data-width="93" data-height="93" data-alt="Assessing Perception"></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:93px;height:93px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf09-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Assessing Perception" width="93" height="93" class="rs_skip"></div> </div></div></div></td> <td id="PWEGF2K9SBYWUKQFK040" class="alignleft valigntop underscore" id-sequence="190"><p id="GBZGKR06K84RNKMB2371" id-sequence="191">The smallest amount of stimulation that is detectable.</p></td> <td id="AFWVZXBNJCSRBWU0L982" class="alignleft valigntop sidescore underscore" id-sequence="192"><p id="WXFET855ZQRF1ZBTE486" id-sequence="193">Seeing light from a candle flame 30 miles away on a dark night.</p></td> </tr> <tr class="even" id="NXHR2JQ23LVJ6E0P7520" id-sequence="194"> <td id="AFJDTYFHFDK2NXJG8542" class="alignleft valigntop underscore" id-sequence="195"><p id="EQLWKQPHCHA0MB5QC469" id-sequence="196"><strong><em>Difference threshold</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d7 rs_skip" id="UHDBX9QPAE16KXA6X909" clrenderdata="[&quot;YZZVU41SXBUKJMHH1948&quot;]" id-sequence="197"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf10-t2.jpg" data-width="93" data-height="83" data-alt="Assessing Perception"></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:93px;height:83px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf10-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Assessing Perception" width="93" height="83" class="rs_skip"></div> </div></div></div></td> <td id="FEWD2FSZ4CT3SKXVJ928" class="alignleft valigntop underscore" id-sequence="198"><p id="FLXWW9RQAR2GQDFQ9356" id-sequence="199">The smallest difference between two stimuli that can be detected.</p></td> <td id="ZWWATP02E3Y4P633C319" class="alignleft valigntop sidescore underscore" id-sequence="200"><p id="YDBC5RYUYVE2R8QL7935" id-sequence="201">Being able to detect the difference between two different weights.</p></td> </tr> <tr class="odd" id="YARG4KCJG8EK4HSVJ627" id-sequence="202"> <td id="XRAN17H5F8436VBCF463" class="alignleft valigntop underscore" id-sequence="203"><p id="SNMVLW6SY0FXCYMMG145" id-sequence="204"><strong><em>Signal detection</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d8 rs_skip" id="XKQBAAGP189MJ88PB908" clrenderdata="[&quot;RNKW3T3ARRCARYK1V856&quot;]" id-sequence="205"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf11-t2.jpg" data-width="92" data-height="62" data-alt="Assessing Perception"></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:92px;height:62px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf11-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Assessing Perception" width="92" height="62" class="rs_skip"></div> </div></div></div></td> <td id="UGEEMNCFXR4GPJ4Y4300" class="alignleft valigntop underscore" id-sequence="206"><p id="XTHVHH5FY7BXXZLU6364" id-sequence="207">Correctly identifying when a faint stimulus is or is not present.</p></td> <td id="DKLTW7SKL9RYE5J7V871" class="alignleft valigntop sidescore underscore" id-sequence="208"><p id="ZWDBQURZ0V520W83F355" id-sequence="209">A radiologist correctly detecting cancer from a mammogram.</p></td> </tr> </tbody> </table><div class="fadediv_tall"></div><div class="fadediv_wide"></div></div> <div class="byline" id="RVSHK31UN9QMV739F393" id-sequence="210">Credits: Top row—<span class="personName"> Karen H. Ilagan</span>/ <span class="orgName"> Shutterstock.com</span>; Second row—<span class="personName"> YURI CORTEZ</span>/ <span class="orgName"> AFP</span>/ <span class="orgName"> Getty Images</span>/ <span class="orgName"> Newscom</span>; Bottom row—BSIP/ <span class="orgName"> Getty Images</span>.</div> </div> </div></div> </div> <div class="footnotes"></div></div><div id="footer" id-sequence="211"></div></div><div class="container page "><div id="header" id-sequence="214"><div id="breadcrumb-old" id-sequence="215" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="216" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h1 id="HVTLEN35184TU5WBZ459" id-sequence="217"><span class="sectionLabel rs_skip">5-2</span> <span class="headingText">How Do We See?</span></h1></div><div class="content" id="KYMZJT4FQYQVKMJH6632_content" id-sequence="218"> <p id="XEZLUUY2BB2Y75W4B010" id-sequence="219"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f81" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f81"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f81" id="QAQN8H5L08UFTPCF1180" id-sequence="220"><span class="index nb_hidden clAnnotationDecoration rs_skip">Vision</span><span class="term"><span class="primaryTerm" id="KJTL7BV443G2P76TM987" id-sequence="221">Vision</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The sense that allows us to process reflected light.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f81">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="KJTL7BV443G2P76TM987" id-sequence="221">Vision</span></span>
        <span class="definition rs_skip">The sense that allows us to process reflected light.</span>
        <span class="pointer"></span>
    </span>
</span>, the processing of light reflected from objects, is one of the most important sensory systems in humans. Approximately 50% of our cerebral cortex processes visual information, in comparison to only 3% for hearing and 11% for touch and pain (Kandel &amp; Wurtz, 2000; <span class="citation" id="XRMW3N6LRJ517W5Y2586" id-sequence="222"> Sereno &amp; Tootell, 2005</span>). We will begin our exploration of vision with a description of the visual stimulus, and then we will follow the processing of that stimulus by the mind into a meaningful perception.</p> <div class="footnotes"></div></div><div id="footer" id-sequence="223"></div></div><div class="container page "><div id="header" id-sequence="226"><div id="breadcrumb-old" id-sequence="227" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="228" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="CHPVMFE29JATUL882005" id-sequence="229"><span class="sectionLabel rs_skip">5-2a</span> <span class="headingText">The Visual Stimulus</span></h2></div><div class="content" id="DRDRMUTCZMW50CY7M263_content" id-sequence="230"> <p id="TWFPC8GSFRNV90HJT845" id-sequence="231">Visible light, or the energy within the electromagnetic spectrum to which our visual systems respond, is a type of radiation emitted by the sun, other stars, and artificial sources such as a lightbulb. As shown in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="FGGB8G2WG3N026EEQ199" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="DRDRMUTCZMW50CY7M263" data-element-id="FGGB8G2WG3N026EEQ199">Figure 5.4</a>, light energy moves in waves, like the waves in the ocean. Wavelength, or the distance between successive peaks of waves, is decoded by our visual system as color or shades of gray. The height, or amplitude, of the waves is translated by the visual system into brightness. Large-amplitude waves appear bright, and low-amplitude waves appear dim.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14d9 rs_skip" id="FGGB8G2WG3N026EEQ199" clrenderdata="[&quot;JGJP530L3CSW99F0A917&quot;]" id-sequence="232"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f04-t3.png" data-width="840" data-height="95"></div><div class="metadata inlineImage" data-filename="61815_05_f04-t2.png" data-width="595" data-height="63" data-alt="A diagram showing how light travels. There is a wave that changes in color from purple to red, from left to right. The labeled parts are wavelength and amplitude (measured against a baseline). The amplitude of the waves on the left is smaller. It increases as we move towards the right."></div><div class="nb_media image wide"><div class="mediaTitle" id="WMZADUME82HQ2PKBE372" id-sequence="233"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.4</span></span><span class="mediaAssetTitle">Light Travels in Waves.</span></div><div class="mediaDescription" id="WFPCE5A56N50RX9WJ404" id-sequence="234"><p>The distance between two peaks in a light wave (wavelength) is decoded by the visual system as color and the height, or amplitude, of the wave as brightness.</p></div> <div class="imageContainer" style="width:595px;height:63px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f04-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A diagram showing how light travels. There is a wave that changes in color from purple to red, from left to right. The labeled parts are wavelength and amplitude (measured against a baseline). The amplitude of the waves on the left is smaller. It increases as we move towards the right." width="595" height="63" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div> </div></div></div> <p id="BTJTT4G1NJ02WKKSM590" id-sequence="235">The human visual world involves only a small part of this light spectrum (review <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="QNRN7167MB8QCZN81734" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="UYJZ78E8L7BRBKCDJ954" data-element-id="QNRN7167MB8QCZN81734">Figure 5.1</a>). Gamma rays, x-rays, ultraviolet rays, infrared rays, microwaves, and radio waves lie outside the capacities of the human eye.</p><a data-type="pageEnd" name="PageEnd_156" data-page="156"></a> <div class="footnotes"></div></div><div id="footer" id-sequence="236"></div></div><div class="container page "><div id="header" id-sequence="239"><div id="breadcrumb-old" id-sequence="240" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="241" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="CJYJMPTS1DJZ70TPY050" id-sequence="242"><span class="sectionLabel rs_skip">5-2b</span> <span class="headingText">The Biology of Vision</span></h2></div><div class="content" id="PHQHDBWK8MPBVXUWT080_content" id-sequence="243"> <p id="LRWED82CYU13R5LJ1137" id-sequence="244">Human vision begins with the eye. The eye is roughly sphere shaped and about the size of a ping-pong ball. Its hard outer covering helps the fluid-filled eyeball retain its shape. Toward the front of the eye, the outer covering becomes clear and forms the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f82" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f82"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f82" id="RGLNCJA4PAXWPJ2RX619" id-sequence="245"><span class="index nb_hidden clAnnotationDecoration rs_skip">cornea</span><span class="term"><span class="primaryTerm" id="CDVRF96AX3T1JMBLZ927" id-sequence="246">cornea</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The clear surface at the front of the eye that begins the process of directing light to the retina.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f82">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="CDVRF96AX3T1JMBLZ927" id-sequence="246">cornea</span></span>
        <span class="definition rs_skip">The clear surface at the front of the eye that begins the process of directing light to the retina.</span>
        <span class="pointer"></span>
    </span>
</span>. The cornea begins the process of bending light to form an image on the back of the eye. Traveling light next enters the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f83" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f83"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f83" id="ZJGQAB0LARKHECHQR007" id-sequence="247"><span class="index nb_hidden clAnnotationDecoration rs_skip">pupil</span><span class="term"><span class="primaryTerm" id="QQNDHG0R9TQV786GV123" id-sequence="248">pupil</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">An opening formed by the iris.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f83">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="QQNDHG0R9TQV786GV123" id-sequence="248">pupil</span></span>
        <span class="definition rs_skip">An opening formed by the iris.</span>
        <span class="pointer"></span>
    </span>
</span>, which is actually an opening formed by the muscles of the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f84" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f84"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f84" id="JPHU71ULB84AGUKD8027" id-sequence="249"><span class="index nb_hidden clAnnotationDecoration rs_skip">iris</span><span class="term"><span class="primaryTerm" id="BRZWV40T5FAQ096AU110" id-sequence="250">iris</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The brightly colored circular muscle surrounding the pupil of the eye.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f84">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="BRZWV40T5FAQ096AU110" id-sequence="250">iris</span></span>
        <span class="definition rs_skip">The brightly colored circular muscle surrounding the pupil of the eye.</span>
        <span class="pointer"></span>
    </span>
</span> (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="WHTTZXJ2XKEW6F4EC312" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="PHQHDBWK8MPBVXUWT080" data-element-id="WHTTZXJ2XKEW6F4EC312">Figure 5.5</a>). The iris, which means “rainbow” in Greek, adjusts the opening of the pupil in response to the amount of light present in the environment and to signals from the autonomic nervous system, described in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="ZUXJT37ZGC28NP5YG839" data-chapter-id="ZUXJT37ZGC28NP5YG839" data-element-id="ZUXJT37ZGC28NP5YG839">Chapter 4</a>. Arousal is associated with dilated pupils, while relaxation is associated with more constricted pupils.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14da rs_skip" id="WHTTZXJ2XKEW6F4EC312" clrenderdata="[&quot;NFBH1RMM0EF25ZPV4127&quot;]" id-sequence="251"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f05-t3.png" data-width="631" data-height="581"></div><div class="metadata inlineImage" data-filename="61815_05_f05-t2.png" data-width="595" data-height="545" data-alt="An illustration of the human eye is at the bottom. The labeled parts are cornea, pupil, iris, lens, blood vessels, optic disk, fovea and retina. The retina is enlarged and shown in a separate illustration at the top. The labeled parts are fovea, optic disk and blood vessels."></div><div class="nb_media image wide"><div class="mediaTitle" id="EGSHBAQTP2SBP5NX0365" id-sequence="252"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.5</span></span><span class="mediaAssetTitle">The Human Eye.</span></div><div class="mediaDescription" id="ZJRS772CKXQ8D8AQR055" id-sequence="253"><p>Light entering the eye travels through the cornea, the pupil, and the lens before reaching the retina. Among the landmarks on the retina are the fovea, which is specialized for seeing fine detail, and the optic disk, where blood vessels enter the eye and the optic nerve exits the eye.</p></div> <div class="imageContainer" style="width:595px;height:545px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f05-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration of the human eye is at the bottom. The labeled parts are cornea, pupil, iris, lens, blood vessels, optic disk, fovea and retina. The retina is enlarged and shown in a separate illustration at the top. The labeled parts are fovea, optic disk and blood vessels." width="595" height="545" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">James P. Gilman, C.R.A. / Phototake </div> </div></div></div> <p id="JVCW1BJ1XW05J1HWR979" id-sequence="254">Directly behind the pupil and iris is the main optical instrument of the eye, the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f85" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f85"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f85" id="XTEY5TEPMWU4XHK6T761" id-sequence="255"><span class="index nb_hidden clAnnotationDecoration rs_skip">lens</span><span class="term"><span class="primaryTerm" id="QGUVYSYDEN07VWG6V377" id-sequence="256">lens</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The clear structure behind the pupil that bends light toward the retina.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f85">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="QGUVYSYDEN07VWG6V377" id-sequence="256">lens</span></span>
        <span class="definition rs_skip">The clear structure behind the pupil that bends light toward the retina.</span>
        <span class="pointer"></span>
    </span>
</span>. Muscles attached to the lens can change its shape, allowing us to accommodate, or adjust our focus to see near or distant objects. Behind the lens is the main chamber of the eye, and located on the rear surface of this chamber is the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f86" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f86"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f86" id="WMSQB4YAMJCV7503U669" id-sequence="257"><span class="index nb_hidden clAnnotationDecoration rs_skip">retina</span><span class="term"><span class="primaryTerm" id="FWTTQ3PUZF6DRZBPL653" id-sequence="258">retina</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Layers of visual processing cells in the back of the eye</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f86">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="FWTTQ3PUZF6DRZBPL653" id-sequence="258">retina</span></span>
        <span class="definition rs_skip">Layers of visual processing cells in the back of the eye</span>
        <span class="pointer"></span>
    </span>
</span>, a thin but complex network of neurons specialized for the processing of light.</p> <p id="XCHUX8CRJZVEAPPHT084" id-sequence="259">Located in the deepest layer of the retina are specialized receptors, the rods and cones, that transduce the light information. However, before light reaches these receptors, it must pass through layers of blood vessels and neurons. We normally do not see the blood vessels and neural layers because of sensory adaptation. As we mentioned previously in this chapter, adaptation occurs when sensory systems tune out stimuli that never change. Because the blood vessels and neural layers are always in the same place, we see them only under unusual circumstances, such as during certain ophthalmology (eye) tests.</p><a data-type="pageEnd" name="PageEnd_157" data-page="157"></a> <p id="JCBLP6D88E3XA20YH240" id-sequence="260">We can identify several landmarks on the surface of the retina. The blood vessels serving the eye and the axons that leave the retina to form the optic nerve exit at the optic disk. Because there are no rods and cones in the optic disk, each eye has a blind spot. Normally, we are unaware of our blind spots because perception fills in the missing details. However, if you follow the directions in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="QFKQKWD9EDNX0JPQE996" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="PHQHDBWK8MPBVXUWT080" data-element-id="QFKQKWD9EDNX0JPQE996">Figure 5.6</a>, you should be able to experience your own blind spot. Toward the middle of the retina is the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f87" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f87"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f87" id="CTCMR22AVV2LR6S43472" id-sequence="261"><span class="index nb_hidden clAnnotationDecoration rs_skip">fovea</span><span class="term"><span class="primaryTerm" id="SABHT2JZMJHP6EHV9022" id-sequence="262">fovea</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">An area of the retina that is specialized for highly detailed vision.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f87">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="SABHT2JZMJHP6EHV9022" id-sequence="262">fovea</span></span>
        <span class="definition rs_skip">An area of the retina that is specialized for highly detailed vision.</span>
        <span class="pointer"></span>
    </span>
</span>, which is specialized for seeing fine detail. When we stare directly at an object, the image of that object is projected onto the fovea. The fovea is responsible for central vision, as opposed to peripheral vision, which is the ability to see objects off to the side while looking straight ahead.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14db rs_skip" id="QFKQKWD9EDNX0JPQE996" clrenderdata="[&quot;CGHDPNPLLZ035M1SY159&quot;]" id-sequence="263"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f06-t2.png" data-width="592" data-height="58" data-alt="A stack of currency notes."></div><div class="nb_media image wide"><div class="mediaTitle" id="BVHWY81CRUM9ACF6L349" id-sequence="264"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.6</span></span><span class="mediaAssetTitle">Now You See It—Now You Don’t.</span></div><div class="mediaDescription" id="AUNKB7VUN4NHQQC8V938" id-sequence="265"><p>There are no photoreceptors in the optic disk, producing a blind spot in each eye. We do not see our blind spots because our brain fills in the hole. You can demonstrate your blind spot by holding your textbook at arm’s length, closing one eye, focusing your other eye on the dot, and moving the book toward you until the stack of money disappears.</p></div> <div class="imageContainer" style="width:592px;height:58px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f06-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A stack of currency notes." width="592" height="58" class="rs_skip"></div> </div></div></div> <p id="MLEGWPSB58UMWHTUY670" id-sequence="266">The image projected on the retina is upside down and reversed relative to the actual orientation of the object being viewed (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="XXSCECYQR8P3VLPSR141" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="PHQHDBWK8MPBVXUWT080" data-element-id="XXSCECYQR8P3VLPSR141">Figure 5.7</a>). You can duplicate this process by looking at both sides of a shiny spoon. In the convex (or outwardly curving) side, you see your image normally. In the concave (or inwardly curving) side, you see your image as your retina sees it. Fortunately, the visual system easily decodes this image and provides realistic perceptions of the actual orientations of objects.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14dc rs_skip" id="XXSCECYQR8P3VLPSR141" clrenderdata="[&quot;JGLY37XBSKBM9MEY2801&quot;]" id-sequence="267"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f07-t2.png" data-width="443" data-height="250" data-alt="An illustration of the human eye depicting how the retina captures an image. On the left is a woman who is the object of vision. On the right is a human eye. Lines connecting the woman’s head and foot to the retina show how light travels. An inverted image of the woman is seen on the retina. The labeled parts of the eye include light rays, retina, cornea, lens and optic nerve."></div><div class="nb_media image"><div class="mediaTitle" id="XFZKB4PXAM2RA0TPZ954" id-sequence="268"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.7</span></span><span class="mediaAssetTitle">What the Retina “Sees.”</span></div><div class="mediaDescription" id="YFUTEC6UT68R1Y18C785" id-sequence="269"><p>The image projected on the retina is upside down and reversed, but the brain is able to interpret the image to perceive the correct orientation of an object.</p></div> <div class="imageContainer" style="width:443px;height:250px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f07-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration of the human eye depicting how the retina captures an image. On the left is a woman who is the object of vision. On the right is a human eye. Lines connecting the woman’s head and foot to the retina show how light travels. An inverted image of the woman is seen on the retina. The labeled parts of the eye include light rays, retina, cornea, lens and optic nerve." width="443" height="250" class="rs_skip"></div> </div></div></div> <div class="pageSection" id="JXXFYGZUY1ELFR8HM571" id-sequence="270"> <h3 id="PUTNZ5L2JE9RG68S9182" id-sequence="271"><span class="headingText">Rods and Cones</span></h3> <p id="ZEBGQ0P8RW7UCME78588" id-sequence="272"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f88" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f88"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f88" id="HQBVA2XNPC1WW4EC9678" id-sequence="273"><span class="index nb_hidden clAnnotationDecoration rs_skip">Rods</span><span class="term"><span class="primaryTerm" id="NENWNSD9UA2X7UF52772" id-sequence="274">Rods</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A photoreceptor specialized to detect dim light</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f88">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="NENWNSD9UA2X7UF52772" id-sequence="274">Rods</span></span>
        <span class="definition rs_skip">A photoreceptor specialized to detect dim light</span>
        <span class="pointer"></span>
    </span>
</span> and <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f89" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f89"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f89" id="DZDMP0NGY87XA4BGV256" id-sequence="275"><span class="index nb_hidden clAnnotationDecoration rs_skip">cones</span><span class="term"><span class="primaryTerm" id="KWSFW42WH2KM9550M193" id-sequence="276">cones</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A photoreceptor in the retina that processes color and fine detail.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f89">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="KWSFW42WH2KM9550M193" id-sequence="276">cones</span></span>
        <span class="definition rs_skip">A photoreceptor in the retina that processes color and fine detail.</span>
        <span class="pointer"></span>
    </span>
</span> are named after their shapes. The human eye contains about 90 million rods and between 4 million and 5 million cones.</p> <p id="MGLTUW4K9QK8WVZA2250" id-sequence="277">Rods and cones are responsible for different aspects of vision. Rods are more sensitive to light than cones, and they excel at seeing dim light. As we observed previously, under ideal circumstances, the absolute threshold for human vision is the equivalent of a single candle flame from a distance of 30 miles (about 48 kilometers; see <span class="citation" id="UWPHZ8R2T00DG4QPL540" id-sequence="278"> Hecht, Shlaer, &amp; Pirenne, 1942</span>). Rods become more common as we move from the fovea to the periphery of the retina, so your peripheral vision does a better job of viewing dim light than your central vision does (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="TVTFZZ7TPAZVLGB1C287" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="PHQHDBWK8MPBVXUWT080" data-element-id="TVTFZZ7TPAZVLGB1C287">Figure 5.8</a>). Before the development of night goggles, soldiers patrolling in the dark were trained to look to the side of a suspected enemy position rather than directly at their target.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14dd rs_skip" id="TVTFZZ7TPAZVLGB1C287" clrenderdata="[&quot;ABWNC311125GK3U6L136&quot;]" id-sequence="279"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f08-t2.png" data-width="473" data-height="329" data-alt="An illustration showing the distribution of rods and cones on the retina of the human eye. On the left is a circle representing the retina. The cones are concentrated in the middle while the rods surrounding the concentration of cones are spread around the circumference of the retina. On the right two enlarged images of rods and cones are shown."></div><div class="nb_media image"><div class="mediaTitle" id="FKANZMD0T8YWU3KMC788" id-sequence="280"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.8</span></span><span class="mediaAssetTitle">Distribution of Rods and Cones across the Retina.</span></div><div class="mediaDescription" id="NKRFHW8ND6UNKBWU2973" id-sequence="281"><p>In humans, cones, indicated by red, blue, and green dots, become less frequent as you move from the fovea to the periphery of the retina. The colors of the dots representing cones indicate the colors to which each shows a maximum response (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="JRQR8KLWCP4UVB97Z470" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="JRQR8KLWCP4UVB97Z470">Figure 5.12</a>). Rods (light brown dots) and cones are named according to their shapes.</p></div> <div class="imageContainer" style="width:473px;height:329px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f08-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing the distribution of rods and cones on the retina of the human eye. On the left is a circle representing the retina. The cones are concentrated in the middle while the rods surrounding the concentration of cones are spread around the circumference of the retina. On the right two enlarged images of rods and cones are shown." width="473" height="329" class="rs_skip"></div> </div></div></div><a data-type="pageEnd" name="PageEnd_158" data-page="158"></a> <p id="XWHWA82PKUXA5H5VS483" id-sequence="282">This extraordinary sensitivity of rods has costs. Rods do not provide information about color, nor do they provide clear, sharp images. Under starlight, normal human vision is 20/200 rather than the normal daylight 20/20. In other words, an object seen at night from a distance of 20 feet would have the same clarity as an object seen in bright sunlight from a distance of 200 feet. Cones function best under bright light and provide the ability to see both sharp images and color.</p> </div> <div class="pageSection" id="YDSW4BSYEP8X9X6SY349" id-sequence="283"> <h3 id="ZQXMB8B246N24V11E307" id-sequence="284"><span class="headingText">Visual Pathways</span></h3> <p id="JUEUB0C3M4V825P0F409" id-sequence="285">The rods and cones are the only true receptors of the visual system. When they absorb light, they trigger responses in four additional layers of neurons within the retina. Axons from the final layer of cells, the ganglion cells, leave the back of the eye to form the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f8a" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f8a"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f8a" id="SEGJ0TD7A3V6JL6MP470" id-sequence="286"><span class="index nb_hidden clAnnotationDecoration rs_skip">optic nerve</span><span class="term"><span class="primaryTerm" id="KPAC0LW43JMU2K5TH451" id-sequence="287">optic nerve</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The nerve exiting the retina of the eye.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f8a">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="KPAC0LW43JMU2K5TH451" id-sequence="287">optic nerve</span></span>
        <span class="definition rs_skip">The nerve exiting the retina of the eye.</span>
        <span class="pointer"></span>
    </span>
</span>. The optic nerves cross the midline at the optic chiasm (named after its X shape, or the Greek letter <em>chi</em>). At the optic chiasm, the axons closest to the nose cross over to the other hemisphere, while the axons to the outside proceed to the same hemisphere. This partial crossing means that if you focus straight ahead, everything to the left of center in the visual field is processed by the right hemisphere, while everything to the right of center is processed by the left hemisphere. This organization provides us with significant advantages when sensing depth, which we discuss later in the chapter.</p> <p id="SSLN6S6J4QRSEZYUE488" id-sequence="288">Beyond the optic chiasm, the visual pathways are known as <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f8b" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f8b"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f8b" id="HCBBDVNQ8E1CGAH16217" id-sequence="289"><span class="index nb_hidden clAnnotationDecoration rs_skip">optic tracts</span><span class="term"><span class="primaryTerm" id="ZGWF24ANPN8VKHSGU691" id-sequence="290">optic tracts</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Nerve pathways traveling from the optic chiasm to the thalamus, hypothalamus, and midbrain.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f8b">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="ZGWF24ANPN8VKHSGU691" id-sequence="290">optic tracts</span></span>
        <span class="definition rs_skip">Nerve pathways traveling from the optic chiasm to the thalamus, hypothalamus, and midbrain.</span>
        <span class="pointer"></span>
    </span>
</span> (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="PWJWT3HZNCEUYP4PR060" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="PHQHDBWK8MPBVXUWT080" data-element-id="PWJWT3HZNCEUYP4PR060">Figure 5.9</a>). About 90% of the axons in the optic tracts synapse in the thalamus. The thalamus sends information about vision to the amygdala and the primary visual cortex in the occipital lobe. The amygdala uses visual information to make quick emotional judgments, especially about potentially harmful stimuli. The remaining optic tract fibers connect with the hypothalamus, where their input provides information about light needed to regulate sleep–wake cycles, discussed in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="MQJZJ4JJN52VRSCZ7957" data-chapter-id="MQJZJ4JJN52VRSCZ7957" data-element-id="MQJZJ4JJN52VRSCZ7957">Chapter 6</a>, or with the superior colliculi of the midbrain, which manage a number of visually guided reflexes, such as changing the size of the pupil in response to light conditions.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14de rs_skip" id="PWJWT3HZNCEUYP4PR060" clrenderdata="[&quot;XTEX3F2Q07WPGW9SY781&quot;]" id-sequence="291"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f09-t3.png" data-width="669" data-height="773"></div><div class="metadata inlineImage" data-filename="61815_05_f09-t2.png" data-width="595" data-height="693" data-alt="An illustration showing how visual information is processed by the human eye and the brain. At the bottom of the image there are boundaries created by lines that show the visual field of each eye. Information from the retina then travels to the brain. The labeled parts of the brain are optic chiasm, midbrain, primary visual cortex, thalamus, optic tract and optic nerve."></div><div class="nb_media image wide"><div class="mediaTitle" id="TYSXPB4W3KGZ4MP7F461" id-sequence="292"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.9</span></span><span class="mediaAssetTitle">Visual Pathways.</span></div><div class="mediaDescription" id="UFZWZ19N8NQ6Y652F452" id-sequence="293"><p>Visual information from the retina travels to the thalamus and then to the primary visual cortex in the occipital lobe.</p></div> <div class="imageContainer" style="width:595px;height:693px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f09-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing how visual information is processed by the human eye and the brain. At the bottom of the image there are boundaries created by lines that show the visual field of each eye. Information from the retina then travels to the brain. The labeled parts of the brain are optic chiasm, midbrain, primary visual cortex, thalamus, optic tract and optic nerve." width="595" height="693" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div> </div></div></div> <p id="PHGYVGMXF5J7TNH7F189" id-sequence="294">The primary visual cortex begins, but by no means finishes, the processing of visual input. The primary visual cortex responds to object shape, location, movement, and color (<span class="citation" id="EXHN60U5QQ8NXN9D5948" id-sequence="295">Hubel &amp; Livingstone, 1987</span>; <span class="citation" id="AREJAGNE87E73U14P622" id-sequence="296"> Hubel &amp; Wiesel, 1959</span>; <span class="citation" id="JYYY4KSF58F6B63TQ856" id-sequence="297"> Livingstone &amp; Hubel, 1984</span>). Two major pathways radiating from the occipital cortex into the adjacent temporal and parietal lobes continue the analysis of visual input. The parietal pathway helps us process movement in the visual environment. The temporal pathway responds to shape and color and contributes to our ability to recognize objects and faces.</p> </div> <div class="footnotes"></div></div><div id="footer" id-sequence="298"></div></div><div class="container page "><div id="header" id-sequence="301"><div id="breadcrumb-old" id-sequence="302" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="303" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="NYETXPH956ZP455KE517" id-sequence="304"><span class="sectionLabel rs_skip">5-2c</span> <span class="headingText">Visual Perception and Cognition</span></h2></div><div class="content" id="BCPZ9771W6YM1Y0X4422_content" id-sequence="305"> <p id="ZNZR8NKSXCR42U76P730" id-sequence="306">To see something requires the brain to interpret the information gathered by the eyes. How do you know your sweater is red or green, based on the information sent from the retina to the brain? How do you recognize your grandmother at your front door?</p><a data-type="pageEnd" name="PageEnd_159" data-page="159"></a> <div class="pageSection" id="FAQH6X3H9G3FLFAUE096" id-sequence="307"> <h3 id="ACDX2AWLW8XKVTKFF582" id-sequence="308"><span class="headingText">Color Vision</span></h3> <p id="CFQS91UAY3J5DYNPC944" id-sequence="309">Most of us think about colors in terms of the paints and crayons we used in elementary school. Any kindergartner can tell you that mixtures of red and yellow make orange, red and blue make purple, and yellow and blue make green. Mixing them all together produces a lovely muddy brown. Colored lights, however, work somewhat differently (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="QLDRQUFKW0KZNFFBF071" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="QLDRQUFKW0KZNFFBF071">Figure 5.10</a>). The primary colors of light are red, green, and blue, and mixing them together produces white light, like sunlight. If you have ever adjusted the color on your computer monitor or television, you know that these devices also use red, green, and blue as primary colors. Observations supporting the existence of three primary colors of light gave rise to a <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f8c" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f8c"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f8c" id="CWWWMFHSWE58B9QUA169" id-sequence="310"><span class="index nb_hidden clAnnotationDecoration rs_skip">trichromatic theory</span><span class="term"><span class="primaryTerm" id="RAEL8ZRNLL3R2M5TE530" id-sequence="311">trichromatic theory</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A theory of color vision based on the existence of different types of cones for the detection of short, medium, and long wavelengths</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f8c">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="RAEL8ZRNLL3R2M5TE530" id-sequence="311">trichromatic theory</span></span>
        <span class="definition rs_skip">A theory of color vision based on the existence of different types of cones for the detection of short, medium, and long wavelengths</span>
        <span class="pointer"></span>
    </span>
</span> of color vision.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14df rs_skip" id="QLDRQUFKW0KZNFFBF071" clrenderdata="[&quot;KSNGG6KXWKG7UFLWV786&quot;]" id-sequence="312"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f10-t2.png" data-width="404" data-height="313" data-alt="Three projectors projecting the three primary light colors - blue, red and green. These lights mix and a Venn diagram shows the effect of mixing each color with another and that of mixing all of them together."></div><div class="nb_media image"><div class="mediaTitle" id="CKHZCZQHGZK84F9GV668" id-sequence="313"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.10</span></span><span class="mediaAssetTitle">Mixing Colored Lights.</span></div><div class="mediaDescription" id="XGRA4QW8LMYU6Y2DF739" id-sequence="314"><p>The primary colors of paint might be red, yellow, and blue, but in the world of light, the primary colors are red, green, and blue.</p></div> <div class="imageContainer" style="width:404px;height:313px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f10-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Three projectors projecting the three primary light colors - blue, red and green. These lights mix and a Venn diagram shows the effect of mixing each color with another and that of mixing all of them together." width="404" height="313" class="rs_skip"></div> </div></div></div> <p id="KEGQ60JX5UVC5AD6M524" id-sequence="315">Trichromatic theory is consistent with the existence of three types of cones in the retina that respond best to short (blue), medium (green), or long (red) wavelengths. Our ultimate experience of color comes not from the response of one type of cone but from comparisons among the responses of all three types of cones (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="PXXDKL0JW2JP4TQKN273" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="PXXDKL0JW2JP4TQKN273">Figure 5.11</a>).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e0 rs_skip" id="PXXDKL0JW2JP4TQKN273" clrenderdata="[&quot;MYPRLGZU2GVPFGKUF900&quot;]" id-sequence="316"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f11-t2.png" data-width="472" data-height="260" data-alt="A graph showing how cones respond to different color lights. On the X axis is the wavelength of the different lights from 400-750. Each section is vertically divided into different colors based on the wavelength of each. On the Y axis is the percentage of maximum response. Different graphs show the responses to rods and cones to each color of light. Each graph peaks at a different colored segment."></div><div class="nb_media image"><div class="mediaTitle" id="SQWTAZPX2J62KC3HC061" id-sequence="317"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.11</span></span><span class="mediaAssetTitle">Responses by Cones to Colored Light.</span></div><div class="mediaDescription" id="NHNZ4GL83EHM88XNP454" id-sequence="318"><p>Our perception of color results from a comparison of the responses of the red, green, and blue cones to light. A 550-nanometer light is perceived as yellow and produces a strong response in green cones, a moderate response in red cones, and little response in blue cones.</p></div> <div class="imageContainer" style="width:472px;height:260px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f11-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A graph showing how cones respond to different color lights. On the X axis is the wavelength of the different lights from 400-750. Each section is vertically divided into different colors based on the wavelength of each. On the Y axis is the percentage of maximum response. Different graphs show the responses to rods and cones to each color of light. Each graph peaks at a different colored segment." width="472" height="260" class="rs_skip"></div> </div></div></div> <p id="QARW91EFZNBUWWGV3330" id-sequence="319">Color deficiency occurs when a person has fewer than the typical three types of cones. We no longer use the term <em>colorblind</em>, as this is not accurate. Most people with color deficiencies see color differently than someone with all three cone types. Very rarely, individuals have either one type of cone or none. To these people, the world appears to be black, white, and gray.</p> <p id="LBPF3P7ZZ9ZBCFL4G941" id-sequence="320">Trichromatic theory does a good job of explaining color deficiency, but it is less successful in accounting for other color vision phenomena, such as color afterimages. For example, if you stare at the yellow, green, and black flag in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="JRQR8KLWCP4UVB97Z470" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="JRQR8KLWCP4UVB97Z470">Figure 5.12</a> and then focus on the dot within the white rectangle to the right, you will see an afterimage of the American flag in its more traditional colors of red, white, and blue.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e1 rs_skip" id="JRQR8KLWCP4UVB97Z470" clrenderdata="[&quot;ZBKE8QNMPGS2D7M02132&quot;]" id-sequence="321"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f12-t2.png" data-width="509" data-height="134" data-alt="A set of two images of flags. On the left is a flag with green and black stripes and black and yellow stars. There is dot at the center of the flag. On the right is a blank rectangle of the size of the flag with only the black dot in the center."></div><div class="nb_media image wide"><div class="mediaTitle" id="LGVGGKYR9RKDP2VZK997" id-sequence="322"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.12</span></span><span class="mediaAssetTitle">Afterimages Demonstrate Opponent Process Theory.</span></div><div class="mediaDescription" id="AKJWA7SBW4BM0DKT5313" id-sequence="323"><p>If you stare at the dot in the center of the yellow, green, and black flag for a minute and then shift your gaze to the dot in the white space on the right, you should see the flag in its traditional red, white, and blue.</p></div> <div class="imageContainer" style="width:509px;height:134px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f12-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A set of two images of flags. On the left is a flag with green and black stripes and black and yellow stars. There is dot at the center of the flag. On the right is a blank rectangle of the size of the flag with only the black dot in the center." width="509" height="134" class="rs_skip"></div> </div></div></div> <p id="ZCPG83Y0M9BR0HJZT536" id-sequence="324">An <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f8d" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f8d"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f8d" id="STPE6FHLENQ9FLCBA719" id-sequence="325"><span class="index nb_hidden clAnnotationDecoration rs_skip">opponent process theory</span><span class="term"><span class="primaryTerm" id="NZXJFP2EGMX1LFUZ3037" id-sequence="326">opponent process theory</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A theory of color vision that suggests we have a red-green color channel and a blue-yellow color channel in which activation of one color in each pair inhibits the other color</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f8d">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="NZXJFP2EGMX1LFUZ3037" id-sequence="326">opponent process theory</span></span>
        <span class="definition rs_skip">A theory of color vision that suggests we have a red-green color channel and a blue-yellow color channel in which activation of one color in each pair inhibits the other color</span>
        <span class="pointer"></span>
    </span>
</span> of color vision does a better job than the trichromatic theory in explaining these color afterimages. This theory proposes the existence of color<a data-type="pageEnd" name="PageEnd_160" data-page="160"></a> channels: a red–green channel and a blue–yellow channel. We cannot see a color like reddish green or bluish yellow because the two colors share the same channel. The channels are “opponent” or competing. Activity in one color group in a channel reduces activity in the other color group.</p> <p id="BWFKYYW99GWKRTQQ4734" id-sequence="327">Returning to our green, yellow, and black flag, how can we use opponent process theory to explain our experience of the red, white, and blue afterimage? By staring at the flag, you fatigue some of your visual neurons. Because the color channels compete, reducing activity in one color group in a channel, such as green, increases activity in the other group, which is red. Fatiguing green, black, and yellow causes a rebound effect in each color channel, and your afterimage looks red, white, and blue. (Black and white also share a channel.) If you stare at an image of a real red, white, and blue flag and then look at a white piece of paper, your afterimage looks like our green, black, and yellow illustration.</p> <p id="EXGGRM30U7M3BD714463" id-sequence="328">Which of these two theories of color vision, trichromatic theory or opponent process theory, is correct? The trichromatic theory provides a helpful framework for the functioning of the three types of cones in the retina. However, as we move from the retina to higher levels of visual analysis, the opponent process theory seems to fit observed phenomena neatly. Both theories help us understand color vision but at different levels of the visual system.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e2 rs_skip" id="QNVMY7XXFNBXS0Z2H808" clrenderdata="[&quot;MUFQK3ZGA5137242R817&quot;]" id-sequence="329"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf12-t2.jpg" data-width="437" data-height="282" data-alt="Monty Roberts, known as the Horse Whisperer, attributes his abilities to observe horse behavior to his complete lack of color vision. This condition is quite rare, occurring in only 1 person out of every 30,000."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="ESTG13GGHJSHPTZAY338" id-sequence="330"><p>Monty Roberts, known as the Horse Whisperer, attributes his abilities to observe horse behavior to his complete lack of color vision. This condition is quite rare, occurring in only 1 person out of every 30,000.</p></div> <div class="imageContainer" style="width:437px;height:282px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf12-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Monty Roberts, known as the Horse Whisperer, attributes his abilities to observe horse behavior to his complete lack of color vision. This condition is quite rare, occurring in only 1 person out of every 30,000." width="437" height="282" class="rs_skip"></div><div class="mediaCredit">Dan Tuffs/Getty Images </div> </div></div></div> <div class="container dependent mt_psychologyasahubscience narrative  rs_skip" id="VMBN9EMRYL002BKGZ953" label="psychologyasahubscience" id-sequence="331"><div class="containerHeading"><span class="label">Psychology as a Hub Science</span><h3 id="NDWWUHJ28SJ6KCN88708" id-sequence="332">Color and Accessible Web Design</h3></div><div class="sidebarContent" id="VMBN9EMRYL002BKGZ953_sidebarcontent" id-sequence="333"> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e3 rs_skip" id="TYXZS4R7QPZFCL6NN305" clrenderdata="[&quot;YAHA9W4ECC9YAKG1H167&quot;]" id-sequence="334"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf41-t2.png" data-width="251" data-height="281" data-alt="An image of the globe with three labels surrounding it - computer science, communications and ophthalmology."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:251px;height:281px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf41-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An image of the globe with three labels surrounding it - computer science, communications and ophthalmology." width="251" height="281" class="rs_skip"></div> </div></div></div> <p id="TTQCKWGNBMEYMYJKH224" id-sequence="335">Now that you have an understanding of color perception, we can consider one of the practical problems associated with individual differences in color vision. Between 7% and 10% of males and about 0.4% of females have a form of red–green color deficiency (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="CCYB3SS8UTUL3T4DG510" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="CCYB3SS8UTUL3T4DG510">Figure 5.13</a>). Males are more affected than females because the genes for the pigments used by red and green cones are located on the X chromosome, making red–green color deficiency a sex-linked condition (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="TPPAPQFA7W5XFGWW3455" data-chapter-id="TPPAPQFA7W5XFGWW3455" data-element-id="TPPAPQFA7W5XFGWW3455">Chapter 3</a>). Smaller numbers of people lack blue cones (0.0011%) or cones altogether (0.00001%). Given the frequency of color deficiency, making visual materials accessible to people with all types of color vision is a serious concern.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e4 rs_skip" id="CCYB3SS8UTUL3T4DG510" clrenderdata="[&quot;TRHK2D87PMPX0LQQ6093&quot;]" id-sequence="336"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f13-t2.png" data-width="229" data-height="215" data-alt="The Ishihara Color test showing small and big green circles closely packed in a circular shape. There is a large 12 written at the center in red."></div><div class="nb_media image"><div class="mediaTitle" id="JZMXR0QZQPXVQTMT5305" id-sequence="337"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.13</span></span><span class="mediaAssetTitle">Detecting Color Deficiency.</span></div><div class="mediaDescription" id="ZWLYZQ88VKXC0EUAY043" id-sequence="338"><p>The Ishihara Color Test, designed by Shinobu Ishihara in 1917, is a standard method for detecting color deficiency. The test is printed on special paper, so the recreated image here would not be considered a valid basis for diagnosing color deficiency.</p></div> <div class="imageContainer" style="width:229px;height:215px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f13-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="The Ishihara Color test showing small and big green circles closely packed in a circular shape. There is a large 12 written at the center in red." width="229" height="215" class="rs_skip"></div><div class="mediaCredit">PRISMA ARCHIVO/Alamy Stock Photo </div> </div></div></div> <p id="LUKHKRVWU83BX0K19050" id-sequence="339">Color can be an effective tool for designing exciting and engaging websites, but many graphic web designers, who typically have excellent vision, fail to consider how the site might look to a person with a color deficiency. One clue for designing an accessible site can be found in other systems based on color, such as traffic lights. Although most of us rely on the color information from the red, yellow, or green lights, the lights also vary in location. In other words, color should never be the only basis for extracting meaning. A second major concern is contrast, which we discuss in the next section. The strong contrast between black letters on the white pages makes text easy to read for most people. Colored text against a colored background might add interest, but it runs the risk of being harder to read, especially when reds and greens are used. As shown in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="XYKCHCD5B7FNAMU4S296" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="XYKCHCD5B7FNAMU4S296">Figure 5.14</a>, online resources simulate how a web page looks to a person with color deficiency, which helps designers maximize accessibility.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e5 rs_skip" id="XYKCHCD5B7FNAMU4S296" clrenderdata="[&quot;SHHKRG9WBH1ECTT3E377&quot;]" id-sequence="340"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f14-t3.png" data-width="828" data-height="328"></div><div class="metadata inlineImage" data-filename="61815_05_f14-t2.png" data-width="595" data-height="235" data-alt="Web designers working on computers. A shade chart that has many colors arranged in the form of a table. There are four columns and eight rows. Eight different colors are shown in the eight rows. The columns denote how these colors would be seen by people with common color deficiencies. While the column on the left shows how the colors appear to a normal person, the second from left shows the appearance of these colors to people with Protanopia (missing red cones). The third from left indicates color appearance to Deuteranopia (missing green cones) and the one on the right indicates color appearance to Tritanopia (missing blue cones). The section on the right shows the overall hue for each row."></div><div class="nb_media image wide"><div class="mediaTitle" id="KFBQRZ37DXMNG7K8C466" id-sequence="341"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.14</span></span><span class="mediaAssetTitle">Making Websites Accessible.</span></div><div class="mediaDescription" id="YWCCQW7UBNP5VCCDF298" id-sequence="342"><p>Web designers have found colors that work for people with typical color vision and people who have color deficiency. This set of colors shows how different shades would be seen by people with typical vision and by people with three of the most common forms of color deficiency. Even though these colors are seen differently by the three groups, nobody mistakes one shade for another.</p></div> <div class="imageContainer" style="width:595px;height:235px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f14-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Web designers working on computers. A shade chart that has many colors arranged in the form of a table. There are four columns and eight rows. Eight different colors are shown in the eight rows. The columns denote how these colors would be seen by people with common color deficiencies. While the column on the left shows how the colors appear to a normal person, the second from left shows the appearance of these colors to people with Protanopia (missing red cones). The third from left indicates color appearance to Deuteranopia (missing green cones) and the one on the right indicates color appearance to Tritanopia (missing blue cones). The section on the right shows the overall hue for each row." width="595" height="235" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Paul Dronsfield/Alamy Stock Photo </div> </div></div></div> </div></div> <a data-type="pageEnd" name="PageEnd_161" data-page="161"></a> </div> <div class="pageSection" id="QAVGA4K1K0UR0NST0800" id-sequence="343"> <h3 id="LHTG5379XYVS5SVBZ424" id-sequence="344"><span class="headingText">Recognizing Objects</span></h3> <p id="VXFS5MFPK5RKU5CZB734" id-sequence="345">We asked earlier how your brain uses incoming visual signals to recognize your grandmother. A bottom-up approach assumes that as information moves from the retina to higher levels of visual processing, more complicated responses are built from simpler input. In this hierarchical model, the result would be a hypothetical “grandmother cell,” or a single cell that could combine all previous input and processing to tell you that your grandmother is at the door.</p> <p id="VJKK4PZ4WDR1J5059436" id-sequence="346">Although the hierarchical model is attractive in many ways, it does not fit perfectly with what we know about the visual system. First, we would need a large number of single neurons to respond to all the objects and the events that we can recognize visually. In addition, the hierarchical model is unable to account for top-down processing. <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="CSAY8N6V4JNADZA5T609" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="CSAY8N6V4JNADZA5T609">Figure 5.15a</a> may appear to be a random pattern of black dots on a white background. <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="CSAY8N6V4JNADZA5T609" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="CSAY8N6V4JNADZA5T609">Figure 5.15b</a> may not appear to be a recognizable object at all. The sensations produced by these stimuli lead to no meaningful perceptions. However, once we tell you that the first image is a Dalmatian dog and the second image is a cow, you can instantly pick out their shapes. Now that you know what the images are, you will probably never see them again the way you did initially. Recognizing these objects requires knowledge and memory of what Dalmatians and cows look like. It is unlikely that a single cortical cell acting as a Dalmatian or cow detector could incorporate such complex inputs from memory.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e6 rs_skip" id="CSAY8N6V4JNADZA5T609" clrenderdata="[&quot;QSBS8V4H8ETWV4L1D461&quot;]" id-sequence="347"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f15-t2.png" data-width="514" data-height="217" data-alt="Two images in black and white marked a) and b). The images look like back dots on a white surface. Closer inspection reveals that the a) is a Dalmatian and b) a cow."></div><div class="nb_media image wide"><div class="mediaTitle" id="HYNUFXZ95YEPVB4VN239" id-sequence="348"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.15</span></span><span class="mediaAssetTitle">Can You Figure out What These Images Are?</span></div><div class="mediaDescription" id="LVDUXHW8BVB8SVKWN351" id-sequence="349"><p>(a) This might look like a splattering of black dots on a white page until you learn that it represents a Dalmatian dog. (b) Top-down processing ensures that once you know this is a photo of a cow, you can pick out its features easily.</p></div> <div class="imageContainer" style="width:514px;height:217px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f15-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Two images in black and white marked a) and b). The images look like back dots on a white surface. Closer inspection reveals that the a) is a Dalmatian and b) a cow." width="514" height="217" class="rs_skip"></div><div class="mediaCredit">From Richard L. Gregory (2005). “The Medawar Lecture 2001 Knowledge for Vision: Vision for Knowledge,” Philosophical Transactions of the Royal Society B, 360, 1231–1251, by permission of the Royal Society. From American Journal of Psychology. Copyright © 1951 by the Board of Trustees of the University of Illinois. Used with permission of the University of Illinois Press. K. M. Dallenbach (1951). “A Puzzle-Picture with a New Principle of Concealment,” 64(3) (July 1951), 431–433. </div> </div></div></div> <p id="RFFXG9L6S9VVS9C9U967" id-sequence="350">If we don’t use single cells to recognize objects, how can we accomplish this task? The visual system might perform a mathematical analysis of the visual field (De Valois &amp; De Valois, 1980). While the hierarchical model implies a reality built out of individual bars<a data-type="pageEnd" name="PageEnd_162" data-page="162"></a> and edges, the mathematical approach suggests that we analyze patterns of lines. The simplest patterns of lines are gratings, as shown in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="XMMZHQ06HLJJ15UP7921" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="XMMZHQ06HLJJ15UP7921">Figure 5.16</a>. Gratings can vary along two dimensions: frequency and contrast. High-frequency gratings have many bars in a given distance and provide fine detail, while low-frequency gratings have relatively few bars. High-contrast gratings have large differences in intensity between adjacent bars, like black next to white. The print you are reading in is an example of high contrast because the black letters are quite different from the white background. Low-contrast gratings have subtler differences in intensity between bars, such as dark gray next to black.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e7 rs_skip" id="XMMZHQ06HLJJ15UP7921" clrenderdata="[&quot;YYWSNEXBKU2SD4HVF667&quot;]" id-sequence="351"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f16-t2.png" data-width="370" data-height="440" data-alt="A graph showing gratings. The X axis is divided into two parts. On the left is 1 degree with 3 cycles of low frequency and on the right is 1 degree with 6 cycles of high frequency. On the Y axis is contrast - both high and low. The graph is a series of black and white stripes of varying thickness."></div><div class="nb_media image"><div class="mediaTitle" id="HUBA3DNWNTFFGN3LA675" id-sequence="352"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.16</span></span><span class="mediaAssetTitle">Features of Gratings.</span></div><div class="mediaDescription" id="MSQFGG9FUY9V6D1Q3654" id-sequence="353"><p>An alternative to the hierarchical model suggests that the visual system analyzes the visual environment as a collection of patterns, like these gratings. Gratings vary in frequency (number of bars in a given distance) and contrast (the difference in light intensity from one bar to the next).</p></div> <div class="imageContainer" style="width:370px;height:440px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f16-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A graph showing gratings. The X axis is divided into two parts. On the left is 1 degree with 3 cycles of low frequency and on the right is 1 degree with 6 cycles of high frequency. On the Y axis is contrast - both high and low. The graph is a series of black and white stripes of varying thickness." width="370" height="440" class="rs_skip"></div> </div></div></div> <p id="TAUPQ5HDRMZCFYAJG511" id-sequence="354">Observing responses to gratings gives us a window into the visual capacities of other species. At a certain point of contrast and frequency, gratings look plain gray. Animals can be trained to make a distinction between gratings and gray circles. For example, if a bird is rewarded with food for pecking at a disk with a grating but not for pecking a uniform gray disk, any performance that is better than 50-50, or chance, indicates that the bird can see the difference between the grating and the gray. We can graph the range of gratings that are visible to the observer as a function of their contrast and frequency. <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="LVJUVNFG7V76J1CMK050" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="LVJUVNFG7V76J1CMK050">Figure 5.17</a> illustrates the visible ranges for human adults and cats. Compared to human adults, cats see less detail. However, cats see large (low-frequency), low-contrast objects better than humans do. Large, low-contrast shadows on the wall may get kitty’s attention but not yours. You will think kitty is chasing ghosts again.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e8 rs_skip" id="LVJUVNFG7V76J1CMK050" clrenderdata="[&quot;PGBD1C0ZTTPGF4CVN954&quot;]" id-sequence="355"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f17-t2.png" data-width="431" data-height="394" data-alt="A line graph shows the frequency and contrast levels visible for human adults and cats. The horizontal axis represents frequency, cycles per degree, ranging from 0.1 to 100 in multiples of 10 with the indicators at left representing less frequency or less detail and that at right representing high frequency or fine detail. The vertical axis represents contrast ranging from 1 to 1000 in multiples of 10 with the indicators at the bottom representing high contrast and that at the top representing low contrast. A curve representing visible ranges for cats rises from a frequency below 0.1 and contrast above 10 up to a frequency between 0.1 and 1 and a contrast of 100. The curve then falls steeply up to a frequency just below 10 and contrast level at 1. Another curve representing visible ranges for human adults rises from a frequency at 0.1 and contrast at 10 up to a frequency just below 10 and a contrast below 1000. The curve then falls steeply up to a frequency just below 100 and contrast level at 1. Both the curves are in the form of inverted V. The region between the left arms of the cats curve and the humans curve represents gratings visible to cats, but not to humans. The region between the left arm of the humans curve and the right arm of the cats curve represents gratings visible to both cats and humans. The region between the right arms of the cats curve and the humans curve represents gratings visible to humans, but not to cats. All values are approximate."></div><div class="nb_media image"><div class="mediaTitle" id="YANSVJ8MJ2ZPEQBUU995" id-sequence="356"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.17</span></span><span class="mediaAssetTitle">What Do Cats See?</span></div><div class="mediaDescription" id="XUKMFX98P9WBJDGMF819" id-sequence="357"><p>Using gratings, we get a window into the visual world of the cat. By comparing gratings to a uniform gray disk, we can learn when a grating with a certain contrast and frequency simply looks gray to humans or cats. We can see better detail than kitty, but she sees large shadows that we don’t even notice.</p></div> <div class="imageContainer" style="width:431px;height:394px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f17-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A line graph shows the frequency and contrast levels visible for human adults and cats. The horizontal axis represents frequency, cycles per degree, ranging from 0.1 to 100 in multiples of 10 with the indicators at left representing less frequency or less detail and that at right representing high frequency or fine detail. The vertical axis represents contrast ranging from 1 to 1000 in multiples of 10 with the indicators at the bottom representing high contrast and that at the top representing low contrast. A curve representing visible ranges for cats rises from a frequency below 0.1 and contrast above 10 up to a frequency between 0.1 and 1 and a contrast of 100. The curve then falls steeply up to a frequency just below 10 and contrast level at 1. Another curve representing visible ranges for human adults rises from a frequency at 0.1 and contrast at 10 up to a frequency just below 10 and a contrast below 1000. The curve then falls steeply up to a frequency just below 100 and contrast level at 1. Both the curves are in the form of inverted V. The region between the left arms of the cats curve and the humans curve represents gratings visible to cats, but not to humans. The region between the left arm of the humans curve and the right arm of the cats curve represents gratings visible to both cats and humans. The region between the right arms of the cats curve and the humans curve represents gratings visible to humans, but not to cats. All values are approximate." width="431" height="394" class="rs_skip"></div><div class="mediaCredit">Julie Src/ <a target="_blank" id="BPVGD7RSQ72TU38KP722" name="BPVGD7RSQ72TU38KP722" class="external" href="http://Shutterstock.com" id-sequence="358">Shutterstock.com</a></div> </div></div></div> </div> <div class="pageSection" id="CEUPAWBVM6LTTBXC8178" id-sequence="359"> <h3 id="GYJZH6SQ6Q0JLKG9U798" id-sequence="360"><span class="headingText">Gestalt Psychology</span></h3> <p id="WUHJ1E0VQ5W32JVY4909" id-sequence="361">As we observed in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="RGLWV0E24Q79YQJK9785" data-chapter-id="RGLWV0E24Q79YQJK9785" data-element-id="RGLWV0E24Q79YQJK9785">Chapter 1</a>, a group of German researchers known as the Gestalt psychologists tackled visual perception with a number of ingenious observations. The word <em>Gestalt</em> is derived from the German word for “shape.” These psychologists objected to efforts by Wilhelm Wundt and the structuralists to reduce human experience to its building blocks, or elements. Instead, the Gestalt psychologists argued that some experiences lose information and value when divided into parts. The main thesis of the Gestalt psychologists, as stated by Kurt Koffka, maintains, “It is more correct to say that the whole is something else than the sum of its parts” (<span class="citation" id="JVQND57JZDZ620RJJ639" id-sequence="362">Koffka, 1935</span>, p. 176).</p> <p id="JFJJNL91VN35GMJ56787" id-sequence="363">According to the Gestalt psychologists, we are born with built-in tendencies to organize incoming sensory information in certain ways. This natural ability to organize simplifies the problem of recognizing objects (<span class="citation" id="VAAMTMTG9PNQFL2D4351" id-sequence="364">Biederman, 1987</span>). One organizing principle suggests that we spontaneously divide a scene into a main figure and ground. We frequently assume that the figure stands in front of most of the ground, and it seems to have more substance and shape. It is possible<a data-type="pageEnd" name="PageEnd_163" data-page="163"></a> to construct ambiguous images, like the vase on this page, in which the parts of the image seem to switch roles as figure or ground.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14e9 rs_skip" id="ZSPGDFJYA3CYX8P9S105" clrenderdata="[&quot;MANTE9TEAZ1ZF89FV410&quot;]" id-sequence="365"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf13-t2.jpg" data-width="367" data-height="454" data-alt="A white vase with gold detailing on it."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="HYXUR3ZTABRR0VAAA208" id-sequence="366"><p>The Gestalt psychologists believe we naturally see the difference between objects and their background, but this figure is designed to make us switch back and forth from the vase to the background faces. This vase was designed to commemorate an anniversary of Queen Elizabeth II of England (face on the right) and her husband, Prince Philip (face on the left).</p></div> <div class="imageContainer" style="width:367px;height:454px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf13-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A white vase with gold detailing on it." width="367" height="454" class="rs_skip"></div><div class="mediaCredit">SSPL/Science Museum / Art Resource, NY </div> </div></div></div> <p id="JGESUVFV6K7JXH2DY556" id-sequence="367">A second Gestalt principle is proximity (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="QBMBLH98AZ3FMPV8T435" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="QBMBLH98AZ3FMPV8T435">Figure 5.18</a>). Objects that are close together tend to be grouped together. The dots that make up our Dalmatian in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="LVJUVNFG7V76J1CMK050" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="LVJUVNFG7V76J1CMK050">Figure 5.17a</a> are close together, suggesting they belong to the same object. The principle of similarity states that similar stimuli are grouped together. On a close examination of the dog image, the dots that make up the dog are similar to one another and slightly different (more rounded perhaps) than the dots making up the remainder of the image.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14ea rs_skip" id="QBMBLH98AZ3FMPV8T435" clrenderdata="[&quot;PGTPGF35DX3AS49H9936&quot;]" id-sequence="368"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f18-t2.png" data-width="305" data-height="398" data-alt="A group of three illustrations showing the gestalt principles of similarity and proximity. Image a) shows an ambiguous pattern using blue dots in a grid like pattern. Image b) shows similarity - two sets of grids created using dots. First one has both blue and yellow dots arranged in alternating columns vertically. The second one shows blue and yellow dots arranged in alternating rows horizontally. Image c) shows similarity - two sets of grids created using only blue dots. First one is arranged vertically while the second one is arranged horizontally."></div><div class="nb_media image"><div class="mediaTitle" id="JSPV3SFWMEEHF5TT8468" id-sequence="369"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.18</span></span><span class="mediaAssetTitle">The Gestalt Principles of Proximity and Similarity.</span></div><div class="mediaDescription" id="JTUKZN9WB2VX2ZCF6603" id-sequence="370"><p>The set of dots in (a) do not appear to have any particular relationship with one another, but when we color rows in (b), we suddenly see the dots in columns or rows. Moving two columns or rows slightly closer to each other in (c) makes us see the array differently too.</p></div> <div class="imageContainer" style="width:305px;height:398px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f18-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A group of three illustrations showing the gestalt principles of similarity and proximity. Image a) shows an ambiguous pattern using blue dots in a grid like pattern. Image b) shows similarity - two sets of grids created using dots. First one has both blue and yellow dots arranged in alternating columns vertically. The second one shows blue and yellow dots arranged in alternating rows horizontally. Image c) shows similarity - two sets of grids created using only blue dots. First one is arranged vertically while the second one is arranged horizontally." width="305" height="398" class="rs_skip"></div> </div></div></div> <p id="MLME5Q7PW1L540PZ9332" id-sequence="371">The principle of continuity suggests that we assume that points that form smooth lines when connected probably belong together (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="UPEAPF8LQPKGTEFPN714" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="UPEAPF8LQPKGTEFPN714">Figure 5.19</a>). In our dog picture, continuity helps us see the border of the curb or sidewalk and the ring of shadow around the base of the tree. Continuity is perhaps a little less useful in identifying the dog, although we can pick out the lines forming the legs.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14eb rs_skip" id="UPEAPF8LQPKGTEFPN714" clrenderdata="[&quot;UBGERTGSW6FG9XY1R242&quot;]" id-sequence="372"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f19-t2.png" data-width="389" data-height="170" data-alt="A white curlicue on a blue background."></div><div class="nb_media image"><div class="mediaTitle" id="FHVJZ92RFDNFVJPNJ391" id-sequence="373"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.19</span></span><span class="mediaAssetTitle">The Gestalt Principle of Continuity.</span></div><div class="mediaDescription" id="JGTNPW7AHDLM3Q1AM685" id-sequence="374"><p>The Gestalt principle of continuity says that we perceive points forming a smooth line as belonging to the same object. If you follow this knot, you can see that it is formed by two objects, but our initial perception is of a single form.</p></div> <div class="imageContainer" style="width:389px;height:170px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f19-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A white curlicue on a blue background." width="389" height="170" class="rs_skip"></div> </div></div></div> <p id="WHQXHM9PBS53GSCMX670" id-sequence="375">Closure occurs when people see a complete, unbroken image even when there are gaps in the lines forming the image (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="FNFLWUK39XMD9WKHU124" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="FNFLWUK39XMD9WKHU124">Figure 5.20</a>). We use this approach in viewing the dog in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="CSAY8N6V4JNADZA5T609" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="CSAY8N6V4JNADZA5T609">Figure 5.15a</a> when we “fill in the blanks” formed by the white parts of its body.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14ec rs_skip" id="FNFLWUK39XMD9WKHU124" clrenderdata="[&quot;FEBFW9LA8Y3VS2F85259&quot;]" id-sequence="376"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f20-t2.png" data-width="170" data-height="190" data-alt="The logo of the WWF."></div><div class="nb_media image"><div class="mediaTitle" id="EEUZ7Y1WVJ7Y4ZQA0767" id-sequence="377"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.20</span></span><span class="mediaAssetTitle">The Gestalt Principle of Closure.</span></div><div class="mediaDescription" id="WDHMTGNF057C8SX6K999" id-sequence="378"><p>Because of the principle of closure, we “fill in the blanks” to see a single object, the World Wildlife Fund logo, although it is made up of several objects.</p></div> <div class="imageContainer" style="width:170px;height:190px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f20-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="The logo of the WWF." width="170" height="190" class="rs_skip"></div> </div></div></div> <p id="NBGUQ5VALFXZ5APB0405" id-sequence="379">Finally, the Gestalt psychologists believed in the principle of simplicity, which suggests that we will use the simplest solution to a perceptual problem. This principle may help explain the fun in pictures like that of our Dalmatian dog. It is simpler to assume that this is a random splash of black dots on white background. Finding a hidden picture within the dots is not the simplest solution, which may account for our surprise.</p> </div> <div class="pageSection" id="PNSMDQCZY39H3A47T826" id-sequence="380"> <h3 id="JZDZSAAJU0MW03WF2453" id-sequence="381"><span class="headingText">Recognizing Depth</span></h3> <p id="AKCZHC3LRCL2BCFFG806" id-sequence="382">An image projected onto the retina is two dimensional, as flat as the sheet of paper or screen on which these words appear. Somehow, the brain manages to construct a three-dimensional (3D) image from these data. Adelbert Ames constructed a room that was named in his honor, the Ames Room, which illustrated vulnerabilities in our <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f8e" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f8e"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f8e" id="MQVWR6J76J5AEHCLR852" id-sequence="383"><span class="index nb_hidden clAnnotationDecoration rs_skip">depth perception</span><span class="term"><span class="primaryTerm" id="DKQH9EML495BP9CA6035" id-sequence="384">depth perception</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The ability to use the two-dimensional image projected on the retina to perceive three dimensions</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f8e">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="DKQH9EML495BP9CA6035" id-sequence="384">depth perception</span></span>
        <span class="definition rs_skip">The ability to use the two-dimensional image projected on the retina to perceive three dimensions</span>
        <span class="pointer"></span>
    </span>
</span> (<span class="citation" id="WDMQ2PZ079182R42E709" id-sequence="385">Ittleson, 1952</span>). When viewed directly from the front, the room appears to be a rectangle. People within the room, shown in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="WJXWRLEL2W4G6NN1W681" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="WJXWRLEL2W4G6NN1W681">Figure 5.21</a>, seem to be larger or smaller than normal. This distortion of perceived size results from the room’s ability to confuse our judgment of distance.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14ed rs_skip" id="WJXWRLEL2W4G6NN1W681" clrenderdata="[&quot;DKPD48ZVJ7M21QAJA366&quot;]" id-sequence="386"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f21-t3.png" data-width="759" data-height="299"></div><div class="metadata inlineImage" data-filename="61815_05_f21-t2.png" data-width="595" data-height="231" data-alt="An image of two men standing in a room at two corners and a diagram explaining how the human eye perceives the trick. A diagram in the shape of a parallelogram with a large man in one end and a small in the other end of the slanting plane. The observer’s eye perceives the small man on the same plane as the large man."></div><div class="nb_media image wide"><div class="mediaTitle" id="MWXPUQ7NJ5GSHR7WS725" id-sequence="387"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.21</span></span><span class="mediaAssetTitle">The Ames Room Tricks Our Depth Perception.</span></div><div class="mediaDescription" id="LRNGSKUQ04AHGHYRS441" id-sequence="388"><p>Many distance cues, such as the apparently rectangular windows, conspire to make these two people look different. The person on the right is much closer to us than the person on the left. The diagram shows the actual layout of the Ames Room.</p></div> <div class="imageContainer" style="width:595px;height:231px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f21-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An image of two men standing in a room at two corners and a diagram explaining how the human eye perceives the trick. A diagram in the shape of a parallelogram with a large man in one end and a small in the other end of the slanting plane. The observer’s eye perceives the small man on the same plane as the large man." width="595" height="231" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Field Museum Library/Contributor/Archive Photos/Getty Images </div> </div></div></div> <p id="BGESHDUJBLTTUGG4Q677" id-sequence="389">To construct a 3D image, we use both <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f8f" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f8f"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f8f" id="LGBNJUG1JAD6VTXK5066" id-sequence="390"><span class="index nb_hidden clAnnotationDecoration rs_skip">monocular cues</span><span class="term"><span class="primaryTerm" id="GKAWVUMV6B9D68ACU368" id-sequence="391">monocular cues</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A depth cue that requires the use of only one eye</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f8f">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="GKAWVUMV6B9D68ACU368" id-sequence="391">monocular cues</span></span>
        <span class="definition rs_skip">A depth cue that requires the use of only one eye</span>
        <span class="pointer"></span>
    </span>
</span> (one eye) and <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f90" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f90"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f90" id="VLFLQQ80EBVZCNFGZ461" id-sequence="392"><span class="index nb_hidden clAnnotationDecoration rs_skip">binocular cues</span><span class="term"><span class="primaryTerm" id="TKLHW3XJ60P5Z59YE316" id-sequence="393">binocular cues</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A depth cue that requires the use of both eyes</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f90">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="TKLHW3XJ60P5Z59YE316" id-sequence="393">binocular cues</span></span>
        <span class="definition rs_skip">A depth cue that requires the use of both eyes</span>
        <span class="pointer"></span>
    </span>
</span> (two eyes). Many monocular cues are found in paintings because the artists attempt to provide an illusion of depth in their two-dimensional pieces. The use of linear perspective, or the apparent convergence of parallel lines at the horizon, by Italian artists during the 15th century provided a realism unknown in earlier works. Linear perspective revolutionized the video game and movie industries, beginning humbly with Sega’s <em>Zaxxon</em> in 1982 and advancing to the ever more realistic environments of <em>Halo</em>, Pixar’s animated films, and the 2009 film <em>Avatar</em>. Other monocular cues include texture gradients and shading. We can see more texture in objects that are close to us, while the texture of distant objects is relatively blurry. Shading and the use of highlights can be used to suggest curved surfaces.</p> <p id="GJMKSJGNDX68UQV8J681" id-sequence="394">Among the most powerful monocular depth cues is occlusion, or the blocking of images of distant objects by closer objects. We also use relative size to judge the distance of objects, although this method requires you to be familiar with the real<a data-type="pageEnd" name="PageEnd_164" data-page="164"></a> size of an object. We know how big people are. When the retinal image of a person is small, we infer that the person is farther from us than when the retinal image of a person is larger.</p> <p id="ATLAJWA602H2XV26Z861" id-sequence="395">Several illusions result from our use of monocular cues to judge depth. Relative size helps to explain the moon illusion. You may have noticed that the moon appears to be larger when it is just above the hills on the horizon than when it is straight overhead. The moon maintains a steady orbit 239,000 miles (385,000 km) above the Earth. How can we account for the discrepancy in its apparent size? When viewed overhead, the moon is seen without intervening objects, such as trees and hills, that might provide cues about its size and distance. However, when viewed near the horizon, we see the moon against a backdrop of familiar objects whose sizes we know well. We expect trees and hills to be smaller at the horizon than when they are close to us, and if we group the moon with those objects, we adjust its apparent size as well. The next time you are viewing the full moon as it rises over the hills, form a peephole with your hand, and you will see the moon in its normal small size. Although some researchers argue that atmospheric differences between the two viewpoints may contribute to the illusion, viewing the moon through your hand should demonstrate that most of the effect arises from your use of other objects to judge distance.</p> <p id="BAEUUCFFUFA22SKSX037" id-sequence="396">In the Müller–Lyer illusion, shown in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="LWFSM30894RU4D3CX286" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="LWFSM30894RU4D3CX286">Figure 5.22</a>, we see the line with outward-pointing arrowheads as being farther from our position, even though the main lines project images of equal length on the retina. The Ponzo illusion, shown in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="FWSU5WV5HC97NX3H9124" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="FWSU5WV5HC97NX3H9124">Figure 5.23</a>, confounds size and distance judgments in a similar fashion. The parallel lines signal depth, leading us to believe that the upper horizontal line is farther away than the lower line. If both lines project the same image on the retina, the more distant line must be longer.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14ee rs_skip" id="LWFSM30894RU4D3CX286" clrenderdata="[&quot;ZNLHUQKYX8BH77ZB1681&quot;]" id-sequence="397"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f22-t2.png" data-width="557" data-height="347" data-alt="A line drawing depicting the Muller Lyer illusion."></div><div class="nb_media image wide"><div class="mediaTitle" id="ELSKY7XXC8EL4RBE0752" id-sequence="398"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.22</span></span><span class="mediaAssetTitle">The Müller–Lyer Illusion.</span></div><div class="mediaDescription" id="EDNZ41H5Y4L6HS78W405" id-sequence="399"><p>You might find it hard to believe that the two red vertical lines are actually the same length.</p></div> <div class="imageContainer" style="width:557px;height:347px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f22-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A line drawing depicting the Muller Lyer illusion." width="557" height="347" class="rs_skip"></div> </div></div></div> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14ef rs_skip" id="FWSU5WV5HC97NX3H9124" clrenderdata="[&quot;DQCNS4F8KZ9PA0GNY941&quot;]" id-sequence="400"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f23-t2.jpg" data-width="334" data-height="336" data-alt="An illustration showing a train track like structure depicting the Ponzo illusion."></div><div class="nb_media image"><div class="mediaTitle" id="LCNF0C7LRYH65MWPL807" id-sequence="401"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.23</span></span><span class="mediaAssetTitle">The Ponzo Illusion.</span></div><div class="mediaDescription" id="EDKNBPCC8JZFRE1VH880" id-sequence="402"><p>We perceive depth because of linear perspective, which in turn make us see the upper horizontal bar as more distant than the lower bar. Even though they are the same length, the bar perceived as more distant looks longer.</p></div> <div class="imageContainer" style="width:334px;height:336px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f23-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing a train track like structure depicting the Ponzo illusion." width="334" height="336" class="rs_skip"></div> </div></div></div> <p id="PZHQJVN7LQZ318MT7973" id-sequence="403">So far, we have discussed monocular cues that involve a person and a scene that is not moving. The introduction of motion can heighten the impression of depth. As you ride in a car, focus your gaze at a distant point. The objects you pass will appear to be moving in the opposite direction of your car, with closer objects appearing to move faster than distant objects. Next, focus on a point about midway between you and the horizon. Now, the closer objects<a data-type="pageEnd" name="PageEnd_165" data-page="165"></a> will continue to move in the opposite direction, but more distant objects appear to be traveling with you. This motion parallax has been used to enhance the 3D feeling in video games.</p> <p id="XFUDD8HXF1WLG5MWU374" id-sequence="404">One of our most effective depth cues is <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f91" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f91"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f91" id="LMEBXM7SFPVSWETQK246" id-sequence="405"><span class="index nb_hidden clAnnotationDecoration rs_skip">retinal disparity</span><span class="term"><span class="primaryTerm" id="KHBG9PN4GP3VWUA6G938" id-sequence="406">retinal disparity</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The difference between the images projected onto each eye</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f91">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="KHBG9PN4GP3VWUA6G938" id-sequence="406">retinal disparity</span></span>
        <span class="definition rs_skip">The difference between the images projected onto each eye</span>
        <span class="pointer"></span>
    </span>
</span>. Because this cue requires the use of both eyes, we refer to retinal disparity as a binocular cue. Predator species, including ourselves, have eyes placed in the front of the head facing forward. As a result of this configuration, the visual scenes observed by the two eyes are different and overlapping, as shown in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="WWSPTKLSDVUBCB6EP994" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BCPZ9771W6YM1Y0X4422" data-element-id="WWSPTKLSDVUBCB6EP994">Figure 5.24</a>. The differences between the images projected onto each eye are called disparities. These disparities do not tell us how far away an object is. Instead, they provide information about the relative distance between two objects in the visual field. As the distance between the objects increases, disparity increases. To illustrate the sensitivity of this system, you can identify an object as being 1 millimeter (about .04 inch) closer than another at a distance of 1 meter (about 3.3 feet) from your body, or a difference of 0.1% (<span class="citation" id="YRHNNGL6467KSRGMV986" id-sequence="407">Blake &amp; Sekuler, 2006</span>).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f0 rs_skip" id="WWSPTKLSDVUBCB6EP994" clrenderdata="[&quot;RQAGUSGMMKP2XSXFU035&quot;]" id-sequence="408"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f24-t2.png" data-width="393" data-height="362" data-alt="An illustration showing how the retinas of the two eyes perceive two objects A and B."></div><div class="nb_media image"><div class="mediaTitle" id="FUNGFGJ36QBV53USS317" id-sequence="409"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.24</span></span><span class="mediaAssetTitle">Retinal Disparity.</span></div><div class="mediaDescription" id="QQFS000SWHUNHTLTG449" id-sequence="410"><p>The right and left eyes see slightly overlapping versions of the visual scene in front of us. We can use the retinal disparity, or discrepancy between the locations of two objects on the two retinas, as a sensitive depth cue.</p></div> <div class="imageContainer" style="width:393px;height:362px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f24-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing how the retinas of the two eyes perceive two objects A and B." width="393" height="362" class="rs_skip"></div> </div></div></div> <p id="ESPWX60JVM1UR4Q15907" id-sequence="411">Why would this binocular depth system be an advantage to predators? Most prey species do an excellent job of hiding, often aided by an appearance that blends into the nearby environment. However, retinal disparity allows us to spot tiny variations in the depths of objects in the visual field. This might make an animal stand out against its background, even though it is well camouflaged. Retinal disparity has been used to identify camouflaged military equipment and counterfeit currency. Retinal disparity is imitated by cameras used to film 3D movies, which have two lenses separated by about the same distance as our two eyes.</p> </div> <div class="footnotes"></div></div><div id="footer" id-sequence="412"></div></div><div class="container page "><div id="header" id-sequence="415"><div id="breadcrumb-old" id-sequence="416" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="417" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="FDZNDB1WGQAF7Q2UF887" id-sequence="418"><span class="sectionLabel rs_skip">5-2d</span> <span class="headingText">Developmental and Individual Differences in Vision</span></h2></div><div class="content" id="MCYC71NXZJ0X2YZ41055_content" id-sequence="419"> <p id="KVJMVDY1S90BSGM4G650" id-sequence="420">Although human infants can’t report what they see, we can take advantage of their longer gazing at patterns than at uniform stimuli, like a patch of a single color. This allows us to construct graphs of the contrasts and the frequencies to<a data-type="pageEnd" name="PageEnd_166" data-page="166"></a> which children respond, similar to those we saw previously for cats. Based on these analyses, we know that human infants see everything human adults see but with less detail. To see well, the infant also needs more contrast than the adult. These findings help explain children’s preferences for large, high-contrast objects.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f1 rs_skip" id="HQGDKTMPG4TUBWGPA263" clrenderdata="[&quot;DSAMAG1XP93ULHTW0629&quot;]" id-sequence="421"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf42-t2.jpg" data-width="334" data-height="221" data-alt="Video games, such as Minecraft, incorporate many monocular cues to provide an experience of depth. The standard-sized blocks used to build structures in the game are separated by lines, which when placed in a row provide linear perspective. Texture gradients, shading, and relative size (players understand the size of the blocks well) also contribute to perceived depth."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="UABEG7EHRDVC1XXXU684" id-sequence="422"><p>Video games, such as Minecraft, incorporate many monocular cues to provide an experience of depth. The standard-sized blocks used to build structures in the game are separated by lines, which when placed in a row provide linear perspective. Texture gradients, shading, and relative size (players understand the size of the blocks well) also contribute to perceived depth.</p></div> <div class="imageContainer" style="width:334px;height:221px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf42-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Video games, such as Minecraft, incorporate many monocular cues to provide an experience of depth. The standard-sized blocks used to build structures in the game are separated by lines, which when placed in a row provide linear perspective. Texture gradients, shading, and relative size (players understand the size of the blocks well) also contribute to perceived depth." width="334" height="221" class="rs_skip"></div><div class="mediaCredit">veryan dale/Alamy Stock Photo </div> </div></div></div> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f2 rs_skip" id="KBBK9VYHTCXZNVM9Y016" clrenderdata="[&quot;KMBFM6CMPN9DPEJ1B107&quot;]" id-sequence="423"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf14-t2.jpg" data-width="308" data-height="238" data-alt="The two lenses of 3D cameras are separated by about 2 inches (about 50 millimeters), mimicking the distance between two human eyes that makes retinal disparity possible."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="WWHH7SAC3K71S53PD928" id-sequence="424"><p>The two lenses of 3D cameras are separated by about 2 inches (about 50 millimeters), mimicking the distance between two human eyes that makes retinal disparity possible.</p></div> <div class="imageContainer" style="width:308px;height:238px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf14-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="The two lenses of 3D cameras are separated by about 2 inches (about 50 millimeters), mimicking the distance between two human eyes that makes retinal disparity possible." width="308" height="238" class="rs_skip"></div><div class="mediaCredit">YOSHIKAZU TSUNO/AFP/Getty Images/Newscom </div> </div></div></div> <p id="KUCTY948Q841AWFJ2485" id-sequence="425">The photographs shown below provide insight into the visual world of the infant. Frequencies that cannot be seen by the infant have been removed from each photograph. Other research shows that infants as young as 4 months not only show binocular disparity, but also show normal adult responses to color (<span class="citation" id="MANB9DMV1ZDUSU72H470" id-sequence="426">Bornstein, Kessen, &amp; Weiskopf, 1976</span>). Other depth cues discussed previously develop early too. Infants as young as 2 months understand occlusion (<span class="citation" id="BNXBY5W75BUA3SJFR552" id-sequence="427">Johnson &amp; Aslin, 1995</span>), and the use of the relative size of objects to judge depth appears between the ages of 5 and 7 months (<span class="citation" id="RQRMJLNLD374RV9EC119" id-sequence="428">Granrud, Haake, &amp; Yonas, 1985</span>). Infants’ abilities to perceive faces also develop quite rapidly, as 2-day-old newborns spend more time gazing at their mothers’ faces than at a stranger’s face (<span class="citation" id="YDQCASPQSSUWASW85449" id-sequence="429">Bushnell, 2001</span>; also see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="FWESRAGQVRBX40E4E415" data-chapter-id="FWESRAGQVRBX40E4E415" data-element-id="FWESRAGQVRBX40E4E415">Chapter 11</a>).</p> <p id="VWBK57171QBUFFSWQ676" id-sequence="430">Predictable changes occur in other aspects of human vision as we grow older. Accommodation of the lens, which allows us to change focus from near to far objects, becomes slower beginning in middle adulthood. Older adults respond more slowly to changes in brightness, such as leaving a dark theater into the sunlight. The muscles of the iris lose their elasticity, so pupils remain smaller, further reducing vision by limiting the amount of light that enters the eye. The lens of the eye begins to yellow, which protects the eye from ultraviolet radiation but affects the perception of color.</p> <p id="BDLSU22SQ5BG06BS3004" id-sequence="431">At any age, individual differences shape what people see. In addition to the color deficiencies discussed previously, people differ in their abilities to see near and far objects. Those who<a data-type="pageEnd" name="PageEnd_167" data-page="167"></a> deviate from the average often wear corrective lenses or undergo laser surgery to reshape the cornea. The most common visual problems result from eyeball length, with elongated eyeballs interfering with a person’s vision for distant objects (nearsightedness) and shortened eyeballs interfering with vision for close-up objects (farsightedness), as in reading. Vision is also affected by astigmatism, which means that the surface of the cornea is uneven. You can test yourself for astigmatism by looking at <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="ANUGDL3N96LZUEP5L640" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MCYC71NXZJ0X2YZ41055" data-element-id="ANUGDL3N96LZUEP5L640">Figure 5.25</a>.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f3 rs_skip" id="KRHCW8GY307GJ88Y3482" clrenderdata="[&quot;FEGG4MEYLEBGTJBQH741&quot;]" id-sequence="432"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_unf15-t3.jpg" data-width="814" data-height="200"></div><div class="metadata inlineImage" data-filename="61815_05_unf15-t2.jpg" data-width="595" data-height="141" data-alt="Four photos of the same person. From left to right, the images become blurry to sharp."></div><div class="nb_media image unnumbered wide"><div class="mediaDescription" id="TPPMLJL5HDFQ3UZWY765" id-sequence="433"><p>We can filter out the frequencies and contrast that a baby cannot see to simulate what the world looks like to an infant.</p></div> <div class="imageContainer" style="width:595px;height:141px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf15-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Four photos of the same person. From left to right, the images become blurry to sharp." width="595" height="141" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Felix Mizioznikov/ <a target="_blank" id="VBYPNSARSWPPHHDH1898" name="VBYPNSARSWPPHHDH1898" class="external" href="http://Shutterstock.com" id-sequence="434">Shutterstock.com</a></div> </div></div></div> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f4 rs_skip" id="ANUGDL3N96LZUEP5L640" clrenderdata="[&quot;ABCPFCX0YPHBVUW6W970&quot;]" id-sequence="435"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f25-t2.png" data-width="324" data-height="324" data-alt="An illustration of a black dot with spoke like lines radiating out of it."></div><div class="nb_media image"><div class="mediaTitle" id="RLWW7EEJJFDL9VMWK103" id-sequence="436"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.25</span></span><span class="mediaAssetTitle">Astigmatism.</span></div><div class="mediaDescription" id="MRVZ7YPY2XB55NDS8326" id-sequence="437"><p>If you have astigmatism, which results from an uneven surface of your corneas, some spokes of this figure will appear darker than others.</p></div> <div class="imageContainer" style="width:324px;height:324px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f25-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration of a black dot with spoke like lines radiating out of it." width="324" height="324" class="rs_skip"></div> </div></div></div> <div class="container dependent mt_connectingtoresearch narrative  rs_skip" id="RJFVM2U0KNCASJ4BP964" label="connectingtoresearch" id-sequence="438"><div class="containerHeading"><span class="label">Connecting to Research </span><h3 id="XAWCBZDZ6EHZ929DK304" id-sequence="439">Do Children with Autism See the World Differently?</h3></div><div class="sidebarContent" id="RJFVM2U0KNCASJ4BP964_sidebarcontent" id-sequence="440"> <p id="PLAACPB9WU3QFN3EU188" id-sequence="441">In addition to deficits in social skills and language (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="KNKVM7TED147CWT15523" data-chapter-id="KNKVM7TED147CWT15523" data-element-id="KNKVM7TED147CWT15523">Chapter 14</a>), individuals with autism spectrum disorder (ASD) often demonstrate unusual responses to stimuli. In some cases, children seem to barely notice things, but in others, children seem to be hypersensitive to stimulation. Psychologists agree that diagnosing autism as early as possible leads to the best treatment outcomes. Identifying differences in sensation and perception at early ages might lead to better diagnoses (<span class="citation" id="TCUL8LSRE8YAB06FW253" id-sequence="442">Gliga et al., 2015</span>).</p> <p id="VEVEN0BQU8SH8TYPE631" id-sequence="443"><strong><em>The Question: Do superior visual search skills predict autism?</em></strong></p> <div class="pageSection" id="UNLS7CDY3SN1JV9SQ909" id-sequence="444"> <h3 id="GMSF6CF39QBQGQ2CG727" id-sequence="445"><span class="headingText">Methods</span></h3> <p id="HHXALXQ7MSFX50TTE742" id-sequence="446">Eighty-two infants with older siblings diagnosed with ASD (high-risk) and 27 control infants with no relatives with ASD took part in a visual search task and measures of ASD risk (response to name, eye contact, social reciprocity, and imitation). Eye-tracking was used to measure the child’s attending to the “odd” character within a visual array (<a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="MSLK2J97UME8U835R213" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MCYC71NXZJ0X2YZ41055" data-element-id="MSLK2J97UME8U835R213">Figure 5.26</a>). Children were assessed at 9 months, 15 months, and 2 years of age.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f5 rs_skip" id="MSLK2J97UME8U835R213" clrenderdata="[&quot;KHMHA2BPA2PTEEHH9186&quot;]" id-sequence="447"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f26-t3.png" data-width="743" data-height="167"></div><div class="metadata inlineImage" data-filename="61815_05_f26-t2.png" data-width="595" data-height="127" data-alt="Four squares each with a pattern in a different color. The first square on the left has Xs written in red in a circle. There is one V in the circle. The next square has orange Xs with a +. The third has green Xs with an S and the fourth has Xs in circles with one O in a circle."></div><div class="nb_media image wide"><div class="mediaTitle" id="GYNAVQW5ZDZBDPTW0685" id-sequence="448"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.26</span></span><span class="mediaAssetTitle">Superior Visual Search in Autism</span></div><div class="mediaDescription" id="CZJUH68L8ETJJMDH4884" id-sequence="449"><p>Eye-tracking showed that 9-month-old infants at risk for autism spectrum disorder (ASD) were able to find the “odd” character within each display faster than children at low risk for ASD. Performance on this visual search task predicted the severity of autism symptoms at the ages of 15 months and 2 years.</p></div> <div class="imageContainer" style="width:595px;height:127px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f26-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Four squares each with a pattern in a different color. The first square on the left has Xs written in red in a circle. There is one V in the circle. The next square has orange Xs with a +. The third has green Xs with an S and the fourth has Xs in circles with one O in a circle." width="595" height="127" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div> </div></div></div> </div> <div class="pageSection" id="DXAJ2GNJ9JJVAFNJP190" id-sequence="450"> <h3 id="AQXSQU3BDGCGR5BR7771" id-sequence="451"><span class="headingText">Ethics</span></h3> <p id="RJLG5CHYDACANJ7LY094" id-sequence="452">Children enjoy extra protection when they serve as research participants. Researchers must present parents with a thorough informed consent form, and great care must be taken to avoid coercion through rewards for participation. Procedures must be suited to the young participants to avoid fatigue. Parents whose children show evidence of risk for ASD should be referred to services.</p> </div> <div class="pageSection" id="NANN8RUWTRCQZ0VXD261" id-sequence="453"> <h3 id="XPGFDP9ZJKQRALCV7702" id-sequence="454"><span class="headingText">Results</span></h3> <p id="HWMPA3B3EYW0HHQRH080" id-sequence="455">Superior performance on the visual search task at 9 months was correlated with indicators of ASD symptoms at 15 months and 2 years of age.</p> </div> <div class="pageSection" id="YVXHGLTL7XULD0G6E162" id-sequence="456"> <h3 id="GDVJZ1EC6VF8PJ41H452" id-sequence="457"><span class="headingText">Conclusions</span></h3> <p id="MSEF307RU4HB2YF9P970" id-sequence="458">Assessments of visual search might prove useful in identifying infants who may be diagnosed with autism spectrum disorder. The results also emphasize the role of attention and perception in the development of ASD. Previously, much research about ASD has focused on social deficits, but these might in fact emerge from more basic differences in information processing.</p> </div> </div></div><a data-type="pageEnd" name="PageEnd_168" data-page="168"></a> <div class="container dependent mt_diversevoicesinpsychology narrative  rs_skip" id="QEEQN1EAQJ0WEM0L4392" label="diversevoicesinpsychology" id-sequence="459"><div class="containerHeading"><span class="label"> Diverse Voices in Psychology</span><h3 id="PCMGG2MZ1LXHS1H7L585" id-sequence="460">Culture Shapes Eye Movements</h3></div><div class="sidebarContent" id="QEEQN1EAQJ0WEM0L4392_sidebarcontent" id-sequence="461"> <p id="KTGBQTWVYAM46QKH5528" id-sequence="462">Psychologists have discovered a number of differences in the ways that East Asians (e.g., people from China, Korea, and Japan) and European/North Americans process information. In general, Eastern cultures process information holistically, which means processing is based on context and relationships. In contrast, Western cultures process information analytically, focusing on salient objects and forming categories. To illustrate this difference, consider the following images (<span class="citation" id="FWKWEQWMTZAYSWX5K062" id-sequence="463">Chiu, 1972</span>). Of the three images in each box, think about which go together, and ask yourself why you think this is correct. Children from East Asian cultures were most likely to group the woman shape with the baby shape and the cow with the grass, whereas children from Western cultures grouped the man and woman shape and the cow and chicken shape. The East Asian children reported grouping the woman and the baby together because the mother takes care of the baby (relationship), whereas the Western children grouped the man and woman together because they shared a category as adults. East Asian children grouped the cow and grass together (context: the cow eats grass), whereas the Western children grouped the chicken and cow together (both are animals). Further research demonstrated that all children begin by using holistic reasoning regardless of culture, but Western children begin to ignore context and focus more on objects beginning around the age of 5 years.</p> <p id="YCJEKSHE6CWKL2UD8264" id-sequence="464">What possible aspects of culture might shape thinking in this way? It is possible that child-rearing practices, such as the emphasis on appropriate social behavior in East Asian cultures versus the emphasis on labeling objects in Western culture, could lead to a divergent emphasis on context or object.</p> <p id="CHEQ7VMFSNS3L7VYR025" id-sequence="465">The roots of this type of thinking might go even deeper. East Asians and Westerners have been found to use different eye movement strategies while scanning faces (<span class="citation" id="FCBXR2KEMYWBSK8TU221" id-sequence="466">Kelly, Miellet, &amp; Caldara, 2010</span>). Eye-tracking shows that Westerners focus on the eye and mouth regions of a face, while East Asians focus on the nose area (<a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="TWMDHSN3TS24UP1XY003" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MCYC71NXZJ0X2YZ41055" data-element-id="TWMDHSN3TS24UP1XY003">Figure 5.27a</a> and <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="TWMDHSN3TS24UP1XY003" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MCYC71NXZJ0X2YZ41055" data-element-id="TWMDHSN3TS24UP1XY003">b</a>). This difference might arise from social norms. Eye contact is considered rude in East Asian cultures but is expected in Western cultures. However, <span class="citation" id="GNNDEFL0SL1Q091FZ179" id-sequence="467"> Kelly et al. (2010)</span> found the same cultural differences when participants looked at the faces of sheep and at artificial figures known as Greebles.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f6 rs_skip" id="TWMDHSN3TS24UP1XY003" clrenderdata="[&quot;BBFNATBCNK3Z8QC3G405&quot;]" id-sequence="468"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f27-t3.png" data-width="663" data-height="642"></div><div class="metadata inlineImage" data-filename="61815_05_f27-t2.png" data-width="595" data-height="574" data-alt="Two sets of images showing two different kinds of illustrations in different styles. The set at the top is marked a) and has two parts on the left is the silhouette of a man, a woman and a child. On the right is the illustration of a hen, a cow and grass. Below this is illustration b) that shows human faces on the left column during learning and recognition, sheep in the middle column and greebles in the right column. On the right is a scale called WC observers."></div><div class="nb_media image wide"><div class="mediaTitle"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.27a and b</span></span></div><div class="mediaDescription" id="BLFCX3A6J9L6GQ4TN527" id-sequence="469"><p>(a) <strong>Which Ones Go Together?</strong> Western children group the man and woman shapes and the cow and chicken shapes using categorical reasoning. East Asian children group the woman and baby shapes and the cow and grass together based on relationships and context. (b) <strong>Western and East Asian Participants Use Different Face Scanning Approaches</strong> Eye-tracking shows that Western participants focus on the eyes and the mouth of a face, whereas East Asian participants focus on the nose. To control for possible social norm influences (eye contact is considered rude in some East Asian cultures), the researchers investigated scanning approaches using sheep and make-believe stimuli known as Greebles. The same principles held for these alternate stimuli, possibly reflecting cultural differences in the emphasis on objects and context.</p></div> <div class="imageContainer" style="width:595px;height:574px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f27-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Two sets of images showing two different kinds of illustrations in different styles. The set at the top is marked a) and has two parts on the left is the silhouette of a man, a woman and a child. On the right is the illustration of a hen, a cow and grass. Below this is illustration b) that shows human faces on the left column during learning and recognition, sheep in the middle column and greebles in the right column. On the right is a scale called WC observers." width="595" height="574" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div> </div></div></div> <p id="MRUJ2U13RG1ZKQ9RG107" id-sequence="470">While researchers often attribute these processing differences to the effects of living within an individualistic (Western) versus collectivistic (Eastern) culture, we cannot rule out the effects of genetics and biology without further research. Repeating these studies with second or third generation Asian Americans, for example, might provide insight into the extent of the cultural influences.</p> </div></div> <a data-type="pageEnd" name="PageEnd_169" data-page="169"></a> <div class="container dependent mt_thinkingscientifically narrative  rs_skip" id="SZVT6YFE25PY8WPTN196" label="thinkingscientifically" id-sequence="471"><div class="containerHeading"><span class="label">Thinking Scientifically </span><h3 id="YNVBNZ5XVLG6NEUNG273" id-sequence="472">The Roger Shepard Parallelogram Illusion: “Turning the Tables”</h3></div><div class="sidebarContent" id="SZVT6YFE25PY8WPTN196_sidebarcontent" id-sequence="473"> <p id="VUQMS4FKFQQJYC10Z416" id-sequence="474">Anyone can tell, simply by looking, whether two tabletops are the same shape, right? For instance, most people would agree that the shapes and sizes of the two tabletops depicted in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="RQFTLZ3Y0RG3W1R1E062" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MCYC71NXZJ0X2YZ41055" data-element-id="RQFTLZ3Y0RG3W1R1E062">Figure 5.28</a> are different. One tabletop appears to be rectangular, while the other appears to be more square. As much as our perceptions may tell us otherwise, these tabletops are identical. To verify this, trace one of the tabletops, and then rotate it to place it above the other. You will be able to prove that these tables have identical tops. It is not our eyes (sensory receptors) that deceive us; it is our brains.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f7 rs_skip" id="RQFTLZ3Y0RG3W1R1E062" clrenderdata="[&quot;YVQNCT6YR38R2YL8K613&quot;]" id-sequence="475"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f28-t3.png" data-width="679" data-height="439"></div><div class="metadata inlineImage" data-filename="61815_05_f28-t2.png" data-width="595" data-height="379" data-alt="Line drawings of two tables. The tables are positioned in such a way so as to cause difficulty in understanding the lines in table a) are the same as those in table b)."></div><div class="nb_media image wide"><div class="mediaTitle" id="GXMFELHAY6XQ3U8D3712" id-sequence="476"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.28</span></span><span class="mediaAssetTitle">Are These Tables the Same or Different?</span></div><div class="mediaDescription" id="SCSGDK7G91E6158ZA921" id-sequence="477"><p>You will probably want to use a ruler to prove to yourself that the lines marked “a” are the same and that the lines marked “b” are the same.</p></div> <div class="imageContainer" style="width:595px;height:379px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f28-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Line drawings of two tables. The tables are positioned in such a way so as to cause difficulty in understanding the lines in table a) are the same as those in table b)." width="595" height="379" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div> </div></div></div> <p id="QBVP7B2KGSXC37S7V559" id-sequence="478">Roger Shepard combined a profound scientific curiosity with a love of mischief. Shepard developed a number of creative visual illusions, including “Turning the Tables,” which he illustrated himself (Shepard, 1990). The visual illusion produced in this illustration results from our use of a visual system designed to cope with the three dimensions of the physical world on stimuli that have only two dimensions.</p> <div class="excerpt" id="YHKUT45VQ3WRHTLPT760" id-sequence="479"> <p id="ZRRUNLS59WXWS6D6K826" id-sequence="480">In Roger Shepard’s words:</p> <p id="KBNH9X2EPUDY05J17376" id-sequence="481">The drawings … achieve their effects by means of various visual tricks. But to call them tricks is not to imply that they are without psychological significance. The tricks work by taking advantage of fundamental perceptual principles that have been shaped by natural selection in a three-dimensional world. Our ability to make pictures, which emerged only recently on an evolutionary time scale, enables us to present the eyes with visual patterns that systematically depart from the patterns that we and our ancestors experienced in nature. In considering the ways pictures can trick the eye, we can gain insight into the nature and ultimate source of the principles of visual perception. (Shepard, 1990, p. 121)</p> </div> <p id="DLVGA339AH23TSXKC864" id-sequence="482">More generally, examples like this underscore the importance of relying on scientific investigation and evidence to unveil how sensation and perception work.</p> </div></div> <a data-type="pageEnd" name="PageEnd_170" data-page="170"></a> <div class="container dependent mt_summary narrative  rs_skip" id="HVWX05E5RMLFECHEH394" label="summary" id-sequence="483"><div class="containerHeading"><span class="label">Summary <span class="ordinal">5.2</span></span><h3 id="CAUE16KGRDVGH37W8815" id-sequence="484">Important Features of the Visual System</h3></div><div class="sidebarContent" id="HVWX05E5RMLFECHEH394_sidebarcontent" id-sequence="485"> </div></div> <div class="table rs_skip" id="NPBFP28KRNYFKYVTV980" id-sequence="486"> <div class="maintable narrowtable longtable" style="height: 711px;"><table data-width="330" class="frameall" style="width: 440px;"> <colgroup><col width="200"><col width="240"></colgroup> <thead> <tr id="MJPF3BGZL28ACRHN4620" id-sequence="487"> <th id="KFYLK0U5XFS07AQ2T589" class="alignleft valignbottom underscore" id-sequence="488"><p id="FPPBHB4LM8UJT70J0935" id-sequence="489">Feature</p></th> <th id="SYEVEP2EE9ACHKFWH104" class="alignleft valignbottom underscore sidescore" id-sequence="490"><p id="RDDEEFZFA26GX3EKG711" id-sequence="491">Significance</p></th> </tr> </thead> <tbody id="GEBGWWTLRMSCQFL8D512" id-sequence="492"> <tr class="odd" id="AUPHLBSNT7MAN6T5E303" id-sequence="493"> <td id="GFPE5SF0HWZDPX7Q2206" class="alignleft valigntop underscore" id-sequence="494"><p id="MNQBVSVWSBU6T75G0198" id-sequence="495"><strong><em>Cornea</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f8 rs_skip" id="RSMUC5P2ZRUN4ZTFP477" clrenderdata="[&quot;TZRMW6MG8JZ4KLSVH836&quot;]" id-sequence="496"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf17-t2.png" data-width="98" data-height="80" data-alt="Illustration showing cornea."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:98px;height:80px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf17-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Illustration showing cornea." width="98" height="80" class="rs_skip"></div> </div></div></div></td> <td id="MMEVRBBK5LNEG1KE2103" class="alignleft valigntop sidescore underscore" id-sequence="497"><p id="MVBEY6Z7YBZUDKF4J802" id-sequence="498">Bends light toward the retina.</p></td> </tr> <tr class="even" id="WYJQPEXQDCAN76F84027" id-sequence="499"> <td id="GMPRGFAZPCSXCTKGY481" class="alignleft valigntop underscore" id-sequence="500"><p id="LJTNV4868UZFTHN3X792" id-sequence="501"><strong><em>Pupil</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14f9 rs_skip" id="QSNARLZ9KYZPRH1QL007" clrenderdata="[&quot;UMFQUW87HARBDV6YS312&quot;]" id-sequence="502"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf18-t2.png" data-width="94" data-height="80" data-alt="Illustration showing pupil."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:94px;height:80px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf18-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Illustration showing pupil." width="94" height="80" class="rs_skip"></div> </div></div></div></td> <td id="ZJDMTMKQ4W7LC49MC070" class="alignleft valigntop sidescore underscore" id-sequence="503"><p id="JNJQ4VET1SM1MMT6D531" id-sequence="504">Forms an opening in the iris.</p></td> </tr> <tr class="odd" id="ZCVFJ8VA37AL91095916" id-sequence="505"> <td id="KDATC8JJRGXFCH6A0092" class="alignleft valigntop" id-sequence="506"><p id="XEZX0P39D9822RFSM102" id-sequence="507"><strong><em>Lens</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14fa rs_skip" id="PZFKG3NM0LAWK021A996" clrenderdata="[&quot;RXBBJZJV6KTLP8AHK227&quot;]" id-sequence="508"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf19-t2.png" data-width="94" data-height="80" data-alt="Illustration showing lens."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:94px;height:80px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf19-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Illustration showing lens." width="94" height="80" class="rs_skip"></div> </div></div></div></td> <td id="WAEA32FJVHWXG6HT8397" class="alignleft valigntop sidescore underscore" id-sequence="509"><p id="UYKDR0HCQX27R53WG760" id-sequence="510">Focuses light onto the retina.</p></td> </tr> <tr class="even" id="KCYR0ZYUQKM12PPK8177" id-sequence="511"> <td id="ZNZHGHQFZPY5UEHJB237" class="alignleft valigntop underscore" id-sequence="512"><p id="CYKU6FPMNHFDRCUAT425" id-sequence="513"><strong><em>Retina</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14fb rs_skip" id="ZZJTCWH2NVYRZR560885" clrenderdata="[&quot;PFWE1JLRHX2PBD918322&quot;]" id-sequence="514"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf20-t2.png" data-width="106" data-height="79" data-alt="Illustration showing retina."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:106px;height:79px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf20-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Illustration showing retina." width="106" height="79" class="rs_skip"></div> </div></div></div></td> <td id="XWRSPGWG90MR2M0H1054" class="alignleft valigntop sidescore underscore" id-sequence="515"><p id="CFSLGU96MSA1DPZM9760" id-sequence="516">Contains rods, cones, and other visual neurons in its layer of cells.</p></td> </tr> <tr class="odd" id="LJTZ40U8V2CTRQK27593" id-sequence="517"> <td id="FQAUDQRYQDE8VCX0R531" class="alignleft valigntop underscore" id-sequence="518"><p id="NXARB1D00ULADPYNQ296" id-sequence="519"><strong><em>Fovea (area of the retina)</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14fc rs_skip" id="HWGXJUQNTCJTRGJUZ365" clrenderdata="[&quot;CXZTH534UL13E6QF5668&quot;]" id-sequence="520"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf21-t2.png" data-width="106" data-height="79" data-alt="Illustration showing fovea."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:106px;height:79px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf21-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Illustration showing fovea." width="106" height="79" class="rs_skip"></div> </div></div></div></td> <td id="NVYJCZW99UTG66P5F538" class="alignleft valigntop sidescore underscore" id-sequence="521"><p id="QYNBF8QPD25XBXFRL879" id-sequence="522">Processes detailed vision.</p></td> </tr> <tr class="even" id="JWCBMBYZYNRQF97BL210" id-sequence="523"> <td id="CGSLSMDJPKBUD145U891" class="alignleft valigntop underscore" id-sequence="524"><p id="MSWQ8XTGT1ZB2MKLZ992" id-sequence="525"><strong><em>Thalamus</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14fd rs_skip" id="GCKPV97YT509B7S2H953" clrenderdata="[&quot;FYPQSLQLR23MRV4CB497&quot;]" id-sequence="526"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf22-t2.png" data-width="93" data-height="94" data-alt="Illustration showing thalamus."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:93px;height:94px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf22-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Illustration showing thalamus." width="93" height="94" class="rs_skip"></div> </div></div></div></td> <td id="EGXGXZFTDPV75F337563" class="alignleft valigntop sidescore underscore" id-sequence="527"><p id="FDRXHFXRPLCAUFFH8925" id-sequence="528">Acts as the target for most axons forming the optic tracts.</p></td> </tr> <tr class="odd" id="PEZKNTJQW87FSX5SX173" id-sequence="529"> <td id="TAAXAB8KGYYGVX256322" class="alignleft valigntop underscore" id-sequence="530"><p id="XKQHNR1W5Y8Z0KFLQ731" id-sequence="531"><strong><em>Primary visual cortex (area in the occipital lobe)</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14fe rs_skip" id="LLWW349TT5L7DFPEL753" clrenderdata="[&quot;YXUW4HAQRRDU6R3D4396&quot;]" id-sequence="532"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf23-t2.png" data-width="108" data-height="100" data-alt="Illustration showing primary visual cortex."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:108px;height:100px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf23-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Illustration showing primary visual cortex." width="108" height="100" class="rs_skip"></div> </div></div></div></td> <td id="CQLR9TSRU8H1WRNP0392" class="alignleft valigntop sidescore underscore" id-sequence="533"><p id="JPTKE4SZEET7J2GK7914" id-sequence="534">Receives visual input from the thalamus and performs initial analysis of input.</p></td> </tr> </tbody> </table><div class="fadediv_tall"></div><div class="fadediv_wide"></div><div class="enlargetable"><img alt="Enlarge Table" title="Enlarge Table" src="/static/nbapps/media/images/enlarge.png" class="rs_skip"></div></div> <div class="byline" id="RSHFCZFQU6MXX8QMN704" id-sequence="535">Credits: Top row— <span class="orgName"> Argosy Publishing</span>, Inc.; Second row— <span class="orgName"> Argosy Publishing</span>, Inc.; Third row— <span class="orgName"> Argosy Publishing</span>, Inc.; Fourth row— <span class="orgName"> Argosy Publishing</span>, Inc.; Fifth row— <span class="orgName"> Argosy Publishing</span>, Inc.; Sixth row— <span class="orgName"> Argosy Publishing</span>, Inc.; Bottom row— <span class="orgName"> Argosy Publishing</span>, Inc.</div> </div> <a data-type="pageEnd" name="PageEnd_171" data-page="171"></a> <div class="footnotes"></div></div><div id="footer" id-sequence="536"></div></div><div class="container page "><div id="header" id-sequence="539"><div id="breadcrumb-old" id-sequence="540" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="541" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h1 id="WUACLNMNQN6GUGKR5514" id-sequence="542"><span class="sectionLabel rs_skip">5-3</span> <span class="headingText">How Do We Hear?</span></h1></div><div class="content" id="WRNRZQU3P77P17WEF982_content" id-sequence="543"> <p id="XUEP83HQUL9DH4A81325" id-sequence="544">We have spent a considerable amount of time on the sense of vision, which might be considered a dominant source of information for humans. However, when Helen Keller, who was both blind and deaf, was asked which disability affected her the most, she replied that blindness separated her from things, while deafness separated her from people. <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f92" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f92"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f92" id="GVWTPFCDRF2LYLQ99816" id-sequence="545"><span class="index nb_hidden clAnnotationDecoration rs_skip">Audition</span><span class="term"><span class="primaryTerm" id="TDDXQKFFMLQZNHMQL407" id-sequence="546">Audition</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The sense of hearing.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f92">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="TDDXQKFFMLQZNHMQL407" id-sequence="546">Audition</span></span>
        <span class="definition rs_skip">The sense of hearing.</span>
        <span class="pointer"></span>
    </span>
</span>, our sense of hearing, not only allows us to identify objects in the distance but also plays an especially important role in our ability to communicate with others through language.</p> <div class="footnotes"></div></div><div id="footer" id-sequence="547"></div></div><div class="container page "><div id="header" id-sequence="550"><div id="breadcrumb-old" id-sequence="551" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="552" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="LAHPW7HKNVF0CL2JZ170" id-sequence="553"><span class="sectionLabel rs_skip">5-3a</span> <span class="headingText">The Auditory Stimulus</span></h2></div><div class="content" id="BNLAEA4HZ7J9K48H2540_content" id-sequence="554"> <p id="FJGVSQKQMKRZ0WM6A000" id-sequence="555">Sound begins with the movement of an object, setting off waves of vibration in the form of miniature collisions between adjacent molecules in air, liquid, or solids. Because sound waves require this jostling of molecules, sound cannot occur in the vacuum of space, which contains no matter. Those explosions we enjoy in <em>Star Wars</em> films are great entertainment but not good science.</p> <p id="QRTVDCRRFA9CLWMDL033" id-sequence="556">Earlier in this chapter, we described light energy as waves with different amplitudes and frequencies. Sound waves possess the same dimensions. However, in the case of sound, the height or amplitude of the wave is encoded as loudness or intensity and the frequency of the wave is encoded as pitch. High-amplitude waves are perceived as loud, and low-amplitude waves are perceived as soft. High-frequency waves (many cycles per unit of time) are perceived as high pitched, whereas low-frequency sounds are low pitched. In sound, amplitude is measured in units called decibels (dB), and frequency is measured in cycles per second, or hertz (Hz; see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="LNSNQ9ZSQ049FRQLV220" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BNLAEA4HZ7J9K48H2540" data-element-id="LNSNQ9ZSQ049FRQLV220">Figure 5.29</a>).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf14ff rs_skip" id="LNSNQ9ZSQ049FRQLV220" clrenderdata="[&quot;EZHVNMVAWD9VP6LCZ659&quot;]" id-sequence="557"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f29-t2.png" data-width="492" data-height="198" data-alt="Five waves of different wavelengths and amplitudes are shown from top to bottom. Amplitude is measured in decibel and wavelength in hertz. The amplitude and the pitch of the waves decrease from top to bottom whereas the wavelength of the waves increases."></div><div class="nb_media image wide"><div class="mediaTitle" id="VCJZ716CBLJR8AY48077" id-sequence="558"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.29</span></span><span class="mediaAssetTitle">Features of Sound.</span></div><div class="mediaDescription" id="JJXUKQE17RLPXXMZB942" id-sequence="559"><p>Like the light energy we see, sound waves are characterized by frequency and amplitude. We perceive frequency as the pitch of the sound (high or low), measured in hertz (Hz), and we perceive amplitude as the loudness of the sound, measured in decibels (dB).</p></div> <div class="imageContainer" style="width:492px;height:198px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f29-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Five waves of different wavelengths and amplitudes are shown from top to bottom. Amplitude is measured in decibel and wavelength in hertz. The amplitude and the pitch of the waves decrease from top to bottom whereas the wavelength of the waves increases." width="492" height="198" class="rs_skip"></div> </div></div></div> <div class="container dependent margin narrative  rs_skip" id="FSBQSQ44BEWTSD5J5658" id-sequence="560"><div class="sidebarContent" id="FSBQSQ44BEWTSD5J5658_sidebarcontent" id-sequence="561"> <p id="CSWJ3T8D1UPULKPXC149" id-sequence="562">In addition to dizziness and nausea, being exposed to infrasound makes people report feelings of chills down the spine, fear, and revulsion, even though they cannot consciously detect the sound. Some scientists believe that infrasound produced in certain places leads people to conclude the places are haunted.</p> </div></div> <p id="KXHU5M0KX591CCYKY090" id-sequence="563">As we observed in the case of the light spectrum, parts of the auditory spectrum are outside the range of human hearing. Ultrasound stimuli occur at frequencies above the range of human hearing, beginning around 20,000 Hz (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="TNBVDKF4TXD3T4AGP413" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="BNLAEA4HZ7J9K48H2540" data-element-id="TNBVDKF4TXD3T4AGP413">Figure 5.30</a>). Ultrasound can be used to clean jewelry or your teeth or to produce noninvasive medical images. Infrasound refers to frequencies below the range of human hearing, or less than 20 Hz. Many animals, including elephants and marine mammals, use infrasound for communication. Infrasound is particularly effective in water because it allows sound to travel long distances.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1500 rs_skip" id="TNBVDKF4TXD3T4AGP413" clrenderdata="[&quot;LAEETB4RJ4JD4LM3M777&quot;]" id-sequence="564"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f30-t3.png" data-width="792" data-height="401"></div><div class="metadata inlineImage" data-filename="61815_05_f30-t2.png" data-width="595" data-height="299" data-alt="An illustration showing the range of hearing of human beings. This illustration shows that infrasound is below the range of human hearing while ultrasound is above it. The picture also shows the range of various other animals such as bats, dolphins, insects, birds, frog, dog and blue whale. Earthquakes and volcanoes are also shown."></div><div class="nb_media image wide"><div class="mediaTitle" id="KPCPSVFH2R358YY2E843" id-sequence="565"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.30</span></span><span class="mediaAssetTitle">Range of Hearing.</span></div><div class="mediaDescription" id="FDATUUQJSUKFSD6EB069" id-sequence="566"><p>Ultrasounds are above the range of human hearing, and infrasounds are below the range of human hearing.</p></div> <div class="imageContainer" style="width:595px;height:299px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f30-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing the range of hearing of human beings. This illustration shows that infrasound is below the range of human hearing while ultrasound is above it. The picture also shows the range of various other animals such as bats, dolphins, insects, birds, frog, dog and blue whale. Earthquakes and volcanoes are also shown." width="595" height="299" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Photos, left to right: pathdoc/ <a target="_blank" id="WGJVCYM0CH1NQ9LSU829" name="WGJVCYM0CH1NQ9LSU829" class="external" href="http://Shutterstock.com" id-sequence="567">Shutterstock.com</a>; Mike Hill/Alamy Stock Photo; Eric Carr/Alamy Stock Photo; Erik Lam/ <a target="_blank" id="BBKPF49LZ1ZJU9RE8975" name="BBKPF49LZ1ZJU9RE8975" class="external" href="http://Shutterstock.com" id-sequence="568">Shutterstock.com</a>; Keith J. Smith/Alamy Stock Photo; Matthias Clamer/Getty Images </div> </div></div></div> <div class="footnotes"></div></div><div id="footer" id-sequence="569"></div></div><div class="container page "><div id="header" id-sequence="572"><div id="breadcrumb-old" id-sequence="573" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="574" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="CPCTH8FCJS0DHBJ0H868" id-sequence="575"><span class="sectionLabel rs_skip">5-3b</span> <span class="headingText">The Biology of Audition</span></h2></div><div class="content" id="TFXE8EUL9PYRQB87P719_content" id-sequence="576"> <p id="TETHHKSDBKM3D8ZCK201" id-sequence="577">Human audition begins with an ear located on either side of the head. The components that make up the ear are divided into three parts: the outer ear, the middle ear, and the inner ear (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="RSFKTT2B1YUHTD1GY638" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="TFXE8EUL9PYRQB87P719" data-element-id="RSFKTT2B1YUHTD1GY638">Figure 5.31</a>).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1501 rs_skip" id="RSFKTT2B1YUHTD1GY638" clrenderdata="[&quot;GCHKH4AZYK0245EMU366&quot;]" id-sequence="578"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f31-t2.png" data-width="505" data-height="357" data-alt="An illustration showing the human ear and its parts - the outer, middle and inner ear. The labeled parts of the outer ear are pinna, bone and auditory canal. The labeled parts of the middle ear are ossicles, tympanic membrane and Eustachian tube. The labeled parts of the inner ear are oval window, auditory nerve and cochlea."></div><div class="nb_media image wide"><div class="mediaTitle" id="GLQN32TAHS2M0CW3K725" id-sequence="579"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.31</span></span><span class="mediaAssetTitle">Parts of the Ear.</span></div><div class="mediaDescription" id="LASKWMB36SDRWYRLB404" id-sequence="580"><p>The human ear is divided into the outer, middle, and inner ear.</p></div> <div class="imageContainer" style="width:505px;height:357px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f31-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing the human ear and its parts - the outer, middle and inner ear. The labeled parts of the outer ear are pinna, bone and auditory canal. The labeled parts of the middle ear are ossicles, tympanic membrane and Eustachian tube. The labeled parts of the inner ear are oval window, auditory nerve and cochlea." width="505" height="357" class="rs_skip"></div> </div></div></div> <div class="container dependent margin narrative  rs_skip" id="VVRU0K5BAQ2LRKRB5168" id-sequence="581"><div class="sidebarContent" id="VVRU0K5BAQ2LRKRB5168_sidebarcontent" id-sequence="582"> <p id="UNFJFRNMKT4CA28EN549" id-sequence="583">The fetus has no bubble of air in the middle ear, having never been exposed to air. Because fluids do a better job than air of transmitting sound waves, there is good evidence that the fetus can hear outside sounds, such as mother’s voice, quite well during the final trimester of pregnancy.</p> </div></div> <p id="REDPUBQJYW3E4TR1W518" id-sequence="584">The outer ear consists of the structures that are visible outside the body. The pinna, the outer visible structure of the ear, collects and focuses sounds, like a funnel. In addition, the pinna helps us localize sounds as being above or below the head. Sounds collected by the pinna are channeled through the auditory canal, which ends at the tympanic membrane, or eardrum, at the boundary between the outer and the middle ear. The boundary between the<a data-type="pageEnd" name="PageEnd_172" data-page="172"></a> middle and the inner ear is formed by another membrane, the oval window. The gap between these two membranes is bridged by a series of tiny bones. The purpose of these bones is to transfer sound energy from the air of the outer and middle ear to the fluid found in the inner ear. Sound waves are weakened as they move from air to water. When you try to talk to friends underwater, the result is rather garbled. Without the adjustments provided by these small bones, we would lose a large amount of sound energy as the sound waves moved from air to liquid.</p><a data-type="pageEnd" name="PageEnd_173" data-page="173"></a> <p id="XWUJ7KZCAEM9EPWXU471" id-sequence="585">The inner ear contains two sets of fluid-filled cavities embedded in the bone of the skull. One set is part of the vestibular system, which we will discuss later in this chapter. The other set is the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f93" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f93"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f93" id="XMGGE7KK93R73PKF6258" id-sequence="586"><span class="index nb_hidden clAnnotationDecoration rs_skip">cochlea</span><span class="term"><span class="primaryTerm" id="GSXS4CAEHW6MQ84C3103" id-sequence="587">cochlea</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The structure in the inner ear that contains auditory receptors.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f93">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="GSXS4CAEHW6MQ84C3103" id-sequence="587">cochlea</span></span>
        <span class="definition rs_skip">The structure in the inner ear that contains auditory receptors.</span>
        <span class="pointer"></span>
    </span>
</span>, from the Greek word for “snail.” When rolled up like a snail shell, the human cochlea is about the size of a pea. It contains specialized receptor cells that respond to vibrations transmitted to the inner ear.</p> <p id="HCMKQN52W4SPJGZ73893" id-sequence="588">The cochlea is a complex structure, which is better understood if we pretend to unroll it (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="YKKTBXDFBQZCR4J8F784" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="TFXE8EUL9PYRQB87P719" data-element-id="YKKTBXDFBQZCR4J8F784">Figure 5.32</a>). The cochlea may be divided into three parallel chambers divided from one another by membranes. Two of these chambers, the vestibular canal and the tympanic canal, are connected at the apex of the cochlea, or the point farthest from the oval window. Vibrations transmitted by the bones of the middle ear to the oval window produce waves in the fluid of the vestibular canal that travel around the apex and back through the tympanic canal. Lying between the vestibular and the tympanic canals is the cochlear duct. The cochlear duct is separated from the tympanic canal by the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f94" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f94"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f94" id="NTLX99HVDSULABTG6474" id-sequence="589"><span class="index nb_hidden clAnnotationDecoration rs_skip">basilar membrane</span><span class="term"><span class="primaryTerm" id="NNZMPR29SPQYT8HNN264" id-sequence="590">basilar membrane</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Membrane in the cochlea on which the organ of Corti is located.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f94">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="NNZMPR29SPQYT8HNN264" id-sequence="590">basilar membrane</span></span>
        <span class="definition rs_skip">Membrane in the cochlea on which the organ of Corti is located.</span>
        <span class="pointer"></span>
    </span>
</span>. Resting on top of the basilar membrane is the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f95" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f95"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f95" id="BLBKTB24JWDL1NLP3085" id-sequence="591"><span class="index nb_hidden clAnnotationDecoration rs_skip">organ of Corti</span><span class="term"><span class="primaryTerm" id="RGGX2HF2LCM120B45000" id-sequence="592">organ of Corti</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A structure located on the basilar membrane that contains auditory receptors.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f95">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="RGGX2HF2LCM120B45000" id-sequence="592">organ of Corti</span></span>
        <span class="definition rs_skip">A structure located on the basilar membrane that contains auditory receptors.</span>
        <span class="pointer"></span>
    </span>
</span>, which contains many rows of hair cells that transduce sound energy into neural signals. Each human ear has about 15,500 of these hair cells.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1502 rs_skip" id="YKKTBXDFBQZCR4J8F784" clrenderdata="[&quot;UVGKLB2LH5R62FU28726&quot;]" id-sequence="593"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f32-t2.png" data-width="550" data-height="328" data-alt="An illustration showing how sound waves travel through the ear. There are two parts - the labeled parts of the picture at the top are vestibular system and cochlea. The labeled parts of the picture at the bottom are oval window, round window, vestibular canal, tympanic canal, basilar membrane, cochlear duct, apex and the sound wave."></div><div class="nb_media image wide"><div class="mediaTitle" id="GTSFFMCPWLFSXV9WF307" id-sequence="594"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.32</span></span><span class="mediaAssetTitle">Perception of Pitch.</span></div><div class="mediaDescription" id="VLSVHQT0WSRF3S4WT408" id-sequence="595"><p>Sound waves produce peak responses on the basilar membrane according to their frequencies. Like the strings on a musical instrument, high tones produce the greatest response at the narrow, stiff base of the basilar membrane, while low tones produce the greatest response at the wide, floppy part of the basilar membrane near the apex. Sound waves travel through the cochlea from the oval window, around the apex, and back to the round window. The waves cause movement of tiny hair cells in the cochlear duct, which we perceive as sound.</p></div> <div class="imageContainer" style="width:550px;height:328px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f32-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing how sound waves travel through the ear. There are two parts - the labeled parts of the picture at the top are vestibular system and cochlea. The labeled parts of the picture at the bottom are oval window, round window, vestibular canal, tympanic canal, basilar membrane, cochlear duct, apex and the sound wave." width="550" height="328" class="rs_skip"></div> </div></div></div> <p id="ASQJ9K03FSPTFSUG3527" id-sequence="596">As waves travel through the cochlea, the basilar membrane responds with a wavelike motion, similar to the crack of a whip. The movement of the basilar membrane causes the hair cells of the organ of Corti to move back and forth within the fluid of the cochlear duct. Bending the hair cells stimulates the release of neurotransmitters onto the cells of the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f96" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f96"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f96" id="TQSHPUS8R6NZL4RHX080" id-sequence="597"><span class="index nb_hidden clAnnotationDecoration rs_skip">auditory nerve</span><span class="term"><span class="primaryTerm" id="WWQC7AG7W8RLFY19B573" id-sequence="598">auditory nerve</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The nerve carrying sound information from the cochlea to the brain.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f96">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="WWQC7AG7W8RLFY19B573" id-sequence="598">auditory nerve</span></span>
        <span class="definition rs_skip">The nerve carrying sound information from the cochlea to the brain.</span>
        <span class="pointer"></span>
    </span>
</span>. The basilar membrane needs to move very little before the hair cells are stimulated. If the hairlike structures extending from the top of the hair cells were the size of the Eiffel Tower in Paris, the movement required to produce a neural response would be the equivalent of 1 centimeter, about 0.4 inch (<span class="citation" id="FQEEAYDQ45KUBHPNK233" id-sequence="599">Hudspeth, 1983</span>).</p> <p id="BDRYMPU68CNSBFLYK651" id-sequence="600">As we mentioned earlier, hair cells stimulate axons forming the auditory nerve. One branch of each auditory nerve cell makes contact with the hair cells, while the other branch proceeds to the medulla of the brainstem. From the medulla, sound information is sent to the midbrain, which manages reflexive responses to sound, such as turning toward the source of a loud noise. In addition, the midbrain participates in sound localization, or the identification of a source of sound.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1503 rs_skip" id="YEMQZ8GRAVDMN6LYU637" clrenderdata="[&quot;LMAXQZ1JMW7PCM1WS502&quot;]" id-sequence="601"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf24-t2.jpg" data-width="421" data-height="310" data-alt="A picture of the brain. The labeled parts are temporal lobe, frontal lobe, parietal lobe and occipital lobe. The primary auditory cortex and secondary auditory cortex are also labeled."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="QHKXURAN0VPEC1ZGF953" id-sequence="602"><p>The movement of tiny hair cells in the inner ear produces neural signals that travel to the brain.</p></div> <div class="imageContainer" style="width:421px;height:310px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf24-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A picture of the brain. The labeled parts are temporal lobe, frontal lobe, parietal lobe and occipital lobe. The primary auditory cortex and secondary auditory cortex are also labeled." width="421" height="310" class="rs_skip"></div><div class="mediaCredit">Prof. P.M. Motta/Univ. “La Sapienza”, Rome/Science Source </div> </div></div></div> <p id="XMZQU1PBA91726ZKZ136" id-sequence="603">The midbrain passes information to the thalamus, which in turn sends sound information to the primary auditory cortex, located in the temporal lobe. The primary auditory cortex conducts the first basic analysis of the wavelengths and amplitudes of incoming information (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="DYBXCQ6RCRQ63JXVG666" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="TFXE8EUL9PYRQB87P719" data-element-id="DYBXCQ6RCRQ63JXVG666">Figure 5.33</a>). Surrounding the primary auditory cortex<a data-type="pageEnd" name="PageEnd_174" data-page="174"></a> are areas of secondary auditory cortex that respond to complex types of stimuli, like clicks, noise, and sounds with particular patterns.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1504 rs_skip" id="DYBXCQ6RCRQ63JXVG666" clrenderdata="[&quot;QUXF8JGJFC7AT1XQ8540&quot;]" id-sequence="604"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f33-t2.png" data-width="406" data-height="181" data-alt="An enlarged image of the tiny hair cells present in the inner ear."></div><div class="nb_media image"><div class="mediaTitle" id="KVQP51JM1FSHUG66B101" id-sequence="605"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.33</span></span><span class="mediaAssetTitle">Auditory Cortex.</span></div><div class="mediaDescription" id="SWVJA977W8CEUDP1R570" id-sequence="606"><p>The auditory cortex is located in the temporal lobe. The primary auditory cortex processes basic features of sound while the surrounding secondary auditory cortex processes more complex sounds, such as clicks and general noise.</p></div> <div class="imageContainer" style="width:406px;height:181px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f33-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An enlarged image of the tiny hair cells present in the inner ear." width="406" height="181" class="rs_skip"></div> </div></div></div> <div class="footnotes"></div></div><div id="footer" id-sequence="607"></div></div><div class="container page "><div id="header" id-sequence="610"><div id="breadcrumb-old" id-sequence="611" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="612" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="VXMHPMYF47X2N8SW4850" id-sequence="613"><span class="sectionLabel rs_skip">5-3c</span> <span class="headingText">Auditory Perception and Cognition</span></h2></div><div class="content" id="KYVXYMRVY8Y7HXMHG320_content" id-sequence="614"> <p id="KNSLEKM7FY53M546M620" id-sequence="615">Now that we have an understanding of the structures and the pathways used to process the sensations that lead to the perception of sound, we turn our attention to the brain’s interpretation and organization of these sounds in terms of pitch, loudness, and spatial localization.</p> <div class="pageSection" id="SZJE2YHTYD8UTHHRJ781" id-sequence="616"> <h3 id="JULHZF5DNR7703293016" id-sequence="617"><span class="headingText">Pitch Perception</span></h3> <p id="DCKX3N12FM196WT7W199" id-sequence="618">Perception of pitch begins with the basilar membrane of the cochlea (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="YKKTBXDFBQZCR4J8F784" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="TFXE8EUL9PYRQB87P719" data-element-id="YKKTBXDFBQZCR4J8F784">Figure 5.32</a>). Place theory suggests that the frequency of a sound is correlated with the part of the basilar membrane showing a peak response. The base of the basilar membrane, closest to the oval window, is narrow and stiff. In contrast, at its farthest point near the apex, the basilar membrane is wide and flexible. If you are familiar with stringed instruments like guitars, you know that high tones are produced by striking the taut, small strings, and low tones are produced by striking the floppy, wide strings. The same principle holds for the basilar membrane. High-frequency tones produce the maximum movement of the basilar membrane near the base, while low-frequency tones produce maximum movement near the apex. The hair cells riding above these areas of peak movement show a maximum response. Place theory works well for sounds above 4,000 Hz, which is about the frequency produced by striking the highest key on a piano, C8. Below frequencies of 4,000 Hz, the response of the basilar membrane does not allow precise localization. In these cases, we appear to use another principle described as temporal theory, in which the patterns of neural firing match the frequency of a sound.</p> </div> <div class="pageSection" id="DKEFDJ5XM460XWXPC295" id-sequence="619"> <h3 id="TKCFCULEH25JSV3Z9571" id-sequence="620"><span class="headingText">Perceiving Loudness</span></h3> <p id="NYDV3K3XBQCQWP7E4100" id-sequence="621">Humans can perceive sounds that vary in intensity by a factor of more than 10 billion, from the softest sound we can detect up to the sound made by a jet engine at takeoff, which causes pain and structural damage to the ear. <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="XKQXQTUH87VE618RL872" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="KYVXYMRVY8Y7HXMHG320" data-element-id="XKQXQTUH87VE618RL872">Table 5.2</a> identifies the intensity levels of many common stimuli, measured in the logarithmic decibel scale. Our<a data-type="pageEnd" name="PageEnd_175" data-page="175"></a> perception of loudness does not change at the same rate as actual intensity. When the intensity of a sound stimulus is 10 times greater than before, we perceive it as being only twice as loud (<span class="citation" id="MTZYWHDY5LW1ZGHCM541" id-sequence="622">Stevens, 1960</span>).</p> <div class="table rs_skip" id="XKQXQTUH87VE618RL872" id-sequence="623"><div class="containerHeading"><span class="label">Table <span class="ordinal">5.2</span></span><h3 id="DTZJAGUZHK2KY9BEJ746" id-sequence="624">Loudness of Common Sounds</h3></div> <div class="maintable narrowtable" style="height: auto;"><table data-width="300" class="frameall" style="width: 400px;"> <colgroup><col width="200"><col width="200"></colgroup> <thead> <tr id="CZMJTHPGHF8TKNKDG283" id-sequence="625"> <th id="ETSBQN4504CCBNQ3Y564" class="alignleft valignbottom underscore" id-sequence="626"><p id="PWARK1D9ZMED21XWL070" id-sequence="627">Source of Sound</p></th> <th id="MSLDGGBQU6XL7FT1B270" class="alignleft valignbottom underscore sidescore" id-sequence="628"><p id="CWXMP6JV7C951HQGW155" id-sequence="629">Intensity (measured in decibels, or dB)</p></th> </tr> </thead> <tbody id="PESJJACHC6TSXUA87261" id-sequence="630"> <tr class="odd" id="CSAR0NF22P627Z72V650" id-sequence="631"> <td id="DMQKQKDPX99HZ2TU7584" class="alignleft valigntop" id-sequence="632"><p id="SJPFVYTV18E30K1WA548" id-sequence="633">Threshold of hearing</p></td> <td id="NUJN83K3U8G5TWEW4467" class="alignleft valigntop sidescore" id-sequence="634"><p id="XXJUHZU8M3GCKVN73532" id-sequence="635">0 dB</p></td> </tr> <tr class="even" id="UNLWUFGZUXHT34J76012" id-sequence="636"> <td id="UNCL1V3K53NR4NB03014" class="alignleft valigntop" id-sequence="637"><p id="ELGJCJX9C2086ATLZ264" id-sequence="638">Rustling leaves</p></td> <td id="TPVHVQ9WV9K48PBV7360" class="alignleft valigntop sidescore" id-sequence="639"><p id="QUTYF2G5AYDYDBTCK837" id-sequence="640">10 dB</p></td> </tr> <tr class="odd" id="XVJGT8W4L6JFHKZMD371" id-sequence="641"> <td id="SHAX3ZCE4D4G1NMM8246" class="alignleft valigntop" id-sequence="642"><p id="ZATLXWZFBG759M9LZ330" id-sequence="643">Whisper</p></td> <td id="CMBJ25WGKW09NNRUF197" class="alignleft valigntop sidescore" id-sequence="644"><p id="HXAQDM5EP2H9FHX4X873" id-sequence="645">20 dB</p></td> </tr> <tr class="even" id="RGYUHT2DQNPD344LC359" id-sequence="646"> <td id="MEUKU4TRDLWRC6BUE146" class="alignleft valigntop" id-sequence="647"><p id="WRSWNSGLGCPJ3PN0F711" id-sequence="648">Normal conversation</p></td> <td id="EFJETFR77UTT7WAJ1534" class="alignleft valigntop sidescore" id-sequence="649"><p id="AHQEUB9HTQJ3874EF396" id-sequence="650">60 dB</p></td> </tr> <tr class="odd" id="VVAJN4BEPPPDH6334592" id-sequence="651"> <td id="UPQMJQR3P9Z0QARAT036" class="alignleft valigntop" id-sequence="652"><p id="NAWS4GYTD5GFNWLSA057" id-sequence="653">Busy street traffic</p></td> <td id="TAPLC1S8QKJUSA87T062" class="alignleft valigntop sidescore" id-sequence="654"><p id="TJET6QBWK6YYP0GQE571" id-sequence="655">70 dB</p></td> </tr> <tr class="even" id="XBJQ6MFRQ67G2C321190" id-sequence="656"> <td id="FZER67PY4HPRQ5NPP591" class="alignleft valigntop" id-sequence="657"><p id="QGVXW7FLNPRVJ7AXG476" id-sequence="658">Vacuum cleaner</p></td> <td id="XBTQPV6HAHRP85SX4973" class="alignleft valigntop sidescore" id-sequence="659"><p id="RLMXEWGCVEX7WDEXT113" id-sequence="660">80 dB</p></td> </tr> <tr class="odd" id="UFDUWNR4AD8CYUKHF728" id-sequence="661"> <td id="TVRPNHE6RYL1S3TX1340" class="alignleft valigntop" id-sequence="662"><p id="MUSWN0HPMLVQLK10L429" id-sequence="663">Water at the foot of Niagara Falls</p></td> <td id="CMVMPEZ9P1JAL4KFT102" class="alignleft valigntop sidescore" id-sequence="664"><p id="AVWECCB7N1ZD5AEUR899" id-sequence="665">90 dB</p></td> </tr> <tr class="even" id="HHHXGM1CW0K908TF7876" id-sequence="666"> <td id="ZNMUEK3HB7BVG82C5091" class="alignleft valigntop" id-sequence="667"><p id="UXBZN45W6Q10A3CK8876" id-sequence="668">iPod with standard earbuds</p></td> <td id="WELZ44G34TQLFA896768" class="alignleft valigntop sidescore" id-sequence="669"><p id="ZKDAUFVC71X0ABASR769" id-sequence="670">100 dB</p></td> </tr> <tr class="odd" id="NFXQ8WQ9Y0KNBX8W3269" id-sequence="671"> <td id="WZEL36CLZB6KGQPB3639" class="alignleft valigntop" id-sequence="672"><p id="TFKWXCDFQ1TSCBCJT367" id-sequence="673">Front rows of a rock concert</p></td> <td id="MMZB9BMYT2CV6N5UM997" class="alignleft valigntop sidescore" id-sequence="674"><p id="LFDN1441LMV4FYQFQ220" id-sequence="675">110 dB</p></td> </tr> <tr class="even" id="XELL9R1X1XW5Y9KUK290" id-sequence="676"> <td id="DKDBZ2B73PT07HLC7621" class="alignleft valigntop" id-sequence="677"><p id="BQQQ7P89TMHDE876D381" id-sequence="678">Propeller plane at takeoff</p></td> <td id="DFDVQ05RVSX9T6J1E854" class="alignleft valigntop sidescore" id-sequence="679"><p id="ANAKXTW7AHVYE2MHS462" id-sequence="680">120 dB</p></td> </tr> <tr class="odd" id="FZAQ3QDWWKN3XKN6H636" id-sequence="681"> <td id="ZSVX6C601CMM7C2LF257" class="alignleft valigntop" id-sequence="682"><p id="SPFGJ1JMEE9XSTCWP444" id-sequence="683">Threshold of pain/machine gun fire</p></td> <td id="UVZQJYKFGU114LA3B136" class="alignleft valigntop sidescore" id-sequence="684"><p id="WUEZV55MG9T8J784S068" id-sequence="685">130 dB</p></td> </tr> <tr class="even" id="NXYNGTN897DT90SZQ521" id-sequence="686"> <td id="MCQH6CUK9NMZYGJDU023" class="alignleft valigntop" id-sequence="687"><p id="TCCL4BH7TPDPW4S2R559" id-sequence="688">Military jet takeoff</p></td> <td id="UDSZ1089156CL7907717" class="alignleft valigntop sidescore" id-sequence="689"><p id="RZSZXZPVN7GRNFHWX884" id-sequence="690">140 dB</p></td> </tr> <tr class="odd" id="KEGGQEQWU66ZKA21K993" id-sequence="691"> <td id="WDPVUYSD5YR1QXG7N715" class="alignleft valigntop underscore" id-sequence="692"><p id="QXQVT0MULTFU7ZK1G749" id-sequence="693">Instant perforation of the eardrum</p></td> <td id="YBWTCH54EQJUPHBJT594" class="alignleft valigntop sidescore underscore" id-sequence="694"><p id="GLNMRA4V0LVR339LY455" id-sequence="695">160 dB</p></td> </tr> </tbody> </table></div> </div> <p id="BSQH2BPJ9KBGHFLHX627" id-sequence="696">The frequency of a sound interacts with our perception of its loudness. Humans are maximally sensitive to sounds that normally fall within the range of speech, or between 80 and 10,000 Hz (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="KCNRZJZKRM71YE0FX720" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="KYVXYMRVY8Y7HXMHG320" data-element-id="KCNRZJZKRM71YE0FX720">Figure 5.34</a>). Sounds falling outside the range of speech must have higher intensity before we hear them as well. One feature that distinguishes an expensive sound system from a cheaper model is its ability to boost frequencies that fall outside our most sensitive range.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1505 rs_skip" id="KCNRZJZKRM71YE0FX720" clrenderdata="[&quot;EAWQE7MJ7CR3L1GX2607&quot;]" id-sequence="697"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f34-t2.png" data-width="559" data-height="468" data-alt="A graph showing human sensitivity to sound. The X axis shows frequency and the Y axis shows intensity. All the graphs are in the shape of a U. The depth of the U reduces as we go higher on the intensity scale. The range of human speech is from 80-10000 hertz. A whisper is at 20 decibels, normal speech at 60 decibels and the threshold of pain is at 125 decibels."></div><div class="nb_media image wide"><div class="mediaTitle" id="LZLA7M03PLD6XHXV2880" id-sequence="698"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.34</span></span><span class="mediaAssetTitle">Human Sensitivity to Sound.</span></div><div class="mediaDescription" id="JFKKDH1925SYCNHYL878" id-sequence="699"><p>These functions plot the results of allowing participants to adjust the intensity of different tones until they sound equally loud. Each curve represents the intensity (dB) at which tones of each frequency match the perceived loudness of a model 1000 Hz tone. The stars indicate that a 100 Hz tone at 60 dB sounds about as loud as a 1000 Hz tone at 40 dB because they fall on the same line. Low frequencies are usually perceived as quieter than high frequencies at the same level of intensity. We are especially sensitive to frequencies found in speech.</p></div> <div class="imageContainer" style="width:559px;height:468px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f34-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A graph showing human sensitivity to sound. The X axis shows frequency and the Y axis shows intensity. All the graphs are in the shape of a U. The depth of the U reduces as we go higher on the intensity scale. The range of human speech is from 80-10000 hertz. A whisper is at 20 decibels, normal speech at 60 decibels and the threshold of pain is at 125 decibels." width="559" height="468" class="rs_skip"></div> </div></div></div> </div> <div class="pageSection" id="GVXT7E4P6H6W6MX4D764" id-sequence="700"> <h3 id="GSHMT93LKG797N68N940" id-sequence="701"><span class="headingText">Localization of Sound</span></h3> <p id="JSGYB7GPDDKDSUJVE941" id-sequence="702">The pinna helps us localize sounds in the vertical plane, or in space above or below the head. Our primary method for localizing sound in the horizontal plane (in front, behind, and to the side) is to compare the arrival time of sound at each ear. As illustrated in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="KGBSSBX183MWNT89Q531" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="KYVXYMRVY8Y7HXMHG320" data-element-id="KGBSSBX183MWNT89Q531">Figure 5.35</a>, the differences in arrival times are quite small, between<a data-type="pageEnd" name="PageEnd_176" data-page="176"></a> 0 milliseconds for sounds that are directly in front of or behind us to 0.6 millisecond for sounds coming from a source perpendicular to the head on either side. Because arrival times for sounds coming from directly in front of or behind us are identical, it is difficult to distinguish these sources without further information. In addition to arrival times, we judge the differences in intensity of sounds reaching each ear. Because the head blocks some sound waves, a sound “shadow” is cast on the ear farthest from the source of sound. As a result, a weaker signal is received by this ear.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1506 rs_skip" id="KGBSSBX183MWNT89Q531" clrenderdata="[&quot;LKZDDLH59PH3UK5LL288&quot;]" id-sequence="703"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f35-t2.png" data-width="551" data-height="221" data-alt="A set of three illustrations showing how humans determine the direction from which a sound is coming. Picture a) shows how a sound from a perpendicular source travels. Picture b) shows the sound directly in front or behind the ear and picture c) shows sound at 45 degrees from the head."></div><div class="nb_media image wide"><div class="mediaTitle" id="QEPYMQQJVK4TSBG4B900" id-sequence="704"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.35</span></span><span class="mediaAssetTitle">Where Is that Sound Coming From?</span></div><div class="mediaDescription" id="ZVKUL37JL0PC3YS2L214" id-sequence="705"><p>We localize sound to the left and right by comparing the differences between the arrival times of the sounds to our two ears.</p></div> <div class="imageContainer" style="width:551px;height:221px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f35-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A set of three illustrations showing how humans determine the direction from which a sound is coming. Picture a) shows how a sound from a perpendicular source travels. Picture b) shows the sound directly in front or behind the ear and picture c) shows sound at 45 degrees from the head." width="551" height="221" class="rs_skip"></div> </div></div></div> <p id="HHYZ2EV7QKSKX8YMY241" id-sequence="706">Just as our visual systems can be fooled by certain types of input, our ability to localize sounds is influenced by interactions between vision and audition. Even before the invention of surround sound, which provides many effective sound localization cues, moviegoers perceived sound as originating from the actors’ lips, even though the speakers producing the sound are located above and to the sides of the screen. Our willingness to believe that the sound is coming from the actors’ lips probably results from our everyday experiences of watching people speak.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1507 rs_skip" id="SJJVDHYJJ1KT43B5Q775" clrenderdata="[&quot;KMDS40HLQQJPQV73L235&quot;]" id-sequence="707"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf25-t2.png" data-width="514" data-height="276" data-alt="A woman sitting in front of a computer talking to man in the computer screen."></div><div class="nb_media image unnumbered wide"><div class="mediaDescription" id="HXQDDLCBQHH9VNS7V447" id-sequence="708"><p>The McGurk effect is an auditory illusion that occurs when we combine vision and hearing. In this demonstration, hearing “ba-ba” at the same time you see a person’s lips making “ga-ga” results in your perceiving “da-da.”</p></div> <div class="imageContainer" style="width:514px;height:276px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf25-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A woman sitting in front of a computer talking to man in the computer screen." width="514" height="276" class="rs_skip"></div> </div></div></div> </div> <div class="pageSection" id="HREBSUBJ2KTAZ0S6B855" id-sequence="709"> <h3 id="FNDFT2FNJZZ4BB8ML921" id-sequence="710"><span class="headingText">Auditory Groupings</span></h3> <p id="GPVR67AQAEJEBHTUE081" id-sequence="711">In our previous discussion of visual perception, we reviewed the grouping principles developed by Gestalt psychologists. Similar types of groupings occur in audition. Sounds from one location are grouped together because we assume they have the same source, whereas sounds identified as coming from different locations are assumed to have different sources. Sounds that start and stop at the same time are perceived as having the same source, while sounds with different starting and stopping times usually arise from separate sources, such as two voices in a conversation. Grouping plays an especially significant role in the perception of music and speech. In these cases, we see evidence of top-down processing as well, because our expectations for the next note or word influence our perceptions (<span class="citation" id="WFVLNKHKVW6AT1L0X029" id-sequence="712">Pearce, Ruiz, Kapasi, Wiggins, &amp; Bhattacharya, 2010</span>). Similarities between the processing of music and language have led researchers to argue for more music instruction in school to assist children with language learning (<span class="citation" id="XKUVWE41YC7SWZ35C938" id-sequence="713">Strait, Kraus, Parbery-Clark, &amp; Ashley, 2010</span>).</p> </div> <div class="footnotes"></div></div><div id="footer" id-sequence="714"></div></div><div class="container page "><div id="header" id-sequence="717"><div id="breadcrumb-old" id-sequence="718" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="719" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="SNGSY5EQVV9DLKJVL298" id-sequence="720"><span class="sectionLabel rs_skip">5-3d</span> <span class="headingText">Developmental and Individual Differences in Audition</span></h2></div><div class="content" id="FWAD17EN0M96KAV0A864_content" id-sequence="721"> <p id="UBRW1X24JE39UUFFX090" id-sequence="722">Hearing begins before birth and develops rapidly in human infants. Newborns as young as 2 days show evidence of recognizing their mother’s voice (<span class="citation" id="DEPLF759ZFX5YFMVX837" id-sequence="723">DeCasper &amp; Fifer, 1980</span>) and respond preferentially to their native language (<span class="citation" id="CPKFB0EUU0BD4DFF2731" id-sequence="724">Moon, Cooper, &amp; Fifer, 1993</span>). Infants younger than 3 months show strong startle reactions to noise. By the age of 6 months, infants turn their heads in the direction of a loud or interesting sound. It is likely that their thresholds for sounds are nearly at adult levels by this age (<span class="citation" id="HYTM6FCXLH7V1G8DE529" id-sequence="725">Olsho, Koch, Halpin, &amp; Carter, 1987</span>). By the age of 1 year, children should reliably turn around when their name is called.</p> <p id="RLLCFP0JDJP78SRKQ600" id-sequence="726">An important developmental change in audition is age-related hearing loss. Hearing loss occurs first at higher frequencies. After the age of 30, most people cannot hear sounds above 15,000 Hz. After the age of 50, most people cannot hear above 12,000 Hz, and people older than 70 years have difficulty with sounds above 6,000 Hz. Because speech normally ranges up to 8,000 to 10,000 Hz, older adults might begin to have difficulty understanding the speech of others.</p> <p id="WGVUK0CG540AKTPQK984" id-sequence="727">Among individual differences in hearing is having perfect pitch, which means that you can name a musical tone that you hear. The brains of individuals with perfect pitch are structurally different from those of people who do not have this ability. Areas of the left hemisphere are larger in musicians with perfect pitch (<span class="citation" id="RLTSUZ04T4MXM0X6C938" id-sequence="728">Schlaug, Jancke, Huang, &amp; Steinmetz, 1995</span>). At the same time, extensive early musical training can shape the structure of the brain (<span class="citation" id="PKEMKF7YK6GW9VERP852" id-sequence="729">Schlaug et al., 2009</span>).</p><a data-type="pageEnd" name="PageEnd_177" data-page="177"></a> <div class="footnotes"></div></div><div id="footer" id-sequence="730"></div></div><div class="container page "><div id="header" id-sequence="733"><div id="breadcrumb-old" id-sequence="734" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="735" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="FAPBMXX1S938BF1DF798" id-sequence="736"><span class="sectionLabel rs_skip">5-3e</span> <span class="headingText">Sociocultural Influences on Auditory Perception</span></h2></div><div class="content" id="FGTDNKAMLJSD3RMH2932_content" id-sequence="737"> <p id="YQRZ80AY0QSY9CPAT630" id-sequence="738">Human culture and social life often provide a framework for the interpretation of stimuli. A dramatic example of this type of influence is our reaction to sine wave speech. To produce this stimulus, scientists artificially alter recordings of speech to resemble regular, repeating sine waves, as shown in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="CEKW9T6623W7V1LCU175" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="FGTDNKAMLJSD3RMH2932" data-element-id="CEKW9T6623W7V1LCU175">Figure 5.36</a> (<span class="citation" id="WGKWU7WB7SKN7LD7R199" id-sequence="739">Davis, 2007</span>). When people hear these artificial sounds without further instructions, they describe them as tweeting birds or other nonlanguage stimuli. However, if people are told the sounds represent speech, they suddenly “hear” language elements (<span class="citation" id="DCEGEKETBNCEBQ5N9522" id-sequence="740">Remez, Rubin, Pisoni, &amp; Carell, 1981</span>).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1508 rs_skip" id="CEKW9T6623W7V1LCU175" clrenderdata="[&quot;QJLPJNQ5MF6MAPHAH080&quot;]" id-sequence="741"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f36-t2.png" data-width="537" data-height="394" data-alt="A waveform at the top shows natural utterance and that at the bottom shows sine wave replica of natural utterance. In both the cases, time is indicated from left to right ranging from 500 milliseconds to 3000 milliseconds in increments of 500 milliseconds and wavelength is indicated in kilohertz from bottom to top ranging from 1 kilohertz to 5 kilohertz in increments of 1. In natural utterance, both dark and light shades of the waveform are shown. In sine wave replica, only the dark shades of the waveform are shown."></div><div class="nb_media image wide"><div class="mediaTitle" id="EZGSYSKHN14ZW9EM8407" id-sequence="742"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.36</span></span><span class="mediaAssetTitle">Expectations Influence the Interpretation of Sine Waves.</span></div><div class="mediaDescription" id="VKZQ55QW320JWGR6F909" id-sequence="743"><p>Sine waves are regular and repetitive waveforms, such as the ones we included earlier to show how the height and frequency of light and sound waves are interpreted by the mind. Researchers can record speech sounds and transform the recordings into artificial sine waves, such as those in this image. If the sounds are played without information about their source, most people interpret the sounds as tweeting birds. However, if people are told that the recordings are language, they report “hearing” language, another example of top-down cognitive influences on perception.</p></div> <div class="imageContainer" style="width:537px;height:394px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f36-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A waveform at the top shows natural utterance and that at the bottom shows sine wave replica of natural utterance. In both the cases, time is indicated from left to right ranging from 500 milliseconds to 3000 milliseconds in increments of 500 milliseconds and wavelength is indicated in kilohertz from bottom to top ranging from 1 kilohertz to 5 kilohertz in increments of 1. In natural utterance, both dark and light shades of the waveform are shown. In sine wave replica, only the dark shades of the waveform are shown." width="537" height="394" class="rs_skip"></div><div class="mediaCredit">© Remez, R. E. (1998). Sine-wave speech. Scholarpedia, 3: 2394 </div> </div></div></div> <p id="NJXET5NAXGL6MHJHS384" id-sequence="744">Sine wave speech shows us how culture in the form of experience with language can shape perception, but in other instances, perception can shape culture. For many people with hearing loss and for their families and friends, being deaf means something other than having a disability. Instead, deafness is viewed as a culture, complete with its own set of attitudes, language, and norms. American Sign Language (ASL) is viewed as being quite distinct from signed English and is difficult for signing people in Great Britain and Australia to understand (<span class="citation" id="BPFGP5A0U9FGDJGXB251" id-sequence="745">Mindess, 2006</span>).</p> <div class="footnotes"></div></div><div id="footer" id-sequence="746"></div></div><div class="container page "><div id="header" id-sequence="749"><div id="breadcrumb-old" id-sequence="750" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="751" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h1 id="RHSHQNGJNBHZK6FUB108" id-sequence="752"><span class="sectionLabel rs_skip">5-4</span> <span class="headingText">How Do We Feel Body Position, Touch, Temperature, and Pain?</span></h1></div><div class="content" id="CRNC7DKSL2E63LSQ8900_content" id-sequence="753"> <p id="GSFHNWS1LVETQ4YE5347" id-sequence="754"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f97" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f97"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f97" id="ZZFBK1R4CTDES5H9H759" id-sequence="755"><span class="index nb_hidden clAnnotationDecoration rs_skip">Somatosensation</span><span class="term"><span class="primaryTerm" id="NPYKTE1LULX68AN5Y673" id-sequence="756">Somatosensation</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The body senses, including body position, touch, skin temperature, and pain.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f97">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="NPYKTE1LULX68AN5Y673" id-sequence="756">Somatosensation</span></span>
        <span class="definition rs_skip">The body senses, including body position, touch, skin temperature, and pain.</span>
        <span class="pointer"></span>
    </span>
</span> (<em>soma</em> comes from the Greek word for “body”) provides us with information about the position and movement of our bodies, along with touch, skin temperature, and pain. Although these senses may not seem as glamorous as vision and hearing, we are severely disabled by their loss. You might think it would be a blessing to be born without a sense of pain, but people who have impaired pain reception often die prematurely because of<a data-type="pageEnd" name="PageEnd_178" data-page="178"></a> their inability to respond to injury. Although unpleasant, pain tells us to stop and assess our circumstances, which might have promoted the survival of our ancestors.</p> <div class="footnotes"></div></div><div id="footer" id-sequence="757"></div></div><div class="container page "><div id="header" id-sequence="760"><div id="breadcrumb-old" id-sequence="761" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="762" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="ZLXRVVKCBKFKWDMDK138" id-sequence="763"><span class="sectionLabel rs_skip">5-4a</span> <span class="headingText">Somatosensory Stimuli</span></h2></div><div class="content" id="WBRFW8M5CPL1G587C487_content" id-sequence="764"> <p id="WLEDPE9R0ZK7KD3XE690" id-sequence="765">Unlike the visual and auditory stimuli we have discussed so far in this chapter, somatosensory stimuli arise from within the body or make contact with its surface. As a result, these stimuli provide an organism little time to react. We can deal with a predator seen or heard from a distance using strategies different from those we use for one that is touching us. Nonetheless, the somatosenses provide essential feedback needed for movement, speech, and safety.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1509 rs_skip" id="USVMJRR4QJGPRXCRB261" clrenderdata="[&quot;VWGELWER4VLZD4APB182&quot;]" id-sequence="766"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf26-t2.jpg" data-width="378" data-height="252" data-alt="The vestibular system helps us maintain a steady view of the world, even when riding the most extreme roller coaster."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="XGUKCBTQUFC42GBKL502" id-sequence="767"><p>The vestibular system helps us maintain a steady view of the world, even when riding the most extreme roller coaster.</p></div> <div class="imageContainer" style="width:378px;height:252px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf26-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="The vestibular system helps us maintain a steady view of the world, even when riding the most extreme roller coaster." width="378" height="252" class="rs_skip"></div><div class="mediaCredit">Peter Mumford/Alamy Stock Photo </div> </div></div></div> <div class="footnotes"></div></div><div id="footer" id-sequence="768"></div></div><div class="container page "><div id="header" id-sequence="771"><div id="breadcrumb-old" id-sequence="772" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="773" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="BEHD1QMFA318PD63A304" id-sequence="774"><span class="sectionLabel rs_skip">5-4b</span> <span class="headingText">The Biology of the Somatosenses</span></h2></div><div class="content" id="MAKWJ35DYYNCCBR5L291_content" id-sequence="775"> <p id="FERNTRCAPEH663B8C198" id-sequence="776">The transition from walking on four legs to walking on two placed selective pressure on the evolution of primate vision and, to some extent, audition. By standing up on two legs, primates distanced themselves from many sources of information, such as smell. If you don’t believe us, try getting down on your hands and knees and smelling your carpet. This transition did not place the same evolutionary pressure on the human somatosenses, which work about the same way in us as they do in other animals.</p> <div class="pageSection" id="BBVW32GTPVH44JFA2377" id-sequence="777"> <h3 id="EVDQ65TME7UDMGU2B896" id-sequence="778"><span class="headingText">Body Position</span></h3> <p id="ATCABG5GJRFWHEV8U515" id-sequence="779">To begin our exploration of the somatosensory systems, we return to the inner ear. Adjacent to the structures responsible for encoding sound, we find the structures of the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f98" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f98"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f98" id="VZKCX34JT481A1ALZ302" id-sequence="780"><span class="index nb_hidden clAnnotationDecoration rs_skip">vestibular system</span><span class="term"><span class="primaryTerm" id="YRMADZPEHZWK779Q6625" id-sequence="781">vestibular system</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The system in the inner ear that provides information about body position and movement.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f98">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="YRMADZPEHZWK779Q6625" id-sequence="781">vestibular system</span></span>
        <span class="definition rs_skip">The system in the inner ear that provides information about body position and movement.</span>
        <span class="pointer"></span>
    </span>
</span>, which provide us with information about body position and movement. The proximity of these structures to the middle ear, which can become congested because of a head cold, is often responsible for those rather unpleasant feelings of dizziness that accompany an illness. The receptors of the vestibular system provide information about the position of the head relative to the ground, linear acceleration, and rotational movements of the head. We sense linear acceleration when our rate of movement changes, such as when our airplane takes off.</p> <p id="DCNJC1XEXUHD59GQL961" id-sequence="782">Like the cochlea, the vestibular receptors contain sensitive hair cells that are bent back and forth within their surrounding fluid when the head moves. When extensive movement stops suddenly, perhaps at the end of an amusement park ride, these fluids reverse course. You may have the odd sensation that your head is now moving in the opposite direction, even though you are sitting or standing still. The movement of these hair cells results in the production of signals in the auditory nerve, the same nerve that carries information about sound. These axons form connections in the medulla and in the cerebellum. You may recall from <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="ZUXJT37ZGC28NP5YG839" data-chapter-id="ZUXJT37ZGC28NP5YG839" data-element-id="ZUXJT37ZGC28NP5YG839">Chapter 4</a> that the cerebellum participates in balance and motor coordination, functions that depend on feedback about movement. In turn, the medulla receives input from the visual system, the cerebellum, and other somatosenses. This arrangement provides an opportunity to coordinate input from the vestibular system with other relevant information. The medulla forms connections directly with the spinal cord, allowing us to adjust our posture to keep our balance. Vestibular information travels from the medulla to the thalamus, the primary somatosensory cortex of the parietal lobe, and then the primary motor cortex in the frontal lobe. This pathway allows vestibular information to guide voluntary movement.</p> <p id="TZXKP87NLZPY57L85148" id-sequence="783">In humans particularly, information from the vestibular system is tightly integrated with visual processing. As we move, it is essential that we maintain a stable view of our surroundings. To accomplish this task, rotation of the head results in a reflexive movement of the eyes in the opposite direction. This action should allow you to maintain a steady view of the world, even on the most extreme roller coaster.</p> </div> <div class="pageSection" id="YSGAY7U893APERLYY009" id-sequence="784"> <h3 id="SNAJL00BTVDWKRSFU539" id-sequence="785"><span class="headingText">Touch</span></h3> <p id="RQKTHPDKBPU3F64RW888" id-sequence="786">Touch provides a wealth of information about the objects around us. By simply exploring an object with touch, we can determine features such as size, shape, texture, and<a data-type="pageEnd" name="PageEnd_179" data-page="179"></a> consistency. These judgments confirm and expand the information we obtain about objects through visual exploration. Touch is not only a means of exploring the environment. Particularly in humans, touch plays a significant role in social communication. Infants who are touched regularly sleep better, remain more alert while awake, and reach cognitive milestones at earlier ages (<span class="citation" id="LWNE0ZXU7H4JDUYL1765" id-sequence="787">Ackerman, 1990</span>). We hug our friends and loved ones to provide comfort, pat others on the back for a job well done, and shake hands to greet a colleague or conclude a deal. The contributions of the sense of touch to human sexuality are obvious.</p> <p id="ANZNWQ8J2HL6XWY6E524" id-sequence="788">Our sense of touch begins with skin, the largest and heaviest organ in the human body. Embedded within the skin are several types of specialized neurons that produce action potentials whenever they are physically bent or stretched. Different types of receptors respond to certain features of a touch stimulus, such as pressure, vibration, or stretch (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="UKWT4A6SF1545ZPC9632" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MAKWJ35DYYNCCBR5L291" data-element-id="UKWT4A6SF1545ZPC9632">Figure 5.37</a>). In addition to their locations in the skin, receptors are located in blood vessels, joints, and internal organs. Unpleasant sensations from a headache or a too-full stomach or bladder originate from some of these receptors. Some receptor fibers wrap around hair follicles and respond whenever a hair is pulled or bent. Others, as we will see later in this section, participate in our senses of pain and skin temperature.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf150a rs_skip" id="UKWT4A6SF1545ZPC9632" clrenderdata="[&quot;ZLHS7EZBLD0EMP8G7829&quot;]" id-sequence="789"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f37-t2.png" data-width="403" data-height="498" data-alt="A hand is shown at the top. Below it is a cross section of the skin. The skin shows touch receptors as the only labeled part."></div><div class="nb_media image"><div class="mediaTitle" id="CJBRJXSMBGMGEM16G864" id-sequence="790"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.37</span></span><span class="mediaAssetTitle">Touch Receptors.</span></div><div class="mediaDescription" id="PRDVCFWYQNJVW4WNW772" id-sequence="791"><p>Different receptors in the skin help us sense pressure, vibration, stretch, or pain.</p></div> <div class="imageContainer" style="width:403px;height:498px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f37-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A hand is shown at the top. Below it is a cross section of the skin. The skin shows touch receptors as the only labeled part." width="403" height="498" class="rs_skip"></div> </div></div></div> <p id="XYSBQZDK4ZS4MYV0L624" id-sequence="792">Information about touch travels from the skin to the spinal cord. Once inside the spinal cord, touch pathways proceed to the thalamus, along with input from the cranial nerves originating in the touch receptors in the skin of the face, the mouth, and the tongue. The thalamus transmits touch information to the primary somatosensory cortex, located in the parietal lobe.</p> <p id="VTNNBBHXR362P9FLM080" id-sequence="793">A map of the body’s representation in the primary somatosensory cortex, or a sensory <em>homunculus</em> (“little man”), is shown in the statue to the right. This odd figure demonstrates how areas of the body are represented based on their sensitivity rather than their size. Different species show different patterns of cortical organization for touch. Humans need sensitive feedback from the lips and the hands to speak and make skilled hand movements for tool use and other tasks. Rats devote a great deal of cortical real estate to whiskers, whereas lips have a high priority in squirrels and rabbits.</p> <p id="FEXK1BTEZ4HD1RSRA565" id-sequence="794">A notable area that is missing from the homunculus is the brain, which has neither touch receptors nor pain receptors. We can only assume that for much of evolutionary history, intrusion into the brain was likely to be fatal. Consequently, there would be no advantage to “feeling” your brain. Because of the lack of somatosensation in the brain, neurosurgeons can work with an alert patient using local anesthesia for the skull and tissues overlying the brain. The surgery produces no sensations of pressure or pain.</p> <p id="AUWJK0M0B0PRVEE4B272" id-sequence="795">The representation of touch in the primary sensory cortex is <em>plastic</em>, which means that it changes in response to increases or decreases in input from a body part. Many individuals who lose a body part experience a phenomenon known as <em>phantom limb</em>, a term first used by a Civil War physician to describe his patients’ experience of pain from a missing limb. Phantom sensations can result from the reorganization of the somatosensory cortex following the loss of a body part (<span class="citation" id="MVWDCGH5ZFPRH2GSE778" id-sequence="796">Borsook et al., 1998</span>). In one case study, touching different parts of a patient’s face produced “feeling” from the patient’s missing hand (Ramachandran &amp; Rogers-Ramachandran, 2000). When his cheek was touched, he reported feeling his missing thumb, along with the expected cheek, while touching his lip elicited feeling from the missing index finger, along with the normal lip sensations. In an even more bizarre example, a patient was embarrassed to report that he experienced a sensation of orgasm in his missing foot.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf150b rs_skip" id="YPHBE7AVVEUAAHGD8473" clrenderdata="[&quot;ESMHTS27TNPDZXDSW471&quot;]" id-sequence="797"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf26-t2.png" data-width="234" data-height="260" data-alt="A human homunculus showing a large head and large pair of hands."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="XCKQV2VD3S2DSUKUL660" id-sequence="798"><p>The sensory homunculus illustrates the amount of representation each part of the body has in the sensory cortex. The human homunculus emphasizes the hands and face.</p></div> <div class="imageContainer" style="width:234px;height:260px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf26-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A human homunculus showing a large head and large pair of hands." width="234" height="260" class="rs_skip"></div><div class="mediaCredit">The Natural History Museum/The Image Works </div> </div></div></div> <p id="ZMCYQ3KER708ALN7Y256" id-sequence="799">Increased input also changes the organization of the somatosensory cortex. When monkeys were trained to use specific fingers to discriminate among surface textures to obtain food rewards, the areas of the cortex responding to the trained fingertips expanded (<span class="citation" id="VWJAGUMTEGAFS4WVY519" id-sequence="800">Merzenich &amp; Jenkins, 1993</span>). A similar reorganization occurs when blind individuals learn<a data-type="pageEnd" name="PageEnd_180" data-page="180"></a> to read Braille (Pascual-Leone &amp; Torres, 1993) or when people train extensively on stringed musical instruments (<span class="citation" id="HUQCA218TPDB6BPW9148" id-sequence="801">Elbert, Pantev, Weinbruch, Rockstroh, &amp; Taub, 1995</span>). Using your thumbs for text messaging will probably result in adaptations in cortical representation not seen in older generations (<span class="citation" id="XVUYGDYJJ6S50J33D452" id-sequence="802">Wilton, 2002</span>).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf150c rs_skip" id="SEPXLJ1RRLA02ULH9364" clrenderdata="[&quot;XGLS2J7F273K4CWKS155&quot;]" id-sequence="803"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf27-t2.jpg" data-width="405" data-height="260" data-alt="A robotic hand holding a ball."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="DJKU7WY6JPYKY6T44936" id-sequence="804"><p>Advances in robotics combined with better understanding of how touch is processed in the brain are leading to the development of prosthetics that can feel. Using fMRI, researchers were able to map areas of the sensory cortex that reacted when a participant imagined something touching different parts of the hand. With electrodes implanted in the relevant areas, the participant could then respond accurately to touch applied to the prosthetic hand, even when blindfolded. With this more natural feedback, the prosthetic hand should be able to manage delicate tasks, like picking up an egg.</p></div> <div class="imageContainer" style="width:405px;height:260px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf27-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A robotic hand holding a ball." width="405" height="260" class="rs_skip"></div><div class="mediaCredit">H.S. Photos/Alamy Stock Photo </div> </div></div></div> <p id="FAAKD3A99XUJFCDZ5834" id-sequence="805">Individuals with autism spectrum disorder (ASD) experience a very different sensory world (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="KNKVM7TED147CWT15523" data-chapter-id="KNKVM7TED147CWT15523" data-element-id="KNKVM7TED147CWT15523">Chapter 14</a>). Many individuals with ASD are oversensitive to touch, leading to rejection of hugs and cuddling. In addition, brain responses to touch of self or others differ between individuals with ASD and healthy controls (<span class="citation" id="EBCG2VH9EU54ZX9X0102" id-sequence="806">Deschrijver, Wiersema, &amp; Brass, 2017</span>). The extent of the differences correlated with the individuals’ reports of sensory and social difficulties.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf150d rs_skip" id="DFKKF0ULPH60JS94F894" clrenderdata="[&quot;UGKQ7XN1J26W1WFUA293&quot;]" id-sequence="807"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf28-t2.jpg" data-width="440" data-height="286" data-alt="The representation of body parts in the primary sensory cortex changes in response to the amount of input from a body part. Children who study stringed instruments show more space in the sensory cortex devoted to fingers."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="WBTXYR2AXQAA9J9B0183" id-sequence="808"><p>The representation of body parts in the primary sensory cortex changes in response to the amount of input from a body part. Children who study stringed instruments show more space in the sensory cortex devoted to fingers.</p></div> <div class="imageContainer" style="width:440px;height:286px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf28-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="The representation of body parts in the primary sensory cortex changes in response to the amount of input from a body part. Children who study stringed instruments show more space in the sensory cortex devoted to fingers." width="440" height="286" class="rs_skip"></div><div class="mediaCredit">wavebreakmedia/ <a target="_blank" id="AXTVNQ267395GRUD5222" name="AXTVNQ267395GRUD5222" class="external" href="http://Shutterstock.com" id-sequence="809">Shutterstock.com</a></div> </div></div></div> </div> <div class="pageSection" id="PXEPYV11QT4D5DMN6328" id-sequence="810"> <h3 id="YXGW7UJC10J63S35N136" id-sequence="811"><span class="headingText">Pain</span></h3> <p id="DCPNNJ4HNV2MSSF4G055" id-sequence="812">Given the anguish experienced by patients with chronic pain, it is tempting to think that not having a sense of pain would be wonderful. However, as mentioned earlier, we need pain to remind us to stop when we are injured, to assess the situation before proceeding, and to allow the body time to heal.</p> <p id="KEXARFHV1EK620NHC717" id-sequence="813">Free nerve endings that respond to pain are triggered by a number of stimuli associated with tissue damage. Some pain receptors respond to mechanical damage, such as that caused by a sharp object, while others respond to temperature or chemicals. Among the chemicals that stimulate pain receptors is capsaicin, an ingredient found in hot peppers (<span class="citation" id="TACZZBGL7A0MAD96E808" id-sequence="814">Caterina et al., 1997</span>). Information about pain is carried centrally to the brain by two types of fibers. Fast, myelinated axons are responsible for that sharp “ouch” sensation that often accompanies an injury. Slower, unmyelinated axons are responsible for dull, aching sensations.</p> <p id="MWXYR9YNFVGF2HU3V347" id-sequence="815">Pain fibers from the body form synapses with cells in the spinal cord, which in turn sends pain messages to the thalamus. This information takes a relatively direct route, with only one synapse in the spinal cord separating the periphery of the body and the thalamus in the forebrain. This arrangement ensures that pain messages are received by the brain with great speed. From the thalamus, pain information is sent to the anterior cingulate cortex and the insula, which manage the emotional qualities of pain, and to the somatosensory cortex in the parietal lobe, which manages information about the location and intensity of pain (<span class="citation" id="RLUR5D2CQHSCX7CCP017" id-sequence="816">Wiech, 2016</span>).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf150e rs_skip" id="BECWA900413KU8NQK659" clrenderdata="[&quot;VGVYCTDZPJ6FN29LA758&quot;]" id-sequence="817"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf29-t2.jpg" data-width="245" data-height="173" data-alt="Ashlyn Blocker was born with a rare condition preventing her from feeling pain. Without complaint, she went several days with a broken ankle after falling off her bicycle."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="BHNJLEZASBT2B3Q06193" id-sequence="818"><p>Ashlyn Blocker was born with a rare condition preventing her from feeling pain. Without complaint, she went several days with a broken ankle after falling off her bicycle.</p></div> <div class="imageContainer" style="width:245px;height:173px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf29-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Ashlyn Blocker was born with a rare condition preventing her from feeling pain. Without complaint, she went several days with a broken ankle after falling off her bicycle." width="245" height="173" class="rs_skip"></div><div class="mediaCredit">AP Images/Stephen Morton </div> </div></div></div><a data-type="pageEnd" name="PageEnd_181" data-page="181"></a> <p id="EQLQE0ZMJ9Q770MUN367" id-sequence="819">Pain messages traveling to the brain may be modified by competing incoming sensory signals. Many of us spontaneously rub our elbow after bumping it painfully. The <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f99" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f99"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f99" id="LHCEME2JKE1WKF97H829" id-sequence="820"><span class="index nb_hidden clAnnotationDecoration rs_skip">gate theory</span><span class="term"><span class="primaryTerm" id="ATRW4VYTAB79SKZR6060" id-sequence="821">gate theory</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The theory that suggests that input from touch fibers competes with input from pain receptors, possibly preventing pain messages from reaching the brain.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f99">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="ATRW4VYTAB79SKZR6060" id-sequence="821">gate theory</span></span>
        <span class="definition rs_skip">The theory that suggests that input from touch fibers competes with input from pain receptors, possibly preventing pain messages from reaching the brain.</span>
        <span class="pointer"></span>
    </span>
</span> of pain accounts for this phenomenon (<span class="citation" id="VDHXG72VPGGYRS2JM535" id-sequence="822">Melzack &amp; Wall, 1965</span>). According to this model, input from touch fibers (reacting to rubbing your elbow) competes with input from pain receptors for activation of cells in the spinal cord (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="QFRCJTR3LRD3AP901447" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MAKWJ35DYYNCCBR5L291" data-element-id="QFRCJTR3LRD3AP901447">Figure 5.38</a>). Activation of the touch fibers effectively dilutes the amount of pain information reaching the brain.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf150f rs_skip" id="QFRCJTR3LRD3AP901447" clrenderdata="[&quot;FRBGXT5WE90RGNBS9154&quot;]" id-sequence="823"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f38-t3.png" data-width="633" data-height="412"></div><div class="metadata inlineImage" data-filename="61815_05_f38-t2.png" data-width="595" data-height="385" data-alt="A photograph of a man holding his elbow in pain is shown next to a flowchart. The flowchart shows three boxes flowing into one central box labeled gate in spinal cord. The three boxes are event or injury, factors that close the gate such as rubbing elbow and high levels of arousal, and factors that open the gate such as chronic stress. The central box flows out to another box labeled pain is experienced how far the gate is open or closed."></div><div class="nb_media image wide"><div class="mediaTitle" id="MNRRGES2ZT67DEWV7937" id-sequence="824"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.38</span></span><span class="mediaAssetTitle">The Gate Theory of Pain.</span></div><div class="mediaDescription" id="JJDJRY27AGTLACM65242" id-sequence="825"><p>According to the gate theory, incoming pain messages can be influenced by factors such as chronic stress (opening the gate wider and producing a greater sensation of pain) or rubbing an injured body part (closing the gate and reducing the sensation of pain).</p></div> <div class="imageContainer" style="width:595px;height:385px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f38-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A photograph of a man holding his elbow in pain is shown next to a flowchart. The flowchart shows three boxes flowing into one central box labeled gate in spinal cord. The three boxes are event or injury, factors that close the gate such as rubbing elbow and high levels of arousal, and factors that open the gate such as chronic stress. The central box flows out to another box labeled pain is experienced how far the gate is open or closed." width="595" height="385" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div><div class="mediaCredit">Juriah Mosin/ <a target="_blank" id="URCCHN56ZRSWGK4GY521" name="URCCHN56ZRSWGK4GY521" class="external" href="http://Shutterstock.com" id-sequence="826">Shutterstock.com</a></div> </div></div></div> <p id="TXGNHU18T49W2YKQV154" id-sequence="827">The perception of pain is affected by the descending influence of higher brain centers. Many forebrain structures form connections with the periaqueductal gray of the midbrain. As we observed in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="ZUXJT37ZGC28NP5YG839" data-chapter-id="ZUXJT37ZGC28NP5YG839" data-element-id="ZUXJT37ZGC28NP5YG839">Chapter 4</a>, this area is rich in receptors for our natural opioids, the endorphins. The periaqueductal gray is a major target for opioid painkillers, such as morphine. Electrical stimulation of the periaqueductal gray produces a significant reduction in the experience of pain.</p> <div class="container dependent margin narrative  rs_skip" id="UFNZU52YLW8K18J0K239" id-sequence="828"><div class="sidebarContent" id="UFNZU52YLW8K18J0K239_sidebarcontent" id-sequence="829"> <p id="RTFZ9LVX1VQZQLEY2002" id-sequence="830">In one of the most dramatic examples of how stress can interfere with the perception of pain, Guy Gertsch unknowingly ran the final 19 miles (about 30 km) of the 1982 Boston Marathon on a broken leg. Gertsch finished the race with a highly respectable time of 2 hours and 47 minutes.</p> </div></div> <p id="FWGVNW7VSPQYYYRD1873" id-sequence="831">Pain is an actively constructed experience that involves our expectations and past experiences (<span class="citation" id="EHBWK0ZZK2MK9GKKA353" id-sequence="832">Wiech, 2016</span>). The power of expectation can be seen in placebo effects, which occur when people experience pain reduction, even though they have been exposed to an ineffective substance or treatment, such as a sugar pill instead of an aspirin tablet. Traditionally, scientists thought placebo effects were due to the ability of people’s belief that they are being treated for pain to initiate a real decrease in pain sensation. However, even when people are told they are receiving a placebo, pain relief can occur as long as they are also told that placebo effects can be powerful (<span class="citation" id="AZAHKVQWPV471MLVB964" id-sequence="833">Carvalho et al., 2016</span>).</p> </div> <div class="footnotes"></div></div><div id="footer" id-sequence="834"></div></div><div class="container page "><div id="header" id-sequence="837"><div id="breadcrumb-old" id-sequence="838" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="839" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="PWMWZHDJX9LL4Q48D288" id-sequence="840"><span class="sectionLabel rs_skip">5-4c</span> <span class="headingText">Sociocultural Influences on the Somatosenses</span></h2></div><div class="content" id="PDWA93KMEA13TKF8W067_content" id-sequence="841"> <p id="BRGX6GXY6PCNM9H5G102" id-sequence="842">No other sensory modality is as dramatically affected by culture, context, and experience as our sense of pain. The connection between culture and experience of pain is vividly illustrated by the hook-swinging ritual practiced in India (<span class="citation" id="WBXQ0N6KG7G1BRGSZ413" id-sequence="843">Melzack &amp; Wall, 1983</span>). This ritual, designed to promote the health of children and crops, involves hanging a male volunteer from steel hooks embedded into the skin and muscles of his back. Instead of suffering excruciating pain, as Westerners might expect, the volunteers appear to be in a state of exaltation.</p><a data-type="pageEnd" name="PageEnd_182" data-page="182"></a> <p id="DJBMF3UBFQS4LKX1W615" id-sequence="844">Women who have participated in prepared childbirth classes report less pain than women who are uninformed regarding the birth process. Although athletes and nonathletes share similar pain thresholds, these groups are quite different in their tolerance of pain (<span class="citation" id="LFAF3RPJ4WQ2RXZRN731" id-sequence="845">Scott &amp; Gijsbers, 1981</span>). Compared to nonathletes, athletes in contact sports such as boxing, rugby, and football tolerate higher levels of pain before identifying a stimulus as painful. Patients who are allowed to self-administer morphine for pain require less medication than patients who receive injections from hospital staff (<span class="citation" id="VKJE15KU1GDQ1DR8H872" id-sequence="846">Bennett et al., 1982</span>). The sense of control may reduce anxiety and the need for pain medication.</p> <div class="footnotes"></div></div><div id="footer" id-sequence="847"></div></div><div class="container page "><div id="header" id-sequence="850"><div id="breadcrumb-old" id-sequence="851" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="852" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h1 id="WFWKZJMM6HJAEXB6Q219" id-sequence="853"><span class="sectionLabel rs_skip">5-5</span> <span class="headingText">How Do We Process Smells and Tastes?</span></h1></div><div class="content" id="HQUX3UCAXRE5U9B52946_content" id-sequence="854"> <p id="VFNJ7SZFVCTQE4Q9F580" id-sequence="855">The famous philosopher Immanuel Kant (1798/1978, p. 46) considered <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f9a" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f9a"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f9a" id="KQKEFEN3F57SZSM7S033" id-sequence="856"><span class="index nb_hidden clAnnotationDecoration rs_skip">olfaction</span><span class="term"><span class="primaryTerm" id="MSUH1CF70F8TSNENV336" id-sequence="857">olfaction</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip"><em>See also</em> Chemical senses</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f9a">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="MSUH1CF70F8TSNENV336" id-sequence="857">olfaction</span></span>
        <span class="definition rs_skip"><em>See also</em> Chemical senses</span>
        <span class="pointer"></span>
    </span>
</span>, or our sense of smell, to be the “most dispensable” sense. Other species rely more heavily on olfaction and <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f9b" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f9b"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f9b" id="UAUR9FKYRE6Z6TFJC266" id-sequence="858"><span class="index nb_hidden clAnnotationDecoration rs_skip">gustation</span><span class="term"><span class="primaryTerm" id="NQZAXPNQAPV7U1UV6794" id-sequence="859">gustation</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip"><em>See also</em> Chemical senses</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f9b">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="NQZAXPNQAPV7U1UV6794" id-sequence="859">gustation</span></span>
        <span class="definition rs_skip"><em>See also</em> Chemical senses</span>
        <span class="pointer"></span>
    </span>
</span>, or the sense of taste, than humans do. Nonetheless, our chemical senses provide warning of danger, such as smelling smoke from a fire or tasting spoiled food. The chemical senses also contribute a richness to our emotional and social experiences. The smell of perfume or the taste of chocolate may be accompanied by strong emotional reactions. Contrary to Kant’s view, people who have lost their sense of smell because of head injury often experience profound depression (<span class="citation" id="PADRH577H75HQ9UBP677" id-sequence="860">Zuscho, 1983</span>). Sharing a meal has a strong effect on bonding for humans and other primates (<span class="citation" id="TRTUCP0QYJA9PARUY755" id-sequence="861">Brosnan, 2010</span>; <span class="citation" id="NTDUDBD9DT5YRU7RX070" id-sequence="862"> Wobber, Wrangham, &amp; Hare, 2010</span>).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1510 rs_skip" id="JMZF5MG5RFA3JSTBJ636" clrenderdata="[&quot;KFUPSJWU7LV8HY2XH992&quot;]" id-sequence="863"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf30-t2.jpg" data-width="228" data-height="322" data-alt="Culture, context, and experience can shape our perception of pain. During a festival dedicated to penance and atonement, Tamil Hindus walked through the streets carrying devices called kavadis that hold hooks that are pierced through the skin. Without this cultural context, it is likely that most people would find this experience excruciatingly painful."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="HDGK34QMW98V6LH9D055" id-sequence="864"><p>Culture, context, and experience can shape our perception of pain. During a festival dedicated to penance and atonement, Tamil Hindus walked through the streets carrying devices called kavadis that hold hooks that are pierced through the skin. Without this cultural context, it is likely that most people would find this experience excruciatingly painful.</p></div> <div class="imageContainer" style="width:228px;height:322px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf30-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Culture, context, and experience can shape our perception of pain. During a festival dedicated to penance and atonement, Tamil Hindus walked through the streets carrying devices called kavadis that hold hooks that are pierced through the skin. Without this cultural context, it is likely that most people would find this experience excruciatingly painful." width="228" height="322" class="rs_skip"></div><div class="mediaCredit">Louise Batalla Duran/Alamy Stock Photo </div> </div></div></div> <div class="footnotes"></div></div><div id="footer" id-sequence="865"></div></div><div class="container page "><div id="header" id-sequence="868"><div id="breadcrumb-old" id-sequence="869" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="870" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="AEQECR5LGRJHVXX8U207" id-sequence="871"><span class="sectionLabel rs_skip">5-5a</span> <span class="headingText">Chemical Stimuli</span></h2></div><div class="content" id="UXUX6HT38ALMHL7XC793_content" id-sequence="872"> <p id="RGVSLG8SBNKVH52TN358" id-sequence="873">Our chemical senses begin with molecules suspended in the air in the case of olfaction and dissolved in saliva in the case of gustation. Olfaction provides more information from a distance, like vision and audition, whereas gustation, like the somatosenses, involves information from contact with the body.</p> <div class="footnotes"></div></div><div id="footer" id-sequence="874"></div></div><div class="container page "><div id="header" id-sequence="877"><div id="breadcrumb-old" id-sequence="878" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="879" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="JUWDHXGRZ0REU75GK416" id-sequence="880"><span class="sectionLabel rs_skip">5-5b</span> <span class="headingText">The Biology of the Chemical Senses</span></h2></div><div class="content" id="XNBKV9NL3DN94427M749_content" id-sequence="881"> <p id="CDPLZR1L64W1RHMPK450" id-sequence="882">Like the somatosenses, the chemical senses are quite ancient in terms of evolution and have undergone little change over time. However, our sense of smell has been influenced by walking on two feet instead of four. Most olfactory stimuli are relatively heavy and tend to fall to the ground. Consider how your dog puts its nose to the ground when tracking something interesting.</p> <div class="pageSection" id="GDGWMX0NY7V28PGP3352" id-sequence="883"> <h3 id="MPLAKQWK186EBLFUL328" id-sequence="884"><span class="headingText">Olfaction</span></h3> <p id="FHTWVBJR1ZBKTHWK2032" id-sequence="885">Air containing olfactory stimuli is taken in through the nostrils and circulated within the nasal cavities connected to the nostrils, where it interacts with olfactory receptors (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="HVWMT4X0KZ5ZL0SZU275" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="XNBKV9NL3DN94427M749" data-element-id="HVWMT4X0KZ5ZL0SZU275">Figure 5.39</a>). The receptors are located in a thin layer of cells within the nasal cavity. Unlike most neurons, the olfactory receptors regularly die and are replaced by new receptor cells in cycles lasting 4 to 6 weeks. Cells at the base of the receptors are responsible for producing the mucus surrounding the receptors. One branch of each receptor interacts with molecules dissolved in the mucus. The other branch carries information back to the central nervous system as part of the <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f9c" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f9c"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f9c" id="MNHK2RFXG01TGRXZD859" id-sequence="886"><span class="index nb_hidden clAnnotationDecoration rs_skip">olfactory nerve</span><span class="term"><span class="primaryTerm" id="APDM4LZB54ZLH04YC042" id-sequence="887">olfactory nerve</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A nerve carrying olfactory information from the olfactory receptors to the olfactory bulbs.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f9c">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="APDM4LZB54ZLH04YC042" id-sequence="887">olfactory nerve</span></span>
        <span class="definition rs_skip">A nerve carrying olfactory information from the olfactory receptors to the olfactory bulbs.</span>
        <span class="pointer"></span>
    </span>
</span>. The olfactory nerve fibers synapse in one of the two <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f9d" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f9d"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f9d" id="ZRBY2UCRXTPB9ZKGP343" id-sequence="888"><span class="index nb_hidden clAnnotationDecoration rs_skip">olfactory bulbs</span><span class="term"><span class="primaryTerm" id="YLVF7FKMPC0QJRWBG847" id-sequence="889">olfactory bulbs</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">One of two structures below the frontal lobes of the brain that receive input from the olfactory receptors in the nose.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f9d">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="YLVF7FKMPC0QJRWBG847" id-sequence="889">olfactory bulbs</span></span>
        <span class="definition rs_skip">One of two structures below the frontal lobes of the brain that receive input from the olfactory receptors in the nose.</span>
        <span class="pointer"></span>
    </span>
</span>, located just below the mass of the frontal lobes. Although we often hear that human olfaction is not as good as olfaction in other species, human olfactory bulbs have about the same number of neurons as in 24 other mammalian species (<span class="citation" id="BKEE3KTXF9F4HWT8F789" id-sequence="890">McGann, 2017</span>).</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1511 rs_skip" id="HVWMT4X0KZ5ZL0SZU275" clrenderdata="[&quot;BSVF47QNSA9V4DV6V171&quot;]" id-sequence="891"><div class="cluimedia_viewer_image rs_skip"><div class="metadata enlargedImage" data-filename="61815_05_f39-t3.png" data-width="716" data-height="860"></div><div class="metadata inlineImage" data-filename="61815_05_f39-t2.png" data-width="595" data-height="720" data-alt="An illustration of a part of the brain. The labeled parts are inhaled air, olfactory bulb, orbitofrontal cortex, hypothalamus, frontal lobe, thalamus, olfactory cortex, hippocampus, to limbic system and amygdala. The olfactory bulb has been enlarged and shown in an illustration below. The labeled parts are air flow, odorant molecules, mucus, olfactory receptor cell, olfactory neuron, olfactory nerve, olfactory bulb, axons of olfactory receptor cells and bone."></div><div class="nb_media image wide"><div class="mediaTitle" id="DJADJFNU2XHLW9RUG948" id-sequence="892"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.39</span></span><span class="mediaAssetTitle">Olfactory Receptors.</span></div><div class="mediaDescription" id="QBRA0GZBTUKS08Y0C569" id-sequence="893"><p>Receptors in the nose interact with airborne chemicals to begin the sensing of odor.</p></div> <div class="imageContainer" style="width:595px;height:720px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f39-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration of a part of the brain. The labeled parts are inhaled air, olfactory bulb, orbitofrontal cortex, hypothalamus, frontal lobe, thalamus, olfactory cortex, hippocampus, to limbic system and amygdala. The olfactory bulb has been enlarged and shown in an illustration below. The labeled parts are air flow, odorant molecules, mucus, olfactory receptor cell, olfactory neuron, olfactory nerve, olfactory bulb, axons of olfactory receptor cells and bone." width="595" height="720" style="cursor: pointer;" class="rs_skip">			<div class="enlarge" style="left:585px">
				<img src="/static/nbapps/media/images/enlarge.png" alt="Enlarge Image" title="Enlarge Image" style="cursor: pointer;" class="rs_skip">
			</div>
</div> </div></div></div> <a data-type="pageEnd" name="PageEnd_183" data-page="183"></a><a data-type="pageEnd" name="PageEnd_184" data-page="184"></a> <p id="BPHPGS19T2NF7BDH7858" id-sequence="894">Unlike most other sensory input to the brain, olfactory pathways do not make direct connections with the thalamus before the information reaches the cerebral cortex. Instead, fibers from the olfactory bulbs proceed to the olfactory cortex, located in the lower portions of the frontal lobe extending into the temporal lobe, and to the amygdala. Because of the role these areas of the brain play in emotion, which we described in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="ZUXJT37ZGC28NP5YG839" data-chapter-id="ZUXJT37ZGC28NP5YG839" data-element-id="ZUXJT37ZGC28NP5YG839">Chapter 4</a>, these pathways may account for the significant emotional reactions we experience (disgust or pleasure) in response to odor. The olfactory cortex makes connections with the thalamus, which in turn sends information to the orbitofrontal cortex. It is likely that this pathway contributes to the conscious awareness of odors.</p> </div> <div class="pageSection" id="KQZD0E2GQU4KJDZQX993" id-sequence="895"> <h3 id="QLLFAQUMC83697860373" id-sequence="896"><span class="headingText">Gustation</span></h3> <p id="YTZGZ8VAFN41QNTZR117" id-sequence="897">The most likely original purpose of our sense of gustation, or taste, was to protect us from eating poisonous or spoiled food and to attract us to foods that boost our chances of survival. Although we seem biased toward detecting negative stimuli (<span class="citation" id="HZUR6S99W0QPLHDJT560" id-sequence="898">Cacioppo &amp; Gardner, 1999</span>), our attraction to certain tastes also reflects our historical past. Because most of our ancestors were constantly facing the threat of famine, we find fatty and sugary foods to be especially tasty. Unfortunately, given the current availability of safe and palatable foods, our sense of taste may drive us to eat more than we need.</p> <p id="QZZQK9QEZNBJ8FYGK943" id-sequence="899">Most of us are familiar with four major categories of taste: sweet, sour, salty, and bitter. A fifth type of taste has been proposed, known by the Japanese term <em>umami</em>, which roughly translated means “savory” or “meaty”(<span class="citation" id="BGLXYUARMCSCG8AUP160" id-sequence="900">Chaudhari, Landlin, &amp; Roper, 2000</span>). In addition, the tongue and the mouth contain receptors for carbohydrates (<span class="citation" id="HHYPLNDAWW1448MY7155" id-sequence="901">Turner, Byblow, Stinear, &amp; Gant, 2014</span>) and capsaicin, an active ingredient in hot peppers. Mice lacking capsaicin receptors happily consumed water containing capsaicin at levels that were rejected by normal mice (<span class="citation" id="SGAE82K0ABHJU4XEQ394" id-sequence="902">Caterina et al., 2000</span>).</p> <p id="FNCD3TTGUJ8HNPDK8461" id-sequence="903">Taste receptors are located on the tongue and in other parts of the mouth (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="RYRHR0HYGG6375NDX820" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="XNBKV9NL3DN94427M749" data-element-id="RYRHR0HYGG6375NDX820">Figure 5.40</a>). Contrary to a popular myth (usually accompanied by an equally mythological map of “taste centers” on the tongue), receptors sensitive to all types of taste are equally distributed across the tongue. You are probably aware of the bumpy texture of your tongue, which results from the presence of <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f9e" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f9e"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f9e" id="EAJXWEGCA9GNN70N8241" id-sequence="904"><span class="index nb_hidden clAnnotationDecoration rs_skip">papillae</span><span class="term"><span class="primaryTerm" id="SQAQJADKHGU071EAG834" id-sequence="905">papillae</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Small bumps on the tongue that contain taste buds.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f9e">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="SQAQJADKHGU071EAG834" id-sequence="905">papillae</span></span>
        <span class="definition rs_skip">Small bumps on the tongue that contain taste buds.</span>
        <span class="pointer"></span>
    </span>
</span>. Most papillae contain somewhere between 1 and 100 <a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0f9f" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0f9f"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0f9f" id="MUBGYUC51RPC7W33W744" id-sequence="906"><span class="index nb_hidden clAnnotationDecoration rs_skip">taste buds</span><span class="term"><span class="primaryTerm" id="KNPV4XHHDNP7N8K73169" id-sequence="907">taste buds</span></span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A structure found in papillae that contains taste receptor cells.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0f9f">
    <span class="glossaryPopover footnotetext">
        <span class="term"><span class="primaryTerm" id="KNPV4XHHDNP7N8K73169" id-sequence="907">taste buds</span></span>
        <span class="definition rs_skip">A structure found in papillae that contains taste receptor cells.</span>
        <span class="pointer"></span>
    </span>
</span>. Each taste bud contains between 50 and 150 receptor cells, which extend tiny hairlike cilia into the saliva that interact with dissolved taste stimuli and transduce the resulting information into neural signals. Like olfactory receptors, taste buds have a limited life before they are replaced. If you burn your tongue by drinking hot<a data-type="pageEnd" name="PageEnd_185" data-page="185"></a> liquid, your taste is affected for a day or two. However, when the taste buds are replaced, taste should be back to normal.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1512 rs_skip" id="RYRHR0HYGG6375NDX820" clrenderdata="[&quot;KRYR2JPJ94FK0W7V7983&quot;]" id-sequence="908"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f40-t2.png" data-width="534" data-height="335" data-alt="A set of four images showing the taste receptors. The image on the left show a tongue with papillae labeled. The papilla is enlarged and shown in the image at the bottom. The labeled part is the taste bud. The taste bud is labeled and shown in the image at the top. The labeled parts are microvilli, supporting cells, taste receptors and axons of cranial nerves. The image on the right shows cross section of a papilla."></div><div class="nb_media image wide"><div class="mediaTitle" id="PTBP9U25J37Z0Z5J7178" id-sequence="909"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.40</span></span><span class="mediaAssetTitle">Taste Receptors.</span></div><div class="mediaDescription" id="SQQCS7Y9P1W6KCU74291" id-sequence="910"><p>Taste buds are located in the bumps, or papillae, located on the tongue.</p></div> <div class="imageContainer" style="width:534px;height:335px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f40-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A set of four images showing the taste receptors. The image on the left show a tongue with papillae labeled. The papilla is enlarged and shown in the image at the bottom. The labeled part is the taste bud. The taste bud is labeled and shown in the image at the top. The labeled parts are microvilli, supporting cells, taste receptors and axons of cranial nerves. The image on the right shows cross section of a papilla." width="534" height="335" class="rs_skip"></div><div class="mediaCredit">Steve Gschmeissner/Science Source </div> </div></div></div> <p id="WVUFGLT5BL4HR8PX7758" id-sequence="911">Information about taste travels from the mouth and the tongue to the medulla. The medulla in turn communicates with the thalamus, which sends taste information to the insula, lower somatosensory cortex of the parietal lobe, and to the orbitofrontal cortex, where the emotional pleasantness or unpleasantness of particular stimuli is processed (<span class="citation" id="HKED396G1602H7XCH613" id-sequence="912">Kobayakawa et al., 2005</span>). As we will see in <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="XKHL3QC5PGZGPGMSD189" data-chapter-id="XKHL3QC5PGZGPGMSD189" data-element-id="XKHL3QC5PGZGPGMSD189">Chapters 7</a> and <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="QYWRDYP5W4T8QDDWS317" data-chapter-id="QYWRDYP5W4T8QDDWS317" data-element-id="QYWRDYP5W4T8QDDWS317">8</a>, taste information interacts with motivation and learning.</p> </div> <div class="footnotes"></div></div><div id="footer" id-sequence="913"></div></div><div class="container page "><div id="header" id-sequence="916"><div id="breadcrumb-old" id-sequence="917" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="918" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="LVSGT1CQMKHEC9S0M512" id-sequence="919"><span class="sectionLabel rs_skip">5-5c</span> <span class="headingText">Perception and Cognition in the Chemical Senses</span></h2></div><div class="content" id="FGYH01JSJBXD0V27L228_content" id-sequence="920"> <p id="ZVTR9DA0LDW24VDFN224" id-sequence="921">Olfaction and gustation share three interesting perceptual themes: </p><ul class="custom" id="CXJPRRQG4ES8TCKJN363" id-sequence="922"> <li id="UVSX28WWLA0LVXQQA954" id-sequence="923"><span class="manualLabel" char="3">(a)</span><p id="RMQLCS9UFSUQD1V7A468" id-sequence="924">We can easily identify a number of complex stimuli combining many types of molecules, such as the aroma of coffee;</p></li> <li id="RTTGRYEWE9D8BJJTD414" id-sequence="925"><span class="manualLabel" char="3">(b)</span><p id="ADQNXGNAR3XD8536Q110" id-sequence="926">we can detect small differences among similar smells and tastes; and</p></li> <li id="LWSWVMN0EMFA9XNXR752" id-sequence="927"><span class="manualLabel" char="3">(c)</span><p id="GNMWNKQFFSYPYXKEH899" id-sequence="928">our experience often shapes our perception of an olfactory or gustatory stimulus (<span class="citation" id="RUANLMKPQ7Z3UV5BC691" id-sequence="929">Goldstein, 2010</span>).</p></li> </ul><p id="ZVTR9DA0LDW24VDFN224-1" id-sequence="930"> Humans can distinguish among at least 1 trillion odors (<span class="citation" id="EGCHJ0WZXC4EYE5B0050" id-sequence="931">Bushdid, Magnasco, Vosshall, &amp; Keller, 2014</span>). An example of the impact of experience and top-down processing on olfaction is the effect of<a data-type="pageEnd" name="PageEnd_186" data-page="186"></a> labeling an odor on people’s rating of its pleasantness. If participants smell an onion stimulus labeled “pizza,” they rate the odor as more pleasant than if the identical stimulus is labeled “body odor” (<span class="citation" id="BUCQGNRE5ACCE7Z68405" id-sequence="932">Herz, 2003</span>).</p> <div class="container dependent mt_experiencingpsychology narrative  rs_skip" id="FXNC3W360HE6TYYTD273" label="experiencingpsychology" id-sequence="933"><div class="containerHeading"><span class="label">Experiencing Psychology </span><h3 id="QFZKW5TDPKW9XQ01P433" id-sequence="934">Are You a Supertaster?</h3></div><div class="sidebarContent" id="FXNC3W360HE6TYYTD273_sidebarcontent" id-sequence="935"> <p id="XUZD2QG9VV8M0UY1L435" id-sequence="936">About 25% of the population are supertasters, or people who are extrasensitive to taste; 25% are nontasters, or people who are relatively insensitive to taste; and the remaining 50% fall between these two extremes. You can use the following exercises to determine your taste category.</p> <div class="pageSection" id="UAVS3VYQAT0TKVXY4226" id-sequence="937"> <h3 id="EGKCZE513XWW209HQ161" id-sequence="938"><span class="headingText">1. How Does Mint Taste to You?</span></h3> <p id="LKPSYYFM6Y980N866908" id-sequence="939">Place a mint Life Saver on your tongue, and allow it to dissolve (no chewing please). Rate the following qualities of the Life Saver on a scale of 1 to 5, with 1 being “very intense” and 5 being “not intense”:</p> <div class="table rs_skip" id="YKGK5JNUH0R0CAPNW013" id-sequence="940"> <div class="maintable narrowtable" style="height: auto;"><table data-width="280" class="frameall" style="width: 373px;"> <colgroup><col width="107"><col width="53"><col width="53"><col width="53"><col width="53"><col width="53"></colgroup> <tbody id="KDTJYRHRSDJ78G7TL792" id-sequence="941"> <tr class="odd" id="ZEQWLYWL24HSNDGWN663" id-sequence="942"> <td id="CWDUJTHQV85UH7E2F215" class="alignleft valigntop" id-sequence="943"><p id="VXLV8GHFQ4HRYX5Q1233" id-sequence="944">Sweetness</p></td> <td id="DFVTENL7CHPDKKTTQ080" class="alignleft valigntop" id-sequence="945"><p id="AGSC1E6ZCYCWXR0S4219" id-sequence="946">1</p></td> <td id="YKSSEGL9AZJUQ5Q27797" class="alignleft valigntop" id-sequence="947"><p id="TRJYD52HBCBU84WJU292" id-sequence="948">2</p></td> <td id="FVMA0DCR36Y173PDB235" class="alignleft valigntop" id-sequence="949"><p id="PKKYWVC3H9K8B8CCS607" id-sequence="950">3</p></td> <td id="QASWE0GVG27T02ZNY543" class="alignleft valigntop" id-sequence="951"><p id="JUDLL679U0HV8LX0V982" id-sequence="952">4</p></td> <td id="HFBJ7QDFJ8Q9LRP2E131" class="alignleft valigntop sidescore" id-sequence="953"><p id="PGSCGCL7RWDPACK58988" id-sequence="954">5</p></td> </tr> <tr class="even" id="ENUSS81WMY1FEUYXR664" id-sequence="955"> <td id="GMUBGY96PHP0U0G40567" class="alignleft valigntop" id-sequence="956"><p id="QAAYU09PAGRHEY2MB837" id-sequence="957">Smell</p></td> <td id="FDJPSL3CFG4N9D0VH544" class="alignleft valigntop" id-sequence="958"><p id="TBVTB84ZC03K0PHU9313" id-sequence="959">1</p></td> <td id="EANHUUD0NVQVZ662D321" class="alignleft valigntop" id-sequence="960"><p id="QNWJZT550GNTG1XRT205" id-sequence="961">2</p></td> <td id="JSGHHD7E3C7CXBXJ1482" class="alignleft valigntop" id-sequence="962"><p id="QBPW8DZE6V4ER1WZN286" id-sequence="963">3</p></td> <td id="URYG5XC81L7CCU6QQ920" class="alignleft valigntop" id-sequence="964"><p id="QTVXSLMCF428LHFFX199" id-sequence="965">4</p></td> <td id="AZGPBKHN2LX1FNAEH883" class="alignleft valigntop sidescore" id-sequence="966"><p id="VCUB5YJN5FAY5P4V7816" id-sequence="967">5</p></td> </tr> <tr class="odd" id="MWFLB7CLW1W2JC93E355" id-sequence="968"> <td id="KFSP2WA2VWBKW69P8730" class="alignleft valigntop" id-sequence="969"><p id="MCGWBJXWE2Y4LY5VH129" id-sequence="970">Coolness</p></td> <td id="VXSCTMHBBTDMSNY9N760" class="alignleft valigntop" id-sequence="971"><p id="VGJD2LKAKRCCVB41A558" id-sequence="972">1</p></td> <td id="PCSBFMW64T6P0YD24472" class="alignleft valigntop" id-sequence="973"><p id="BGLZ4ZM7KB7G9ZF5V139" id-sequence="974">2</p></td> <td id="XDSRG0X5Q3Y8AK7S7667" class="alignleft valigntop" id-sequence="975"><p id="WDQQ340W9KE3DTPGW839" id-sequence="976">3</p></td> <td id="NKMCN2M36426MFPE1389" class="alignleft valigntop" id-sequence="977"><p id="WYFKLCBX99Q7N5B24122" id-sequence="978">4</p></td> <td id="RDYZ7587YG238EUQU548" class="alignleft valigntop sidescore" id-sequence="979"><p id="BJGAR16754GX1V6VU889" id-sequence="980">5</p></td> </tr> <tr class="even" id="GQAKW26QSXWPSDD1R395" id-sequence="981"> <td id="CHJR9HKLJATMSWPHF516" class="alignleft valigntop underscore" id-sequence="982"><p id="YFLUXHVXC89WXJ157471" id-sequence="983">“Rush”</p></td> <td id="VUUTR540LWXHAX75M675" class="alignleft valigntop underscore" id-sequence="984"><p id="BGDG329FA8Z8ZQD5V596" id-sequence="985">1</p></td> <td id="XMRYL9TT2DLC4FN07825" class="alignleft valigntop underscore" id-sequence="986"><p id="PUZNCPK8CX30SFPUJ255" id-sequence="987">2</p></td> <td id="SZWHT3E61Z2M5SBT9452" class="alignleft valigntop underscore" id-sequence="988"><p id="VSTYATAJHK10S8111195" id-sequence="989">3</p></td> <td id="DWUP2NK5TSSFR1RY1943" class="alignleft valigntop underscore" id-sequence="990"><p id="ZESWA3YL7R7U4091V789" id-sequence="991">4</p></td> <td id="YVFMWXAA0A6KA3VXA042" class="alignleft valigntop sidescore underscore" id-sequence="992"><p id="ABFRZ2L7KFKC2QKDB407" id-sequence="993">5</p></td> </tr> </tbody> </table></div> </div> <p id="UXMNFZNXUAFNL1PEL509" id-sequence="994">How to interpret your results: Mint tasters fall into four groups:</p> <p id="UBHGCTMT2J2Z2HP7K587" id-sequence="995">Group 1: Mint is mild, no rush.</p> <p id="NVXAVTVY9V8AWUBL4804" id-sequence="996">Group 2: Mint is moderate, no rush.</p> <p id="VJWQ3P186LKEGEKD2531" id-sequence="997">Group 3: Mint is moderate, rush.</p> <p id="XKUL2BB1PUUDPHU02872" id-sequence="998">Group 4: Mint is intense, rush.</p> <p id="WHEZ0YMRHWL9Z3WBZ147" id-sequence="999"><a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="CKLUDRJGW5FT0029E933" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="FGYH01JSJBXD0V27L228" data-element-id="CKLUDRJGW5FT0029E933">Table 5.3</a> shows further characteristics of these taste groups.</p> <div class="table rs_skip" id="CKLUDRJGW5FT0029E933" id-sequence="1000"><div class="containerHeading"><span class="label">Table <span class="ordinal">5.3</span></span><h3 id="PESF18YHKGA4PX4UL632" id-sequence="1001">Interpreting Your Supertaster Results</h3></div> <div class="maintable narrowtable" style="height: auto;"><table data-width="390" class="frameall" style="width: 520px;"> <colgroup><col width="173"><col width="173"><col width="173"></colgroup> <thead> <tr id="EZBDSZGLW14SUVWHV235" id-sequence="1002"> <th id="KJQPQ7DPA7WUDF72U146" class="alignleft valignbottom underscore" id-sequence="1003"><p id="FNSQ0A5J8DCRMY01J369" id-sequence="1004">Mildly Sensitive Tasters (Group 1)</p></th> <th id="SWPD56JKL2RG14LS0437" class="alignleft valignbottom underscore" id-sequence="1005"><p id="NKSYND2Q1SQFJYAZ0494" id-sequence="1006">Moderately Sensitive Tasters (Groups 2 and 3)</p></th> <th id="LFDRK72FVF8XCM0BB329" class="alignleft valignbottom underscore sidescore" id-sequence="1007"><p id="NBDLHE8FP758P4FLW427" id-sequence="1008">Supertasters (Group 4)</p></th> </tr> </thead> <tbody id="MZVNYG3E4N0S21SEU522" id-sequence="1009"> <tr class="odd" id="HCTF1VQN0WVLNERW1297" id-sequence="1010"> <td id="JZTP3KXXAC9RCPZSR172" class="alignleft valigntop" id-sequence="1011"><p id="TLMLBB7SU80TYT7ET968" id-sequence="1012">Weak to undetectable sensation from mint.</p></td> <td id="HTVA1Q23K66ZVE9MD203" class="alignleft valigntop" id-sequence="1013"><p id="ACBJ4X4J88W7Q25P1594" id-sequence="1014">Moderate to strong sensation from mint.</p></td> <td id="CBVGZ0WTG3SGW4S1K102" class="alignleft valigntop sidescore" id-sequence="1015"><p id="BNKPUKDK3BWV0PFUN768" id-sequence="1016">Very strong sensation from mint.</p></td> </tr> <tr class="even" id="MZAU60SAU271MAPR8234" id-sequence="1017"> <td id="ZVTESBMWNP6SJ9FGU547" class="alignleft valigntop" id-sequence="1018"><p id="YQNY92QWGCBPEDCWB892" id-sequence="1019">Flavor of food is not that important.</p></td> <td id="MMAR8CDMUHK2420PV193" class="alignleft valigntop" id-sequence="1020"><p id="AHXR1SCC1J9UA1MV0647" id-sequence="1021">Flavor of food is important.</p></td> <td id="ZFZZSGWF88XKU301H785" class="alignleft valigntop sidescore" id-sequence="1022"><p id="NZWVMDJRFDRNDM5YV022" id-sequence="1023">Flavor of food is important.</p></td> </tr> <tr class="odd" id="PYKBKK96WMVJZZ7D4118" id-sequence="1024"> <td id="DYDA0PUN33M9QY5MX813" class="alignleft valigntop underscore" id-sequence="1025"><p id="ANAW5KETQGQHJ3662672" id-sequence="1026">Many foods liked, few foods disliked, and not passionate about food.</p></td> <td id="SPFH4VRMSABXP9TSZ293" class="alignleft valigntop underscore" id-sequence="1027"><p id="FCLF64L1N7W8MRV73797" id-sequence="1028">Many foods liked, few foods disliked, and often passionate about food.</p></td> <td id="EJHH9SHNBJ8TLBS0X550" class="alignleft valigntop sidescore underscore" id-sequence="1029"><p id="JDXPXWD9PZ15UKLC9558" id-sequence="1030">Great variation in the number of foods liked and often passionate about food.</p></td> </tr> </tbody> </table></div> </div> </div> <div class="pageSection" id="QZWRJ9EQYB65BGSGS145" id-sequence="1031"> <h3 id="PFTWU9HY553291BA2122" id-sequence="1032"><span class="headingText">2. Count Your Papillae</span></h3> <p id="NKREFUCV7DN3GVS2A361" id-sequence="1033">You need a gummed reinforcer (sticky white ring for notebooks), a swab, blue food coloring, and a mirror.</p> <p id="QXHFGXK7S3EUVJ6JF685" id-sequence="1034">Place one reinforcer on the front of your tongue just to the side of midline. Use a swab to apply blue food coloring to the part of your tongue that shows through the center of the reinforcer. The blue food coloring should make your papillae (bumps) more obvious. Count the number of papillae you see in the ring. More than 25 papillae within the reinforcer ring means you’re a supertaster. The number of papillae of mildly or moderately sensitive tasters will be less than 25, but these two groups cannot be distinguished based on this factor.</p> </div> <div class="pageSection" id="WQQWL4W35U2EJ7PQY918" id-sequence="1035"> <h3 id="RTASP74E3MQ7H0JC4989" id-sequence="1036"><span class="headingText">3. Other Eating Habits</span></h3> <p id="LLQYY3KYXM8A1BE93660" id-sequence="1037">Rate the tastes of the following foods and drinks using a 1-to-5 scale, with 1 being “dislike strongly” and 5 being “like a great deal”:</p> <div class="table rs_skip" id="AYVDUEBQ79GVCM6M1865" id-sequence="1038"> <div class="maintable narrowtable" style="height: auto;"><table data-width="280" class="frameall" style="width: 373px;"> <colgroup><col width="107"><col width="53"><col width="53"><col width="53"><col width="53"><col width="53"></colgroup> <tbody id="XPNLFQV99TKUS8HA6436" id-sequence="1039"> <tr class="odd" id="SFGJ60VZDC9X3J3VR592" id-sequence="1040"> <td id="CKNQXNMKD161ZUNDB121" class="alignleft valigntop" id-sequence="1041"><p id="KZWC2EK4SE5CH61NM731" id-sequence="1042">Broccoli</p></td> <td id="KYDWR5LWSTQ4VNHJG562" class="alignleft valigntop" id-sequence="1043"><p id="CLTCRFNK78BXF7WWQ885" id-sequence="1044">1</p></td> <td id="RYHP9TSDRYR7RBWSU986" class="alignleft valigntop" id-sequence="1045"><p id="VYBW9STQKD3J93LWB589" id-sequence="1046">2</p></td> <td id="CUSGKW3J3FWAV9S56548" class="alignleft valigntop" id-sequence="1047"><p id="MMGKHC3399EKAT5E3219" id-sequence="1048">3</p></td> <td id="EPZG2FGZGRUWTKK48431" class="alignleft valigntop" id-sequence="1049"><p id="TVFKEA46F6ANDTQKM876" id-sequence="1050">4</p></td> <td id="MQVMVC5E841UA6EN6446" class="alignleft valigntop sidescore" id-sequence="1051"><p id="JAELGPCD8F9P2AJPJ655" id-sequence="1052">5</p></td> </tr> <tr class="even" id="JGRT47UUREEE02RQK741" id-sequence="1053"> <td id="PTDAXZNZ1GK8J6BMR658" class="alignleft valigntop" id-sequence="1054"><p id="LVRWN6M0JGGBY2TMQ556" id-sequence="1055">Grapefruit</p></td> <td id="QEAKJ8Z4X8PF1F8ST189" class="alignleft valigntop" id-sequence="1056"><p id="PQGR1KHNFP4XAM32P977" id-sequence="1057">1</p></td> <td id="TQAGBDPN5RW9L2G4S829" class="alignleft valigntop" id-sequence="1058"><p id="QXUKUYS6KEA4TEX83219" id-sequence="1059">2</p></td> <td id="HVHM77PHTUJMPGFDU108" class="alignleft valigntop" id-sequence="1060"><p id="YUQYBCDUKN9H0Q089095" id-sequence="1061">3</p></td> <td id="HMAK347JBPBTASF8E969" class="alignleft valigntop" id-sequence="1062"><p id="BLGC7VTY4WCZ6QL15904" id-sequence="1063">4</p></td> <td id="QDDPE2WV7UFWUHMV1246" class="alignleft valigntop sidescore" id-sequence="1064"><p id="TSAXYVRGA3XQK17S6733" id-sequence="1065">5</p></td> </tr> <tr class="odd" id="QFTRNYK2V2KNUY8WJ952" id-sequence="1066"> <td id="KLZBYXHV75M59JUCU614" class="alignleft valigntop" id-sequence="1067"><p id="DWNSCJSW876Y0PX8R892" id-sequence="1068">Coffee (black)</p></td> <td id="NFUY1RAYSLD641DAX364" class="alignleft valigntop" id-sequence="1069"><p id="NHPZY42AALZVVH8YY854" id-sequence="1070">1</p></td> <td id="PANUHZX9WUPHZ8DMB742" class="alignleft valigntop" id-sequence="1071"><p id="VDLV345X82XLEVSDB716" id-sequence="1072">2</p></td> <td id="YGWFTZF7GT5L051GQ724" class="alignleft valigntop" id-sequence="1073"><p id="XDEC7ALBNN6ZRPCP3636" id-sequence="1074">3</p></td> <td id="SDXBBHQ4FETP2S43W858" class="alignleft valigntop" id-sequence="1075"><p id="CYTGKURK7Z244VCNY472" id-sequence="1076">4</p></td> <td id="AKJV3HUNES6C57312750" class="alignleft valigntop sidescore" id-sequence="1077"><p id="ASMTGUS4A0XZBLW9P641" id-sequence="1078">5</p></td> </tr> <tr class="even" id="RPHGQDNYVERNS6A1M532" id-sequence="1079"> <td id="KSUWFV5WD95ZG9QAS522" class="alignleft valigntop underscore" id-sequence="1080"><p id="AXNNMVTTC0EM4EM4F350" id-sequence="1081">Dark chocolate</p></td> <td id="WVHFYGEUZVT736JPS458" class="alignleft valigntop underscore" id-sequence="1082"><p id="SDRT0T6NUJMCS04FC839" id-sequence="1083">1</p></td> <td id="ADPZTJ4UKJSKD741V064" class="alignleft valigntop underscore" id-sequence="1084"><p id="JRAVTA5W73MHQTQWP501" id-sequence="1085">2</p></td> <td id="UERY4P3318KE8ACWP911" class="alignleft valigntop underscore" id-sequence="1086"><p id="MZREAXRPDE62YYZSQ042" id-sequence="1087">3</p></td> <td id="TBMGK7EQZ2VPBVXWN768" class="alignleft valigntop underscore" id-sequence="1088"><p id="CWTMCMSMVMFZZU78J053" id-sequence="1089">4</p></td> <td id="HCCJB85VWMLJDC6K1835" class="alignleft valigntop sidescore underscore" id-sequence="1090"><p id="TWNFRUQYU3HEXSHXR306" id-sequence="1091">5</p></td> </tr> </tbody> </table></div> </div> <p id="HPDA2UE9W1PR0HNKY647" id-sequence="1092">As a child, were you ever described by a parent, teacher, or other adult as a “picky eater”? (circle one)</p> <p id="LRRURRQJFZBYX99XU438" id-sequence="1093">YES</p> <p id="EZWGN9WHMFMQ0WAT8540" id-sequence="1094">NO</p> <p id="JGTE2XYNA45N0WWZM739" id-sequence="1095">Can you easily tell the difference between the fat content of milk, for example, between whole and 2% milk or between 1% and 2% milk? (circle one)</p> <p id="PBJJTT7SNDBFPWZWJ891" id-sequence="1096">YES</p> <p id="TEQWFBS1U4M0VHWWA559" id-sequence="1097">NO</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1513 rs_skip" id="YFMJPL49AA51UHYSK930" clrenderdata="[&quot;ALCLGF3JZ96HS9CZ1602&quot;]" id-sequence="1098"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf31-t2.png" data-width="543" data-height="368" data-alt="A woman with her tongue out on the left. On the right is the enlarged image of the tongue colored blue with yellow dots on it."></div><div class="nb_media image unnumbered wide"><div class="mediaDescription" id="MGUA1P3QC6082RLGW896" id-sequence="1099"><p>Placing blue food coloring on the tongue makes the papillae easier to see. Supertasters have many more papillae, and thus more taste buds, than other people.</p></div> <div class="imageContainer" style="width:543px;height:368px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf31-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A woman with her tongue out on the left. On the right is the enlarged image of the tongue colored blue with yellow dots on it." width="543" height="368" class="rs_skip"></div><div class="mediaCredit">Blend Images/Alamy Stock Photo; Roger Freberg </div> </div></div></div> <p id="TDMP1RVSMVDGJBMXQ795" id-sequence="1100">Supertasters tend to dislike bitter foods; they have many low numbers. Supertasters also tend to be picky eaters as children and are better at detecting differences in fats in foods.</p> </div> </div></div> <p id="VYKJRLUM5FW4TBLQZ261" id-sequence="1101">The chemical senses interact to provide the perception of flavor. You have probably noticed that food doesn’t taste good when your sense of smell is decreased by a bad cold. If you close your eyes and hold your nose, you are unable to distinguish between a slice of apple and a slice of raw potato. The orbitofrontal cortex plays an important role in the perception of flavor because the pathways serving olfaction and gustation converge in this part of the brain (<span class="citation" id="BTJU864YBJ9VHL9PP342" id-sequence="1102">Rolls, 2000</span>).</p> <div class="footnotes"></div></div><div id="footer" id-sequence="1103"></div></div><div class="container page "><div id="header" id-sequence="1106"><div id="breadcrumb-old" id-sequence="1107" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="1108" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="WMBLXHAWHVH9CHJCT071" id-sequence="1109"><span class="sectionLabel rs_skip">5-5d</span> <span class="headingText">Developmental and Individual Differences in the Chemical Senses</span></h2></div><div class="content" id="VCWDNHQS7VADTHARM103_content" id-sequence="1110"> <p id="FFXMSEYWD1JE5VCCR959" id-sequence="1111">Young children are notorious for putting things in their mouths that adults would quickly reject based on taste, including poisonous substances such as drain cleaner. However, this propensity does not mean that children lack a sense of taste. Using facial expressions, researchers have demonstrated that newborns differentiate among sweet, bitter, and sour tastes but seem relatively oblivious to salty tastes (<span class="citation" id="EUGXBMYZB8K1GK3L6076" id-sequence="1112">Rosenstein &amp; Oster, 1988</span>). As we get older, the<a data-type="pageEnd" name="PageEnd_187" data-page="187"></a> overall number of taste buds decreases, reducing the intensity of many tastes and providing a possible explanation for why some strong flavors, such as that of broccoli, are enjoyed more by adults than by children. As we age, our sensitivity to smell also decreases (<span class="citation" id="VAVGYE9Z59AVSXYJH678" id-sequence="1113">Cain &amp; Gent, 1991</span>). Because olfaction and taste interact to form the flavor of foods, decreased sensitivity in both senses might affect overall appetite as we age.</p> <p id="FQAQYW8PE6ES19JHJ427" id-sequence="1114">Like the other sensory modalities discussed in this chapter, the chemical senses vary from person to person. Females are generally more sensitive to smell than are males (<span class="citation" id="PVAR9GAPUTC76YNS9886" id-sequence="1115">Dorries, 1992</span>; <span class="citation" id="SQZCDT3ZTY9NYW070042" id-sequence="1116"> Koelega &amp; Koster, 1974</span>; <span class="citation" id="BMZHHBYG3B0VU0KLQ424" id-sequence="1117"> Ship &amp; Weiffenbach, 1993</span>). The average person has approximately 6,000 taste buds, but this number may vary widely. Supertasters have unusually high numbers of papillae and, therefore, have more taste buds (<span class="citation" id="ZMGNMUNWDE4NPFH1K771" id-sequence="1118">Bartoshuk, 2000</span>).</p> <p id="MWKD6DYQJ3967YLFG918" id-sequence="1119">Disturbances in the chemical senses are correlated with several psychological disorders. Olfaction and the experience of posttraumatic stress disorder (PTSD) (see <a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="KNKVM7TED147CWT15523" data-chapter-id="KNKVM7TED147CWT15523" data-element-id="KNKVM7TED147CWT15523">Chapter 14</a>) appear to interact in combat veterans. PTSD is often characterized by intrusive, disturbing flashbacks in which the patient essentially relives the traumatic experience. Given the close association between olfaction and memory, researchers hypothesized that some PTSD flashbacks could be initiated by relevant smells. When compared to combat veterans who did not have PTSD, combat veterans with the disorder experienced marked anxiety when exposed to the smell of diesel, accompanied by changes in the activity of the amygdala (<span class="citation" id="PHZAP2NX4388YG11H188" id-sequence="1120">Vermetten, Schmahl, Southwick, &amp; Bremner, 2007</span>).</p> <div class="footnotes"></div></div><div id="footer" id-sequence="1121"></div></div><div class="container page "><div id="header" id-sequence="1124"><div id="breadcrumb-old" id-sequence="1125" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="1126" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h2 id="LVVZE5VU9HJV37XHW877" id-sequence="1127"><span class="sectionLabel rs_skip">5-5e</span> <span class="headingText">Sociocultural Influences on the Chemical Senses</span></h2></div><div class="content" id="MQBWE81ACZV4FXDGK821_content" id-sequence="1128"> <p id="NMASULEMXS2RN0U4J684" id-sequence="1129">The sense of smell might seem to play a secondary role to vision and audition in humans, but people have manipulated scent for religious, medicinal, and personal purposes since ancient times. We can speculate that once people learned to control fire, a recognition that<a data-type="pageEnd" name="PageEnd_188" data-page="188"></a> some burning things smelled better than others could not have been far behind, possibly leading to the use of incense in religious rituals. Use of natural materials for medicine and self-adornment provides the historical roots for large, contemporary industries that manufacture scent for a host of consumer products, including perfume, air fresheners, “new car smell” products, and detergents.</p> <div class="container dependent mt_interpersonalrelationships narrative  rs_skip" id="VZKATKCEY1CVCMRNV978" label="interpersonalrelationships" id-sequence="1130"><div class="containerHeading"><span class="label"> Interpersonal Relationships</span><h3 id="BBNKPXRBCXP63U9SX527" id-sequence="1131">Sensation and Perception Perspectives</h3></div><div class="sidebarContent" id="VZKATKCEY1CVCMRNV978_sidebarcontent" id-sequence="1132"> <div class="pageSection" id="JHYCD4E4RUJCM92H9454" id-sequence="1133"> <h3 id="CRHXLAP1U2CCYBUXT554" id-sequence="1134"><span class="headingText">Can Relationships Buffer the Experience of Pain?</span></h3> <p id="MLULDD5BPG1J6T6TP888" id-sequence="1135">We mentioned earlier that of the senses we discussed in this chapter, pain was particularly influenced by cognition and context. Can being in a close relationship affect the way you feel pain?</p> <p id="KVYXCLX57RTVSLCKF137" id-sequence="1136">The answer appears to be “yes.” Physical contact with a loved one can affect how the brain processes pain. Women who were expecting an electric shock showed reduced activity in parts of the brain associated with the emotional and arousing aspects of pain when they held their husbands’ hands (Coan, Schaefer, &amp; Davidson, 2006). In addition, the amount of reduction of activity in these pain areas of the brain correlated with the quality of the marriage—happily married women experienced greater decreases in activity associated with pain than less happily married women.</p> <p id="PMYNXUHETHS9CRA0E512" id-sequence="1137">Perhaps this buffering effect is why you may reach for your partner when frightened during a scary movie. Knowing that such intimacy could reduce a loved one’s pain might compel you to accompany your partner to a doctor’s appointment or visit a friend in the hospital. Our understanding of pain in connection with our interpersonal relationships can help us in tangible ways to create and maintain stronger, healthier relationships.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1514 rs_skip" id="UPLKZ9VSP41ZXUPPD103" clrenderdata="[&quot;LPHK1UEF70W1A6T19420&quot;]" id-sequence="1138"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf33-t2.jpg" data-width="412" data-height="269" data-alt="Research shows that physical contact with loved ones reduces the sensation of pain."></div><div class="nb_media image unnumbered"><div class="mediaDescription" id="HQYHEWK3S8RC7K3AH766" id-sequence="1139"><p>Research shows that physical contact with loved ones reduces the sensation of pain.</p></div> <div class="imageContainer" style="width:412px;height:269px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf33-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Research shows that physical contact with loved ones reduces the sensation of pain." width="412" height="269" class="rs_skip"></div><div class="mediaCredit">Science Photo Library/Alamy Stock Photo </div> </div></div></div> </div> </div></div> <p id="CVWXBT4T5W9MDLCDJ969" id-sequence="1140">Although olfaction often seems to run in the background of our other cognitive processes, it is not immune to the effects of culture and experience. Americans spend millions on products that remove or mask body odor, whereas other cultures do not find such odors offensive. One study compared the categorization of odors by French, American, and Vietnamese participants (<span class="citation" id="LGNDFTDFFS00KFLWE598" id-sequence="1141">Chrea et al., 2004</span>). Although the participants sorted odors similarly into broad categories of floral, sweet, bad, and natural, they differed along subtler dimensions. The French and American participants quickly sorted odors into fruit or flower categories, but this separation had little relevance to the<a data-type="pageEnd" name="PageEnd_189" data-page="189"></a> Vietnamese participants. French and French-Canadian participants rated the pleasantness of wintergreen quite differently (<span class="citation" id="UMFUMGB39K49Q4PFZ298" id-sequence="1142">Ferdenzi et al., 2016</span>). Wintergreen is used in candy in Canada, but in medicine in France.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1515 rs_skip" id="RQGVT5R6FD2FREJUX585" clrenderdata="[&quot;KERHJYUFBA1VBK6NK024&quot;]" id-sequence="1143"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf34-t2.jpg" data-width="510" data-height="373" data-alt="Different cultures can prefer different foods. It is unlikely that you will find fruit bat pie, a delicacy in Palau, in many American restaurants."></div><div class="nb_media image unnumbered wide"><div class="mediaDescription" id="EVWGB7CL36EQTGFRN344" id-sequence="1144"><p>Different cultures can prefer different foods. It is unlikely that you will find fruit bat pie, a delicacy in Palau, in many American restaurants.</p></div> <div class="imageContainer" style="width:510px;height:373px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf34-t2.jpg?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="Different cultures can prefer different foods. It is unlikely that you will find fruit bat pie, a delicacy in Palau, in many American restaurants." width="510" height="373" class="rs_skip"></div><div class="mediaCredit">Kristin Saling </div> </div></div></div> <div class="container dependent mt_psychologytakesonrealworldproblems narrative  rs_skip" id="KMATZ1RV14WHPZHCJ727" label="psychologytakesonrealworldproblems" id-sequence="1145"><div class="containerHeading"><span class="label"> Psychology Takes on Real-World Problems</span><h3 id="SVYYWDMU7HTUGS19D933" id-sequence="1146">When Is Behavior Perceived as Cyberbullying?</h3></div><div class="sidebarContent" id="KMATZ1RV14WHPZHCJ727_sidebarcontent" id-sequence="1147"> <p id="NZKNKL6MEQ2FQ0X4H324" id-sequence="1148">As we have seen in this chapter, different people watching the same event can reach different conclusions about what just happened. If researchers are to truly understand a problem such as cyberbullying, they must have methods for identifying perceptions of the experience from the perspectives of those involved.</p> <p id="JCAY81YEKFMTNMJA8392" id-sequence="1149">There are two major approaches for collecting information about cyberbullying: self-report and peer-nomination (<span class="citation" id="VEUPBUW6BXEWZ8ZP6084" id-sequence="1150">Pellegrini, 2001</span>). Each provides a unique perspective. Self-report asks youth to identify the frequency and the degree of cyberbullying that they have experienced or perpetrated personally, along with their emotional responses to these instances. Because cyberbullying often takes place where adult supervision is scarce, self-report can be more useful than observation. At the same time, self-report can be biased.</p> <p id="JMBHX4QVKQG29L80C012" id-sequence="1151">Peer nomination provides insight into the larger group’s perception of the individuals being bullied or of the aggressors (<a href="javascript://" data-link-type="bookmark" data-isbn="9781337561815" data-link-id="EAXTE4A8T4MF5M9AR814" data-chapter-id="MHBJUR6JN6H15AF1Q599" data-section-id="MQBWE81ACZV4FXDGK821" data-element-id="EAXTE4A8T4MF5M9AR814">Figure 5.41</a>). Again, this method does a good job of providing information that is not typically accessible to adults. To conduct a peer nomination, students are provided with photos or a roster of their group, usually their class. Youth are asked to identify which classmates are picked on frequently and which do the bullying. Peer nominations generally show high correlations among the participants.</p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1516 rs_skip" id="EAXTE4A8T4MF5M9AR814" clrenderdata="[&quot;MPEFW3G2TVHGXBY9R618&quot;]" id-sequence="1152"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_f41-t2.png" data-width="322" data-height="249" data-alt="A graph showing peer nomination. On the X axis are negative votes and positive votes and on the Y axis are the number of votes. The locations of the following are shown on the graph: rejected, controversial, popular, average and ignored."></div><div class="nb_media image"><div class="mediaTitle"><span class="mediaFigureLabel"><span class="mediaLabelText">Figure </span><span class="mediaFigureNumber">5.41</span></span></div><div class="mediaDescription" id="DJZMPH1847BSJA762225" id-sequence="1153"><p>Peer Nomination. The peer nomination method provides information about how individuals are viewed by their peers. This information usually shows high levels of consensus and provides insights about the group that are not usually observable by outsiders such as teachers and parents.</p></div> <div class="imageContainer" style="width:322px;height:249px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_f41-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="A graph showing peer nomination. On the X axis are negative votes and positive votes and on the Y axis are the number of votes. The locations of the following are shown on the graph: rejected, controversial, popular, average and ignored." width="322" height="249" class="rs_skip"></div> </div></div></div> <p id="BYHR4QDESCBP4WJTU692" id-sequence="1154">Self-report and peer nomination results can be complimentary, providing perceptions of cyberbullying from both the perspective of the individuals involved and of the peers observing the cyberbullying. In both cases, these methods can provide insight into the phenomenon often unavailable to observation by parents, teachers, researchers, and other adults.</p> </div></div> <p id="RJJK0ZLB2MUGA9KCQ764" id-sequence="1155">Experience clearly plays a role in developing an individual’s taste preferences. The effects of experience on taste begin in the prenatal environment. Infants whose mothers consumed carrot juice during pregnancy showed stronger preferences for carrot flavor (<span class="citation" id="KSMBPL7DX7XX6H44N612" id-sequence="1156">Mennella &amp; Beauchamp, 1996</span>; <span class="citation" id="VCASVA9E5LMWD8AW6857" id-sequence="1157"> Mennella, Jagnow, &amp; Beauchamp, 2001</span>). In terms of survival, this result makes perfect sense. Infants are born with a predisposition to like the safe foods available in their environment. Because the food supply historically has varied widely from place to place, delicacies such as fruit bat pie are appreciated in Palau but not necessarily in the United States.</p> <div class="container dependent mt_summary narrative  rs_skip" id="WAVSBQ4G0YYV7DEH0332" label="summary" id-sequence="1158"><div class="containerHeading"><span class="label">Summary <span class="ordinal">5.3</span></span><h3 id="JGMJACSW6W4GBY90X741" id-sequence="1159">Important Structures in Audition</h3></div><div class="sidebarContent" id="WAVSBQ4G0YYV7DEH0332_sidebarcontent" id-sequence="1160"> </div></div> <div class="table rs_skip" id="PKQCJBXSXJ3BC5VUS009" id-sequence="1161"> <div class="maintable narrowtable longtable" style="height: 711px;"><table data-width="350" class="frameall" style="width: 467px;"> <colgroup><col width="200"><col width="267"></colgroup> <thead> <tr id="HWWE33VT90M1JW0A7955" id-sequence="1162"> <th id="MMFMH6ZCP3NMSMNML704" class="alignleft valignbottom underscore" id-sequence="1163"><p id="BPNY3BBGAS82MT2GP211" id-sequence="1164">Structure</p></th> <th id="QMYXKC46J21B086WY551" class="alignleft valignbottom underscore sidescore" id-sequence="1165"><p id="QABQA7J4NJU4E1MFL449" id-sequence="1166">Function</p></th> </tr> </thead> <tbody id="XNMDXFUUADF5J97BK042" id-sequence="1167"> <tr class="odd" id="HAYGLXEELMXZL6VEX443" id-sequence="1168"> <td id="HFCHRZVWPN4Q6SCFD841" class="alignleft valigntop underscore" id-sequence="1169"><p id="ZBYDVPSKEC2DZTV35255" id-sequence="1170"><strong><em>Pinna</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1517 rs_skip" id="UBJE4UMMFFCMZ93KG248" clrenderdata="[&quot;XTLW0BHR7TK8VCL67240&quot;]" id-sequence="1171"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf35-t2.png" data-width="97" data-height="96" data-alt="An illustration showing the pinna."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:97px;height:96px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf35-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing the pinna." width="97" height="96" class="rs_skip"></div> </div></div></div></td> <td id="EYYV28XYNBC2S2QF2420" class="alignleft valigntop sidescore underscore" id-sequence="1172"><p id="AFMY2RB1S02AJRBZB528" id-sequence="1173">Collects sound and identifies its location as coming from above or below the head.</p></td> </tr> <tr class="even" id="ZGQRWJ60LSC94BP1P399" id-sequence="1174"> <td id="NENRUH35HKH7ECJ8A460" class="alignleft valigntop underscore" id-sequence="1175"><p id="DFYEE49URF9RZWNU8543" id-sequence="1176"><strong><em>Tympanic membrane</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1518 rs_skip" id="UBDTTVMDSB6K85A0V388" clrenderdata="[&quot;JASHVHXFVX2VEGVDY192&quot;]" id-sequence="1177"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf36-t2.png" data-width="101" data-height="97" data-alt="An illustration showing the tympanic membrane."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:101px;height:97px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf36-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing the tympanic membrane." width="101" height="97" class="rs_skip"></div> </div></div></div></td> <td id="PHDQXQMCRS93BNXQ5654" class="alignleft valigntop sidescore underscore" id-sequence="1178"><p id="XSUM658X9DEV0GXNW088" id-sequence="1179">Begins the process of transduction of sound waves to neural signals when movement occurs.</p></td> </tr> <tr class="odd" id="ZXNSCPQ0J39UJSEL8849" id-sequence="1180"> <td id="GBKJAGCZRA0DKB6BW332" class="alignleft valigntop underscore" id-sequence="1181"><p id="ZGWSJ19AGN10A20ZW407" id-sequence="1182"><strong><em>Cochlea</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf1519 rs_skip" id="QSMKC5LCQT35R1NKV062" clrenderdata="[&quot;DYKAHQ65K3DRJ56SP112&quot;]" id-sequence="1183"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf37-t2.png" data-width="101" data-height="99" data-alt="An illustration showing the cochlea."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:101px;height:99px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf37-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing the cochlea." width="101" height="99" class="rs_skip"></div> </div></div></div></td> <td id="PBXVPTSRPTSGBJT4C173" class="alignleft valigntop sidescore underscore" id-sequence="1184"><p id="BBRSNH36XM46REQ8R779" id-sequence="1185">Contains auditory receptors.</p></td> </tr> <tr class="even" id="HEHC4Q7WWV85FVZ0M331" id-sequence="1186"> <td id="YJAKAA7JXERPB2DGX291" class="alignleft valigntop underscore" id-sequence="1187"><p id="GURCH7089FBPQMBWR929" id-sequence="1188"><strong><em>Thalamus</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf151a rs_skip" id="PNQGC9Z0Z4M2P1CWS308" clrenderdata="[&quot;MNMJP775QKXKC61MT963&quot;]" id-sequence="1189"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf38-t2.png" data-width="101" data-height="96" data-alt="An illustration showing the thalamus."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:101px;height:96px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf38-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing the thalamus." width="101" height="96" class="rs_skip"></div> </div></div></div></td> <td id="BGSWFUQLPNVL8R1G9319" class="alignleft valigntop sidescore underscore" id-sequence="1190"><p id="ZRNBDFZPQZPVUA05Q874" id-sequence="1191">Receives auditory input from the brainstem and connects to the primary auditory cortex.</p></td> </tr> <tr class="odd" id="FNYR86H4F1N3TPYEX050" id-sequence="1192"> <td id="ZFJZYRMENMC9MRSFG516" class="alignleft valigntop underscore" id-sequence="1193"><p id="WEPSFJHG0MK2NDCTD356" id-sequence="1194"><strong><em>Primary auditory cortex (area in the temporal lobe)</em></strong></p> <div class="media nbannotation prerendered nbid_5caf90f30ec112076ccf151b rs_skip" id="QGALN968XJKRCQ9KN350" clrenderdata="[&quot;MMEUPW5AS9XMBPHCK726&quot;]" id-sequence="1195"><div class="cluimedia_viewer_image rs_skip"><div class="metadata inlineImage" data-filename="61815_05_unf39-t2.png" data-width="82" data-height="99" data-alt="An illustration showing the primary auditory cortex."></div><div class="nb_media image unnumbered"> <div class="imageContainer" style="width:82px;height:99px;"><img src="https://college.cengage.com/nextbook/shared/psychology/cacioppo_9781337561815/images/61815_05_unf39-t2.png?token=CD3844E30A003ECCC8072FDCEBF1AF87B73C16E22CD8E66F1BBC9079F5332520647C926E3C0A22A1EFABFAB73B212D68500C0588FA9F8473D3873F90032592142553C89742879D35" alt="An illustration showing the primary auditory cortex." width="82" height="99" class="rs_skip"></div> </div></div></div></td> <td id="LDAGCAZHRYHPZCDMC728" class="alignleft valigntop sidescore underscore" id-sequence="1196"><p id="FDPKM6LEMXL6KMC0T914" id-sequence="1197">Receives and performs an initial analysis of auditory input from the thalamus.</p></td> </tr> </tbody> </table><div class="fadediv_tall"></div><div class="fadediv_wide"></div><div class="enlargetable"><img alt="Enlarge Table" title="Enlarge Table" src="/static/nbapps/media/images/enlarge.png" class="rs_skip"></div></div> <div class="byline" id="PPJBTEYX3YJN4Y8UU619" id-sequence="1198">Credits: Top row— <span class="orgName"> Argosy Publishing</span>, Inc.; Second row— <span class="orgName"> Argosy Publishing</span>, Inc.; Third row— <span class="orgName"> Argosy Publishing</span>, Inc.; Fourth row— <span class="orgName"> Argosy Publishing</span>, Inc.; Bottom row— <span class="orgName"> Argosy Publishing</span>, Inc.</div> </div><a data-type="pageEnd" name="PageEnd_190" data-page="190"></a> <div class="footnotes"></div></div><div id="footer" id-sequence="1199"></div></div><div class="container page eoc "><a id="BHCFZ38HDJVWL5KMH905" name="BHCFZ38HDJVWL5KMH905" class="pageSection" id-sequence="1202"></a><div id="header" id-sequence="1203"><div id="breadcrumb-old" id-sequence="1204" class="rs_skip" style="display: none;"><a id="chapterTitle" href="javascript://" data-link-type="outline" id-sequence="1205" class="reader_toolbar_button" tabindex="1" role="button" aria-label="Chapter contents"></a></div><h1 id="SUHKULPWPBFYVJYV4857" id-sequence="1206"><span class="sectionLabel rs_skip"></span> <span class="headingText">Chapter Review</span></h1><h2 id="JDTZYVLHNM13UGUSK872" id-sequence="1207"><span class="sectionLabel rs_skip"></span> <span class="headingText"><span class="label">Key Terms</span> The Language of Psychological Science</span></h2></div><div class="content" id="BHCFZ38HDJVWL5KMH905_content" id-sequence="1208"> <p id="EUYYRV6WX9CRXTXEH326" id-sequence="1209">Be sure you can define these terms and use them correctly.</p> <div class="keyTermList" id="MSVP7T90072L3W2NU246" id-sequence="1210"><ul class="unformatted keyTermList" id="MSVP7T90072L3W2NU246" id-sequence="1211"> <li id="YXTCTGCSUPPAZTTX5833" id-sequence="1212"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa0" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa0"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa0" id="YXTCTGCSUPPAZTTX5833" id-sequence="1213"><span class="index nb_hidden clAnnotationDecoration rs_skip">absolute threshold</span><span class="term">absolute threshold</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The smallest amount of stimulus that can be detected.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa0">
    <span class="glossaryPopover footnotetext">
        <span class="term">absolute threshold</span>
        <span class="definition rs_skip">The smallest amount of stimulus that can be detected.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="TEWPWKK5VQ2MN2S8L582" id-sequence="1214"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa1" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa1"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa1" id="TEWPWKK5VQ2MN2S8L582" id-sequence="1215"><span class="index nb_hidden clAnnotationDecoration rs_skip">audition</span><span class="term">audition</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The sense of hearing.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa1">
    <span class="glossaryPopover footnotetext">
        <span class="term">audition</span>
        <span class="definition rs_skip">The sense of hearing.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="BMDSHR7JKP2ED2GEE355" id-sequence="1216"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa2" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa2"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa2" id="BMDSHR7JKP2ED2GEE355" id-sequence="1217"><span class="index nb_hidden clAnnotationDecoration rs_skip">auditory nerve</span><span class="term">auditory nerve</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The nerve carrying sound information from the cochlea to the brain.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa2">
    <span class="glossaryPopover footnotetext">
        <span class="term">auditory nerve</span>
        <span class="definition rs_skip">The nerve carrying sound information from the cochlea to the brain.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="EUFEYHMW3AVWH471L325" id-sequence="1218"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa3" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa3"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa3" id="EUFEYHMW3AVWH471L325" id-sequence="1219"><span class="index nb_hidden clAnnotationDecoration rs_skip">basilar membrane</span><span class="term">basilar membrane</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Membrane in the cochlea on which the organ of Corti is located.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa3">
    <span class="glossaryPopover footnotetext">
        <span class="term">basilar membrane</span>
        <span class="definition rs_skip">Membrane in the cochlea on which the organ of Corti is located.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="CGJWCR9UNE62AZQJ5486" id-sequence="1220"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa4" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa4"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa4" id="CGJWCR9UNE62AZQJ5486" id-sequence="1221"><span class="index nb_hidden clAnnotationDecoration rs_skip">binocular cues</span><span class="term">binocular cues</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A depth cue that requires the use of both eyes</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa4">
    <span class="glossaryPopover footnotetext">
        <span class="term">binocular cues</span>
        <span class="definition rs_skip">A depth cue that requires the use of both eyes</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="BQZSXQLKXM93N8YJF968" id-sequence="1222"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa5" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa5"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa5" id="BQZSXQLKXM93N8YJF968" id-sequence="1223"><span class="index nb_hidden clAnnotationDecoration rs_skip">bottom-up processing</span><span class="term">bottom-up processing</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Perception based on building simple input into more complex perceptions</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa5">
    <span class="glossaryPopover footnotetext">
        <span class="term">bottom-up processing</span>
        <span class="definition rs_skip">Perception based on building simple input into more complex perceptions</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="LTEUVS405VJJ00LQW280" id-sequence="1224"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa6" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa6"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa6" id="LTEUVS405VJJ00LQW280" id-sequence="1225"><span class="index nb_hidden clAnnotationDecoration rs_skip">cochlea</span><span class="term">cochlea</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The structure in the inner ear that contains auditory receptors.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa6">
    <span class="glossaryPopover footnotetext">
        <span class="term">cochlea</span>
        <span class="definition rs_skip">The structure in the inner ear that contains auditory receptors.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="LUSZGE7R3RZ1U84D9621" id-sequence="1226"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa7" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa7"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa7" id="LUSZGE7R3RZ1U84D9621" id-sequence="1227"><span class="index nb_hidden clAnnotationDecoration rs_skip">cones</span><span class="term">cones</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A photoreceptor in the retina that processes color and fine detail.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa7">
    <span class="glossaryPopover footnotetext">
        <span class="term">cones</span>
        <span class="definition rs_skip">A photoreceptor in the retina that processes color and fine detail.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="HGZQETSSP1GXWQG9V251" id-sequence="1228"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa8" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa8"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa8" id="HGZQETSSP1GXWQG9V251" id-sequence="1229"><span class="index nb_hidden clAnnotationDecoration rs_skip">cornea</span><span class="term">cornea</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The clear surface at the front of the eye that begins the process of directing light to the retina.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa8">
    <span class="glossaryPopover footnotetext">
        <span class="term">cornea</span>
        <span class="definition rs_skip">The clear surface at the front of the eye that begins the process of directing light to the retina.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="VARERXKAQ2EVGG04Z100" id-sequence="1230"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fa9" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fa9"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fa9" id="VARERXKAQ2EVGG04Z100" id-sequence="1231"><span class="index nb_hidden clAnnotationDecoration rs_skip">depth perception</span><span class="term">depth perception</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The ability to use the two-dimensional image projected on the retina to perceive three dimensions</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fa9">
    <span class="glossaryPopover footnotetext">
        <span class="term">depth perception</span>
        <span class="definition rs_skip">The ability to use the two-dimensional image projected on the retina to perceive three dimensions</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="XDREL979WFMV6ZR8W443" id-sequence="1232"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0faa" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0faa"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0faa" id="XDREL979WFMV6ZR8W443" id-sequence="1233"><span class="index nb_hidden clAnnotationDecoration rs_skip">difference threshold</span><span class="term">difference threshold</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The smallest detectable difference between two stimuli.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0faa">
    <span class="glossaryPopover footnotetext">
        <span class="term">difference threshold</span>
        <span class="definition rs_skip">The smallest detectable difference between two stimuli.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="SLFE3WVPBT59EKUZK632" id-sequence="1234"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fab" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fab"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fab" id="SLFE3WVPBT59EKUZK632" id-sequence="1235"><span class="index nb_hidden clAnnotationDecoration rs_skip">fovea</span><span class="term">fovea</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">An area of the retina that is specialized for highly detailed vision.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fab">
    <span class="glossaryPopover footnotetext">
        <span class="term">fovea</span>
        <span class="definition rs_skip">An area of the retina that is specialized for highly detailed vision.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="TZGFX16XSK6B98ECM826" id-sequence="1236"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fac" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fac"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fac" id="TZGFX16XSK6B98ECM826" id-sequence="1237"><span class="index nb_hidden clAnnotationDecoration rs_skip">gate theory</span><span class="term">gate theory</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The theory that suggests that input from touch fibers competes with input from pain receptors, possibly preventing pain messages from reaching the brain.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fac">
    <span class="glossaryPopover footnotetext">
        <span class="term">gate theory</span>
        <span class="definition rs_skip">The theory that suggests that input from touch fibers competes with input from pain receptors, possibly preventing pain messages from reaching the brain.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="WKZA6B8TCMKPX5QC3530" id-sequence="1238"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fad" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fad"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fad" id="WKZA6B8TCMKPX5QC3530" id-sequence="1239"><span class="index nb_hidden clAnnotationDecoration rs_skip">gustation</span><span class="term">gustation</span><span class="definition nb_hidden clAnnotationDecoration rs_skip"><em>See also</em> Chemical senses</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fad">
    <span class="glossaryPopover footnotetext">
        <span class="term">gustation</span>
        <span class="definition rs_skip"><em>See also</em> Chemical senses</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="VSKTWUDEU037T4VHF938" id-sequence="1240"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fae" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fae"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fae" id="VSKTWUDEU037T4VHF938" id-sequence="1241"><span class="index nb_hidden clAnnotationDecoration rs_skip">iris</span><span class="term">iris</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The brightly colored circular muscle surrounding the pupil of the eye.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fae">
    <span class="glossaryPopover footnotetext">
        <span class="term">iris</span>
        <span class="definition rs_skip">The brightly colored circular muscle surrounding the pupil of the eye.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="YGCFHX9UVJX1WEJMX584" id-sequence="1242"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0faf" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0faf"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0faf" id="YGCFHX9UVJX1WEJMX584" id-sequence="1243"><span class="index nb_hidden clAnnotationDecoration rs_skip">lens</span><span class="term">lens</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The clear structure behind the pupil that bends light toward the retina.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0faf">
    <span class="glossaryPopover footnotetext">
        <span class="term">lens</span>
        <span class="definition rs_skip">The clear structure behind the pupil that bends light toward the retina.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="RUJY45F4J3BRWVEM3566" id-sequence="1244"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb0" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb0"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb0" id="RUJY45F4J3BRWVEM3566" id-sequence="1245"><span class="index nb_hidden clAnnotationDecoration rs_skip">monocular cues</span><span class="term">monocular cues</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A depth cue that requires the use of only one eye</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb0">
    <span class="glossaryPopover footnotetext">
        <span class="term">monocular cues</span>
        <span class="definition rs_skip">A depth cue that requires the use of only one eye</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="RMHYML28X711YLMS3770" id-sequence="1246"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb1" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb1"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb1" id="RMHYML28X711YLMS3770" id-sequence="1247"><span class="index nb_hidden clAnnotationDecoration rs_skip">olfaction</span><span class="term">olfaction</span><span class="definition nb_hidden clAnnotationDecoration rs_skip"><em>See also</em> Chemical senses</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb1">
    <span class="glossaryPopover footnotetext">
        <span class="term">olfaction</span>
        <span class="definition rs_skip"><em>See also</em> Chemical senses</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="UAPM0LY4XHF7CWPNQ278" id-sequence="1248"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb2" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb2"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb2" id="UAPM0LY4XHF7CWPNQ278" id-sequence="1249"><span class="index nb_hidden clAnnotationDecoration rs_skip">olfactory bulbs</span><span class="term">olfactory bulbs</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">One of two structures below the frontal lobes of the brain that receive input from the olfactory receptors in the nose.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb2">
    <span class="glossaryPopover footnotetext">
        <span class="term">olfactory bulbs</span>
        <span class="definition rs_skip">One of two structures below the frontal lobes of the brain that receive input from the olfactory receptors in the nose.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="ZZVFJVWDCYMEZZTW0002" id-sequence="1250"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb3" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb3"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb3" id="ZZVFJVWDCYMEZZTW0002" id-sequence="1251"><span class="index nb_hidden clAnnotationDecoration rs_skip">olfactory nerve</span><span class="term">olfactory nerve</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A nerve carrying olfactory information from the olfactory receptors to the olfactory bulbs.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb3">
    <span class="glossaryPopover footnotetext">
        <span class="term">olfactory nerve</span>
        <span class="definition rs_skip">A nerve carrying olfactory information from the olfactory receptors to the olfactory bulbs.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="PUTFGW7JKB2JCD5ZE803" id-sequence="1252"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb4" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb4"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb4" id="PUTFGW7JKB2JCD5ZE803" id-sequence="1253"><span class="index nb_hidden clAnnotationDecoration rs_skip">opponent process theory</span><span class="term">opponent process theory</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A theory of color vision that suggests we have a red-green color channel and a blue-yellow color channel in which activation of one color in each pair inhibits the other color</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb4">
    <span class="glossaryPopover footnotetext">
        <span class="term">opponent process theory</span>
        <span class="definition rs_skip">A theory of color vision that suggests we have a red-green color channel and a blue-yellow color channel in which activation of one color in each pair inhibits the other color</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="PNWE244Q77UCKGHVR748" id-sequence="1254"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb5" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb5"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb5" id="PNWE244Q77UCKGHVR748" id-sequence="1255"><span class="index nb_hidden clAnnotationDecoration rs_skip">optic nerve</span><span class="term">optic nerve</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The nerve exiting the retina of the eye.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb5">
    <span class="glossaryPopover footnotetext">
        <span class="term">optic nerve</span>
        <span class="definition rs_skip">The nerve exiting the retina of the eye.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="HRSNGRTJAG9KXT8N5256" id-sequence="1256"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb6" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb6"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb6" id="HRSNGRTJAG9KXT8N5256" id-sequence="1257"><span class="index nb_hidden clAnnotationDecoration rs_skip">optic tracts</span><span class="term">optic tracts</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Nerve pathways traveling from the optic chiasm to the thalamus, hypothalamus, and midbrain.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb6">
    <span class="glossaryPopover footnotetext">
        <span class="term">optic tracts</span>
        <span class="definition rs_skip">Nerve pathways traveling from the optic chiasm to the thalamus, hypothalamus, and midbrain.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="MUEGJMYC69X56E7QL576" id-sequence="1258"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb7" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb7"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb7" id="MUEGJMYC69X56E7QL576" id-sequence="1259"><span class="index nb_hidden clAnnotationDecoration rs_skip">organ of Corti</span><span class="term">organ of Corti</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A structure located on the basilar membrane that contains auditory receptors.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb7">
    <span class="glossaryPopover footnotetext">
        <span class="term">organ of Corti</span>
        <span class="definition rs_skip">A structure located on the basilar membrane that contains auditory receptors.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="VJDA8Q1MFC00N04UM071" id-sequence="1260"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb8" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb8"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb8" id="VJDA8Q1MFC00N04UM071" id-sequence="1261"><span class="index nb_hidden clAnnotationDecoration rs_skip">papillae</span><span class="term">papillae</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Small bumps on the tongue that contain taste buds.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb8">
    <span class="glossaryPopover footnotetext">
        <span class="term">papillae</span>
        <span class="definition rs_skip">Small bumps on the tongue that contain taste buds.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="VXMMUVG3WLA6Y0Q5J157" id-sequence="1262"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fb9" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fb9"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fb9" id="VXMMUVG3WLA6Y0Q5J157" id-sequence="1263"><span class="index nb_hidden clAnnotationDecoration rs_skip">perception</span><span class="term">perception</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The process of interpreting sensory information.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fb9">
    <span class="glossaryPopover footnotetext">
        <span class="term">perception</span>
        <span class="definition rs_skip">The process of interpreting sensory information.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="CQCJGKKDP5X4QH8E0450" id-sequence="1264"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fba" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fba"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fba" id="CQCJGKKDP5X4QH8E0450" id-sequence="1265"><span class="index nb_hidden clAnnotationDecoration rs_skip">psychophysics</span><span class="term">psychophysics</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The study of relationships between the physical qualities of stimuli and the subjective responses they produce.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fba">
    <span class="glossaryPopover footnotetext">
        <span class="term">psychophysics</span>
        <span class="definition rs_skip">The study of relationships between the physical qualities of stimuli and the subjective responses they produce.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="TKTCRUU8LRUMQ44AE309" id-sequence="1266"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fbb" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fbb"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fbb" id="TKTCRUU8LRUMQ44AE309" id-sequence="1267"><span class="index nb_hidden clAnnotationDecoration rs_skip">pupil</span><span class="term">pupil</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">An opening formed by the iris.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fbb">
    <span class="glossaryPopover footnotetext">
        <span class="term">pupil</span>
        <span class="definition rs_skip">An opening formed by the iris.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="NQHZZGYPMN159L5FS246" id-sequence="1268"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fbc" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fbc"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fbc" id="NQHZZGYPMN159L5FS246" id-sequence="1269"><span class="index nb_hidden clAnnotationDecoration rs_skip">retina</span><span class="term">retina</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">Layers of visual processing cells in the back of the eye</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fbc">
    <span class="glossaryPopover footnotetext">
        <span class="term">retina</span>
        <span class="definition rs_skip">Layers of visual processing cells in the back of the eye</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="MZZLLB5B8ZU9KGRJ4598" id-sequence="1270"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fbd" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fbd"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fbd" id="MZZLLB5B8ZU9KGRJ4598" id-sequence="1271"><span class="index nb_hidden clAnnotationDecoration rs_skip">retinal disparity</span><span class="term">retinal disparity</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The difference between the images projected onto each eye</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fbd">
    <span class="glossaryPopover footnotetext">
        <span class="term">retinal disparity</span>
        <span class="definition rs_skip">The difference between the images projected onto each eye</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="YREEZQQUDY9HKV277232" id-sequence="1272"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fbe" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fbe"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fbe" id="YREEZQQUDY9HKV277232" id-sequence="1273"><span class="index nb_hidden clAnnotationDecoration rs_skip">rods</span><span class="term">rods</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A photoreceptor specialized to detect dim light</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fbe">
    <span class="glossaryPopover footnotetext">
        <span class="term">rods</span>
        <span class="definition rs_skip">A photoreceptor specialized to detect dim light</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="PQYD7VVASY6WLUQJ6922" id-sequence="1274"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fbf" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fbf"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fbf" id="PQYD7VVASY6WLUQJ6922" id-sequence="1275"><span class="index nb_hidden clAnnotationDecoration rs_skip">sensation</span><span class="term">sensation</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The process of detecting environmental stimuli or stimuli arising from the body.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fbf">
    <span class="glossaryPopover footnotetext">
        <span class="term">sensation</span>
        <span class="definition rs_skip">The process of detecting environmental stimuli or stimuli arising from the body.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="TLRCBCFF6TS4KP0A0565" id-sequence="1276"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fc0" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fc0"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fc0" id="TLRCBCFF6TS4KP0A0565" id-sequence="1277"><span class="index nb_hidden clAnnotationDecoration rs_skip">sensory adaptation</span><span class="term">sensory adaptation</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The tendency to pay less attention to a nonchanging source of stimulation.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fc0">
    <span class="glossaryPopover footnotetext">
        <span class="term">sensory adaptation</span>
        <span class="definition rs_skip">The tendency to pay less attention to a nonchanging source of stimulation.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="XTRK6LU125D47ZEGE030" id-sequence="1278"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fc1" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fc1"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fc1" id="XTRK6LU125D47ZEGE030" id-sequence="1279"><span class="index nb_hidden clAnnotationDecoration rs_skip">signal detection</span><span class="term">signal detection</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The analysis of sensory and decision-making processes in the detection of faint, uncertain stimuli.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fc1">
    <span class="glossaryPopover footnotetext">
        <span class="term">signal detection</span>
        <span class="definition rs_skip">The analysis of sensory and decision-making processes in the detection of faint, uncertain stimuli.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="TPEQ4TUEDFXU9UHJ5290" id-sequence="1280"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fc2" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fc2"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fc2" id="TPEQ4TUEDFXU9UHJ5290" id-sequence="1281"><span class="index nb_hidden clAnnotationDecoration rs_skip">somatosensation</span><span class="term">somatosensation</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The body senses, including body position, touch, skin temperature, and pain.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fc2">
    <span class="glossaryPopover footnotetext">
        <span class="term">somatosensation</span>
        <span class="definition rs_skip">The body senses, including body position, touch, skin temperature, and pain.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="WKHJ7WQJJE187CYMA880" id-sequence="1282"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fc3" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fc3"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fc3" id="WKHJ7WQJJE187CYMA880" id-sequence="1283"><span class="index nb_hidden clAnnotationDecoration rs_skip">taste buds</span><span class="term">taste buds</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A structure found in papillae that contains taste receptor cells.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fc3">
    <span class="glossaryPopover footnotetext">
        <span class="term">taste buds</span>
        <span class="definition rs_skip">A structure found in papillae that contains taste receptor cells.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="GTGJ4AD98NBXNBKLV664" id-sequence="1284"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fc4" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fc4"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fc4" id="GTGJ4AD98NBXNBKLV664" id-sequence="1285"><span class="index nb_hidden clAnnotationDecoration rs_skip">top-down processing</span><span class="term">top-down processing</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A perceptual process in which memory and other cognitive processes are required for interpreting incoming sensory information</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fc4">
    <span class="glossaryPopover footnotetext">
        <span class="term">top-down processing</span>
        <span class="definition rs_skip">A perceptual process in which memory and other cognitive processes are required for interpreting incoming sensory information</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="CDYQ1BZRA1B3NWNEM269" id-sequence="1286"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fc5" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fc5"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fc5" id="CDYQ1BZRA1B3NWNEM269" id-sequence="1287"><span class="index nb_hidden clAnnotationDecoration rs_skip">transduction</span><span class="term">transduction</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The translation of incoming sensory information into neural signals.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fc5">
    <span class="glossaryPopover footnotetext">
        <span class="term">transduction</span>
        <span class="definition rs_skip">The translation of incoming sensory information into neural signals.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="MNMAJ0VP8ZW3GKNYJ038" id-sequence="1288"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fc6" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fc6"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fc6" id="MNMAJ0VP8ZW3GKNYJ038" id-sequence="1289"><span class="index nb_hidden clAnnotationDecoration rs_skip">trichromatic theory</span><span class="term">trichromatic theory</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">A theory of color vision based on the existence of different types of cones for the detection of short, medium, and long wavelengths</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fc6">
    <span class="glossaryPopover footnotetext">
        <span class="term">trichromatic theory</span>
        <span class="definition rs_skip">A theory of color vision based on the existence of different types of cones for the detection of short, medium, and long wavelengths</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="DRSKL94P0S64XZAMN901" id-sequence="1290"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fc7" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fc7"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fc7" id="DRSKL94P0S64XZAMN901" id-sequence="1291"><span class="index nb_hidden clAnnotationDecoration rs_skip">vestibular system</span><span class="term">vestibular system</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The system in the inner ear that provides information about body position and movement.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fc7">
    <span class="glossaryPopover footnotetext">
        <span class="term">vestibular system</span>
        <span class="definition rs_skip">The system in the inner ear that provides information about body position and movement.</span>
        <span class="pointer"></span>
    </span>
</span></li> <li id="ENLHZXB9DM7B9N0E3038" id-sequence="1292"><a role="link" href="javascript://" data-annotation-id="5caf90f30ec112076ccf0fc8" class="clui_glossary_link glossary_link_5caf90f30ec112076ccf0fc8"><span class="glossary nbannotation nbid_5caf90f30ec112076ccf0fc8" id="ENLHZXB9DM7B9N0E3038" id-sequence="1293"><span class="index nb_hidden clAnnotationDecoration rs_skip">vision</span><span class="term">vision</span><span class="definition nb_hidden clAnnotationDecoration rs_skip">The sense that allows us to process reflected light.</span></span></a><span class="glossaryContainer clAnnotationDecoration footnotediv rs_skip" style="display:none" id="glossaryContainer_5caf90f30ec112076ccf0fc8">
    <span class="glossaryPopover footnotetext">
        <span class="term">vision</span>
        <span class="definition rs_skip">The sense that allows us to process reflected light.</span>
        <span class="pointer"></span>
    </span>
</span></li> </ul></div> <a data-type="pageEnd" name="PageEnd_191" data-page="191"></a><div class="footnotes"></div></div><div id="footer" id-sequence="1294"></div></div>